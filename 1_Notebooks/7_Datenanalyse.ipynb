{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419114ff-f17c-45bb-8178-753282c0e39a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Datenanalyse\n",
    "\n",
    "In diesem Notebook lernen wir, wie wir in Python gro√üe Mengen strukturierter Daten, allen voran Daten in Form von Tabellen, verarbeiten und analysieren k√∂nnen. \n",
    "\n",
    "Im f√ºnften Notebook haben wir mit folgender Tabelle gearbeitet:\n",
    "\n",
    "<img src=\"../3_Dateien/Grafiken_und_Videos/Fl√§chengr√∂sste_Gemeinden_Tabelle.png\">\n",
    "\n",
    "Wir haben unter Zuhilfenahme des `csv`-Moduls unseren eigenen Code geschrieben, um auszurechnen, wieviele der 100 fl√§chengr√∂√üten Gemeinden sich in jedem der sechzehn Bundesl√§nder befinden. In diesem Notebook lernen wir die sehr viel leistungsst√§rkere Bibliothek *pandas* kennen, die uns diese Rechnung im Handumdrehen liefern kann. Pandas kann aber viel mehr, wie wir gleich sehen werden.\n",
    "\n",
    "Zu Beginn m√ºssen wir pandas nat√ºrlich importieren. Folgendes Statement importiert die Bibliothek und verleiht ihr den Namen `pd`. Diese Abk√ºrzung ist eine Konvention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a68f01-688c-4605-bd5e-175caa212b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72803703-42be-459b-94f2-12a8ee10cfe5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Solltest Du einen `ModuleNotFoundError` erhalten, musst Du `pandas` erst √ºber die Command Line installieren. √ñffne dazu das Terminal (macOS) bzw. die Eingabeaufforderung (Windows) in einem neuen Fenster, gib `pip3 install pandas` (macOS) bzw. `pip install pandas` (Windows) ein und dr√ºcke auf Enter. Sobald der Prozess abgeschlossen ist, sollte der Import oben klappen.\n",
    "Um pandas kennenzulernen, wollen wir mit einem gro√üen Datensatz arbeiten, n√§mlich dem [Songkorpus](https://songkorpus.de/index.html). Das Songkorpus beinh√§lt Lieder von bekannten deutschen K√ºnstler:innen, u.a. von Udo Lindenberg und Fettes Brot und umspannt die Jahre 1969-2022. √ñffentlich herunterladbar sind unter anderem Worth√§ufigkeiten pro Jahr und zwar als Tabelle (auf der Webseite selbst finden sich weitere spannende Daten und Analysen). Jedes Wort, das in einem oder mehreren Songs in einem bestimmten Jahr vorkommt, steht in einer eigenen Zeile, zusammen mit dem entsprechenden Jahr und der H√§ufigkeit, mit der es in diesem Jahr bei allen K√ºnstler:innen auftritt (s.u.). Insgesamt handelt es sich um √ºber 380.000 W√∂rter. Solch eine tabellarische Datei, zumal derart gro√ü, ist pr√§destiniert dazu, mit pandas verarbeitet zu werden.\n",
    "\n",
    "## Input\n",
    "\n",
    "In der folgenden Zelle √∂ffnen wir die Datei, die sich bereits in \"3_Dateien/Songkorpus\" befindet, und lesen sie mit der pandas-Funktion `read_csv` ein, die neben dem Dateipfad u.a. auch das Trennzeichen (`sep`, in diesem Fall der Tabulator \"\\t\") als Argument nimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb01128-867f-4e72-8264-16e6ca07ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vor read_csv steht wie gewohnt der Modulname, damit Python wei√ü, wo sich die Funktion befindet\n",
    "songkorpus = pd.read_csv(\"../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e8f3f-2a7a-41af-bdc4-2e63a530fea1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Neben `read_csv` f√ºr Dateien mit Trennzeichen, bietet pandas u.a. auch Funktionen f√ºr XML (`read_xml`), JSON (`read_json`)  und Excel-Dateien (`read_excel`) an. Ebenfalls kann man je nach Daten weitere Parameter spezifizieren, u.a. `na_filter`, um zu definieren, wie mit fehlenden Werten (sog. *NaN-Werten*) umgegangen werden soll. \n",
    "\n",
    "*Bemerkung am Rande: Fehlende Werte f√ºhren immer wieder zu Problemen bei der Arbeit mit pandas. Deswegen solltest Du Dich beim Einlesen Deiner eigenen Daten stets fragen, ob bestimmte Werte darin fehlen k√∂nnten und wenn ja, wie Du damit umgehen m√∂chtest. Pandas bietet neben `na_filter` n√ºtzliche Methoden wie `isna`, `dropna` und `fillna` f√ºr den Umgang mit fehlenden Werten (mehr Infos [hier](https://pandas.pydata.org/docs/user_guide/missing_data.html)). Im Folgenden gehen wir aber nicht darauf ein, im Songkorpus fehlen schlicht keine Werte.*\n",
    "\n",
    "Die Lesemethode √ºberf√ºhrt unsere Daten in jedem Fall in ein sog. *DataFrame*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bdaa92-9dd4-43ff-9ef8-5e6916b8a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(songkorpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6ac71-11dc-4118-a0e4-97e6517bb1bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "DataFrames sind ein eigener Datentyp von pandas, auf dem wir eine Vielzahl n√ºtzlicher Operationen ausf√ºhren k√∂nnen, etwa um einen √úberblick √ºber die Daten zu bekommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a8f43-ba1b-475f-ba01-f9167491f898",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## √úberblick bekommen\n",
    "\n",
    "Hier bietet sich insbesondere die Methode `head` an, die standardm√§√üig die ersten f√ºnf Zeilen (also den \"Kopf\") des DataFrames ausgibt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc99c07-ede3-4c0d-b990-8f5cc66ecb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.head() #head nimmt optional eine Ganzzahl als Argument, die definiert, wieviele der ersten Zeilen ausgegeben werden sollen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0db8fe-8856-4374-b1b7-fa6e954e0f07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Eher komische W√∂rter in der Spalte \"CO_TOKEN\". Wie wir an Spalte \"CO_COUNT\" erkennen k√∂nnen, kamen sie aber auch nur jeweils einmal (im in \"CO_YEAR\" angegebenen Jahr) vor.\n",
    "\n",
    "Das Gegenst√ºck zu `head` ist `tail` (also der \"Schwanz\"), wodurch wir die letzten f√ºnf Zeilen des DataFrames erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34ae6b-082a-46f3-a319-f6ac3ae75c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.tail() #auch tail nimmt optional eine Ganzzahl als Argument, die definiert, wieviele der letzten Zeilen ausgegeben werden sollen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88785171-847b-49ba-b653-f411a47d4489",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Ausgabe sieht √ºbrigens anders aus, wenn wir einen `print`-Befehl verwenden, anstatt dass JupyterLab schlicht die letzte Zeile ausgibt (probier's aus!). Mit `print`-Befehl verschwindet die angenehme Formatierung.\n",
    "\n",
    "Mithilfe von `shape`, `columns` und `index` k√∂nnen wir au√üerdem in Erfahrung bringen, welches Format (`shape`), d.h. wieviele Spalten und Zeilen, das DataFrame hat, sowie, wie Spalten (`columns`) und Zeilen (`index`) benannt sind.\n",
    "\n",
    "‚ö†Ô∏è Achtung: Es handelt sich dabei um sog. Attribute des DataFrames, die wir uns vereinfacht gesagt als Eigenschaften des DataFrames vorstellen k√∂nnen. Um auf ein Attribut eines Objekts zuzugreifen, h√§ngt man den Namen des Attributs wie bei Methoden nach einem Punkt an das betreffende Objekt, schlie√üt aber nicht mit Klammern ab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bae015-15ed-4991-aa7f-d0336b7ca309",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(songkorpus.shape, songkorpus.columns, songkorpus.index, sep=\"\\n\")\n",
    "original_len = len(songkorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a64b1-6a33-4ec7-ae82-53b651b016aa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Unser DataFrame besteht also aus 386.510 Zeilen und drei Spalten. Die Anzahl an Zeilen, also die L√§nge des DataFrames, speichern wir in einer separaten Variablen ab, wir werden sie sp√§ter noch brauchen.\n",
    "\n",
    "Die Spaltennamen sind \"CO_TOKEN\", \"CO_YEAR\" und \"CO_COUNT\" und die Zeilen sind mit Indizes von 0 (inklusive) bis 386510 (exklusive) durchnummeriert. \n",
    "\n",
    "Die etwas kryptischen Spaltennamen k√∂nnen wir √§ndern, indem wir das Attribut `columns` unseres DataFrames ganz einfach mit einer Liste an neuen Spaltennamen √ºberschreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70052e-6a8f-4904-97ea-920003824ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.columns = [\"Wort\", \"Jahr\", \"H√§ufigkeit\"]\n",
    "print(songkorpus.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750a6ff-0a95-4f79-849c-88e2c12c575f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die L√§nge der Liste muss nat√ºrlich der Anzahl an Spalten entsprechen. \n",
    "\n",
    "Um eine spezifische Spalte zu √ºberschreiben, k√∂nnen wir die `rename`-Methode verwenden, derer wir ein dictionary mit Schl√ºssel-Werte-Paaren ({\"jetziger Name\": \"neuer Name\"}) √ºbergeben. Im Allgemeinen haben wir beim Bearbeiten eines DataFrames zwei M√∂glichkeiten, um die Bearbeitung wirksam zu machen: \n",
    "\n",
    "1) Wir k√∂nnen immer das alte DataFrame mit der bearbeiteten Version √ºberschreiben. So haben wir das auch in der Zelle obendran gehandhabt. \n",
    "2) Bei der Bearbeitung mithilfe einer Methode, hier `rename`, k√∂nnen wir auch den Parameter `inplace=True` spezifizieren, um die Bearbeitung \"an Ort und Stelle\" vorzunehmen. \n",
    "\n",
    "In der n√§chsten Zelle sehen wir beide Alternativen. Im Folgenden beschr√§nken wir uns aber auf die erste M√∂glichkeit, da diese auch abseits von Methoden funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24bb83-3868-4010-a155-c2b2fb3bd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus = songkorpus.rename(columns={\"Wort\": \"Token\"}) #1. M√∂glichkeit: √úberschreiben\n",
    "songkorpus.rename(columns={\"Wort\": \"Token\"}, inplace=True) #2. M√∂glichkeit: Bearbeiten \"inplace\"/\"an Ort und Stelle\"\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38433ae-706f-4207-a861-e3cb1f49680d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Schon kennen wir erste n√ºtzliche Operationen f√ºr einen ersten Eindruck unserer Daten.\n",
    "\n",
    "***\n",
    "\n",
    "## üîß Anwendungsfall: Wortverlaufskurven visualisieren üìà\n",
    "\n",
    "Auch in diesem Notebook gibt es einen Anwendungsfall: Wir wollen visualisieren, wie h√§ufig beliebige W√∂rter in jedem Jahr im vom Songkorpus abgedeckten Zeitraum 1969-2022 vorkommen. F√ºr die Begriffe \"ich\", \"du\", \"er\" und \"sie\" s√§he das z.B. so aus:\n",
    "\n",
    "<img src=\"../3_Dateien/Grafiken_und_Videos/Wortverlaufskurve_Jahr.png\" width=\"700\">\n",
    "\n",
    "Es scheint, als s√§ngen die K√ºnstler:innen im Songkorpus bevorzugt √ºber sich selbst (bzw. √ºber ihr lyrisches Ich). üòÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bca9e-25f1-4fe4-ad84-3b20b71f136c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Zuallererst wollen wir einen detailierten Blick auf Spalten und Zeilen werfen, aus denen ein DataFrame ja besteht.\n",
    "\n",
    "## Auf Spalten zugreifen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30c95b-d6f6-4352-9724-57a9015371b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenn wir an einer bestimmten Spalte eines DataFrames interessiert sind, k√∂nnen wir auf diese mit der gleichen Syntax wie bei dictionaries zugreifen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c3906-9941-4ce5-8e43-3b7de4b58b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f55e2b-8722-4c15-91b3-02abc71da9a0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "An dieser Stelle ist es nat√ºrlich wichtig, dass die Spalte aktuell wirklich \"Token\" und nicht mehr \"CO_TOKEN\" oder \"Wort\" hei√üt. Dies w√ºrde, wie bei inexistenten Schl√ºsseln in einem dictionary auch, zu einem `KeyError` f√ºhren.\n",
    "\n",
    "Weiter funktioniert f√ºr den Spaltenzugriff auch die sog. dot-Notation nach dem Schema `DataFrame.column`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd34cea-ad82-4c02-9ac5-21c78a7340fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.Token #beachte, dass hierf√ºr der Spaltenname nicht als string, also ohne Anf√ºhrungszeichen angeh√§ngt wird!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5169b-3ec0-4e4e-8d7b-94634ad0247e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die dot-Notation erf√ºllt (fast immer) die gleiche Funktion wie die Zugriffsweise √ºber eckige Klammern, auf die wir uns fortan beschr√§nken. \n",
    "\n",
    "In jedem Fall entspricht das, was wir dabei zur√ºckerhalten, dem zweiten wichtigen Datentyp von pandas neben *DataFrame*, n√§mlich einer sog. *Series*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e0325-7aa6-4037-b3b6-4a174c66f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = songkorpus[\"Token\"]\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae55036-bab7-4d12-acc4-c71a4bbd4af3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Series kann man mit Listen vergleichen. Sie sind im Gegensatz zu Dataframes nicht zweidimensional (Spalten und Zeilen), sondern eindimensional. Viele Listen-Operationen wie z.B. Indexing und Slicing funktionieren bei Series gleicherma√üen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b8fab-77c5-4a70-b16e-6e68c8ec2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens[10000], \"\\n\") #Indexing\n",
    "print(tokens[9999:10002]) #Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7914210-b059-4a90-b63d-e54ab273b8bd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 1:** Erstelle eine weitere Series, die nur das 100.000te, 200.000te und 300.000te Token der Series `tokens` beinh√§lt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0bdfc-209a-4bb8-ac2d-ca90416c2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7edeb-a4e1-4a04-8d45-65a176251db0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Anstatt *eines* Spaltennamens k√∂nnen wir auch eine Liste an Spaltennamen √ºbergeben, um auf mehrere Spalten gleichzeitig zuzugreifen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7faaf-5382-42d9-a1c0-f0b900b7db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_columns = songkorpus[[\"Token\", \"Jahr\"]].head() #beachte die inneren eckigen Klammern f√ºr die Liste!\n",
    "two_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efb9c9-d7f2-4930-9ebf-ac32b7f00bf9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "√úberlege Dir kurz, was f√ºr ein Datentyp `two_columns` hat. \n",
    "\n",
    "Genau: Nun haben wir nicht mehr nur eine Spalte, in der Zeilenwert um Zeilenwert in einer Dimension gespeichert ist, sondern zwei Spalten. `two_columns` ist also immer noch ein zweidimensionales Objekt, sprich ein DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f478e-4d27-4646-ad0d-dd0166ee0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(two_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c96de-e05a-4450-83e0-aa7f7df05d78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun wissen wir, wie wir auf Spalten zugreifen k√∂nnen. \n",
    "\n",
    "## Auf Zeilen zugreifen\n",
    "\n",
    "Um auf Zeilen zuzugreifen, h√§ngen wir `.loc[index]` an das DataFrame an und √ºbergeben den Index der gew√ºnschten Zeile anstelle von `index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ff79e-2f89-4101-a5d8-e44d211f77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.loc[777]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b20e21-1b6d-4fc7-8a4a-e5715816a76c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Verwende stets diese Syntax, um auf Zeilen zuzugreifen. \n",
    "\n",
    "Anf√§nger:innen versuchen oft, die Syntax `DataFrame[index]` zu verwenden. Das f√ºhrt aber zu einem `KeyError`, denn diese Syntax ist dem Spaltenzugriff vorbehalten (sollte der √ºbergebene `index` zuf√§lligerweise auch ein Spaltenname sein, erhalten wir keinen `KeyError`, aber die Ausgabe entspricht dann auch der jeweiligen Spalte, und nicht der gew√ºnschten Zeile).\n",
    "\n",
    "Da wir blo√ü auf eine einzige Zeile zugreifen, in der Spaltenwert um Spaltenwert in einer Dimension gespeichert ist, liegt wieder der Datentyp Series vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e8ed9-b5d5-47e6-840b-085c0c5e707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(songkorpus.loc[777]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747552f-fc21-47a3-aa59-9a06a6579033",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Zur Verdeutlichung: Sowohl eine Sequenz von Werten einer Spalte als auch eine Sequenz von Werten einer Zeile entsprechen bei pandas einer Series. Entscheidend ist blo√ü, dass nur eine einzige Dimension vorliegt. Sobald ein Objekt sowohl mehrere Spalten als auch mehrere Zeilen umfasst, handelt es sich um ein DataFrame.\n",
    "\n",
    "Ein solches Objekt k√∂nnen wir auch √ºber `loc` erhalten, indem wir auf mehrere Zeilen gleichzeitig zugreifen. Dies funktioniert wie bei dem Zugriff auf mehrere Spalten (s.o), indem wir mehrere Indizes als Liste √ºbergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501ad3b-2a0a-4365-9322-0823c84886b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(songkorpus.loc[[777,888]])) #beachte die inneren eckigen Klammern f√ºr die Liste!\n",
    "songkorpus.loc[[777,888]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf1ce2-bd71-4d66-8356-901e513f348f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Zudem k√∂nnen wir auf mehrere aufeinanderfolgende Zeilen zugreifen, indem wir dieselbe Syntax wie bei Slicing verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d18d8-52d3-424b-a948-dee7d11e720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.loc[777:780] #keine inneren eckigen Klammern!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81758d0-b78e-4631-a23e-958a12934b3a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Im Gegensatz zu gew√∂hnlichem Slicing bei Listen wird der letzte Index bei Pandas miteingerechnet (\"inklusiv\", vgl. zweites Notebook).\n",
    "\n",
    "Abschlie√üend sei erw√§hnt, dass Zeilen nicht zwingend mit *numerischen* Indizes durchnummeriert sein m√ºssen. Zeilen k√∂nnen wie Spalten ebenfalls Namen haben. Dieses Szenario wollen wir in der n√§chsten √úbung mit denselben Daten durchspielen.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 2:** \n",
    "\n",
    "1. Lies die Datei `songkorpus_tokens.tsv` abermals ein und √ºbergib beim Erstellen des DataFrames zus√§tzlich den Parameter `index_col=0`. Dadurch wird die erste Spalte (mit dem Index 0), also diejenige mit den Tokens, zur sog. *Index-Spalte*. Jede Zeile hat nun statt eines numerischen Index einen Namen, n√§mlich das jeweilige Token. Weise das DataFrame der Variablen `songkorpus_labelled_rows` zu. \n",
    "2. Benenne die Spalten wie bei `songkorpus` um. Falls Du hier eine Fehlermeldung kriegst, lies sie aufmerksam und passe Deinen Code entsprechend an.\n",
    "3. √úberlege Dir, was die Tatsache, dass wir nun Tokens als Zeilennamen verwenden, zur Konsequenz hat. Experimentiere dazu gerne mit dem DataFrame herum und greife auf verschiedene Zeilen √ºber Namen zu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59357c3f-8363-4c52-84f7-cb9a2aaf525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48667d-813e-4558-a989-6703ce3fe35a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Im Gegensatz zu Spaltennamen (und Schl√ºsseln bei dictionaries) d√ºrfen Zeilennamen mehrfach vorkommen. Der Zugriff auf eine oder mehrere Zeilen funktioniert ungeachtet dessen gleich wie bei DataFrames, die mit numerischen Indizes durchnummeriert sind, also mittels `.loc[index]`.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 3:** Setze die Tatsache, dass Zeilennamen mehrfach vorkommen d√ºrfen, produktiv ein und finde heraus, wie oft \"Dresden\" in `songkorpus_labelled_rows` vorkommt, indem Du die H√§ufigkeiten in allen Jahren, in denen das Wort gesungen wird, zusammenz√§hlst.\n",
    "\n",
    "üí° Tipp: Der erste Schritt besteht darin, aus dem gesamten DataFrame `songkorpus_labelled_rows` ein kleineres, sog. *Sub-DataFrame* zu erstellen, das mit einer neuen Variablen referenziert wird. Der zweite Schritt besteht darin, eine Series aus diesem Sub-DataFrame \"herauszuschneiden\", die Du anschlie√üend wie eine Liste behandeln kannst, um schlie√ülich zur Anzahl der Nennungen von \"Dresden\" zu gelangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a7819-4392-4fae-84fa-063b21e585f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5eaf89-0992-44d8-a073-e3a5a82a763f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "## Auf Spalten *und* Zeilen zugreifen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857bb4a-57e5-4bec-b0e8-810769dd8b82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "`loc` k√∂nnen wir ebenfalls verwenden, um gleichzeitig anzugeben, auf welche Spalte(n) und Zeile(n) wir bei einem DataFrame zugreifen m√∂chten. Auf den Zeilenindex folgt nach einem Komma der gew√ºnschte Spaltenname:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb0ad9-fca1-4291-ad1c-0754e8c94eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(songkorpus.loc[10, \"Jahr\"])\n",
    "\n",
    "\"\"\"Randbemerkung: Auf die Spitze getrieben, k√∂nnen wir mit .loc auch nur auf Spalten zugreifen, n√§mlich, indem wir, \n",
    "wie bei Listen-Slicing auch m√∂glich, durch Weglassen eines Start- und Endindex s√§mtliche Zeilen ansprechen, sprich so: \n",
    "songkorpus.loc[:, \"Jahr\"]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c5d80-c3d2-4feb-bfdd-f029fe5d7c4b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Neben der Herangehensweise √ºber `loc` besteht auch die M√∂glichkeit erst wie oben gelernt auf eine spezifische Spalte bzw. eine spezifische Zeile zuzugreifen, was in einer Series resultiert, und in dieser Series anschlie√üend auf eine bestimmte Zeile bzw. eine bestimmte Spalte zuzugreifen (z.B. `songkorpus[\"Token\"][22]`). Obige Syntax mit `loc` ist diesen sog. \"chained assignments\" (etwa: Kettenaufgabe) jedoch vorzuziehen.\n",
    "\n",
    "Wie immer k√∂nnen wir auch Listen √ºbergeben, um auf mehrere Spalten und/oder mehrere Zeilen gleichzeitig zuzugreifen. Beim Zeilenzugriff funktioniert sowohl eine Liste einzelner Indizes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2f2ce-eb25-447a-8b76-a3cbb8d6a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.loc[[9999,10000], [\"Token\", \"H√§ufigkeit\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945a57e-92aa-4184-b646-93703b423e53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "...als auch die slicing√§hnliche Syntax f√ºr eine Sequenz an Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c79387-86b1-445a-a2e3-0eda0c176ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.loc[9999:10005, [\"Token\", \"H√§ufigkeit\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c916d-efec-4002-a603-68a8c1bf4ed4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun wissen wir, wie wir auf beliebige (Kombinationen) von Spalte(n) und Zeile(n) zugreifen k√∂nnen. Als N√§chstes m√∂chten wir unseren Daten erweitern, indem wir eine Spalte hinzuf√ºgen:\n",
    "\n",
    "## Spalten hinzuf√ºgen\n",
    "\n",
    "Eine einzelne Spalte entspricht ja einer Series und Series wiederum kommen Listen sehr nahe. Deshalb k√∂nnen wir zur Definition einer neuen Spalte ganz einfach eine Liste √ºbergeben, deren L√§nge nat√ºrlich der Anzahl an Zeilen des DataFrames entsprechen muss.\n",
    "\n",
    "Sagen wir, wir h√§tten gerne eine neue Spalte, in der das Jahrzehnt gespeichert wird, in der das jeweilige Token gesungen wurde. Die einzelnen Jahre haben wir schon, nun wollen wir aber jeweils zehn Jahre zu einem Jahrzehnt b√ºndeln. \n",
    "\n",
    "Dazu k√∂nnen wir in gewohnter Python-Manier √ºber die Spalte \"Jahr\" in `songkorpus` iterieren (auch bei der Iteration zieht die Analogie Series ‚Äì Liste!), auf den jeweiligen Wert in der Spalte \"Jahr\" zugreifen, ihn in einen string casten und das Jahr reduziert auf das Jahrzehnt einer neuen Liste anh√§ngen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81e3a0-a93c-4102-9ae3-c12c446542de",
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = []\n",
    "for year in songkorpus[\"Jahr\"]:\n",
    "    \"\"\"Casten in einen string ist erforderlich, da sich Slicing nur auf sequentielle Objekte anwenden l√§sst \n",
    "    (Ganzzahlen geh√∂ren nicht dazu, vgl. zweites Notebook) und nur strings miteinander konkateniert werden k√∂nnen.\"\"\"\n",
    "    decade = str(year)[:-1] + \"0\"\n",
    "    decades.append(decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d87a3-860b-41dd-9f40-db5f84853135",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Anschlie√üend m√ºssen wir nur noch eine neue Spalte in `songkorpus` definieren und ihr die Liste `decades` zuweisen. Das Erstellen einer neuen Spalte erfolgt genau gleich wie das Definieren eines neuen Schl√ºssels bei einem dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0909205-f9c5-4bb8-bc8a-4a05fb11784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Jahrzehnt\"] = decades\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b89bee-73bd-4297-a4fc-e0e050493d38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Recht simpel.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 4:**\n",
    "\n",
    "F√ºge `songkorpus` eine weitere Spalte mit dem Namen \"L√§nge\" hinzu, in der die Anzahl Buchstaben je Token steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f3e5f-2572-4d46-abb9-6885bf501a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d12e2d-5c2c-4b69-b0e6-5ed59553ac00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 5:** Vereinfache den Code von oben, mit dessen Hilfe wir die Spalte \"Jahrzehnt\" hinzugef√ºgt haben, indem Du ihn mittels List Comprehension (vgl. viertes Notebook) auf eine einzige Zeile reduzierst. Hole den Abschnitt zu List Comprehensions nach, falls Du ihn damals ausgelassen hast, da er als fortgeschritten markiert war.\n",
    "\n",
    "Hinweis: `songkorpus` verf√ºgt ja bereits √ºber eine Spalte mit dem Namen \"Jahrzehnt\". Indem Du das Resultat Deiner List Comprehension `songkorpus[\"Jahrzehnt\"]` zuweist, √ºberschreibst du die befindliche Spalte ganz einfach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5180e14-e561-41bf-b47b-0e8d36529f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f03ed-1b59-45f0-9501-6cc1b30bf745",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Sehr gut. Zus√§tzlich zum klassischen `for`-Loop und der List Comprehension lernen wir weiter unten eine dritte, pandas-eigene Methode kennen, mit der wir den modifizierten Inhalt einer Spalte in eine andere schreiben k√∂nnen.\n",
    "\n",
    "Schauen wir uns nun an, wie wir Zeilen zu einem DataFrame hinzuf√ºgen k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcf94c-a697-462f-8a1b-2347a2ccc899",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Zeilen hinzuf√ºgen\n",
    "\n",
    "Auch neue Zeilen k√∂nnen wir einem DataFrame als Liste hinzuf√ºgen. Die L√§nge der Liste muss wiederum der Anzahl an Spalten entsprechen. \n",
    "\n",
    "Dies ist bei `new_row` in der n√§chsten Zelle nur der Fall, wenn Du in der √úbung oben eine f√ºnfte Spalte namens \"L√§nge\" hinzugef√ºgt hast. Um sicherzustellen, dass `songkorpus` im Weiteren alle notwendigen Spalten umfasst, f√ºgt die erste Zeile die Spalte \"L√§nge\" mittels List Comprension hinzu (bzw. √ºberschreibt eine bereits vorhandene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d8e88-f2dc-4c92-b8b5-34196445447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"L√§nge\"] = [len(str(token)) for token in songkorpus[\"Token\"]]\n",
    "new_row = [\"Fantasiewort\", 2023, 800, 2020, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1b443-a076-4b4c-9c29-fbe2d09b9329",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "`new_row` k√∂nnen wir `songkorpus` nun unter Verwendung der bereits bekannten `.loc[index]`-Syntax hinzuf√ºgen. Als `index` geben wir schlicht den letzten numerischen Index + 1 an, was der L√§nge von `songkorpus` entspricht (die numerischen Indizes fangen ja bei 0 an):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c70490-83b2-4083-b98f-2c1e52fd6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.loc[len(songkorpus)] = new_row\n",
    "songkorpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88841556-dfc3-40fc-8aa8-4fcc4ab09f86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenn Du diese Zelle mehrfach ausf√ºhrst, wird `new_row` jedes einzelne Mal hinzugef√ºgt. Schlie√ülich entspricht `len(songkorpus)` jedes Mal dem letzten numerischen Index + 1. \n",
    "\n",
    "Anstatt eine Zeile am Ende eines DataFrames hinzuzuf√ºgen, kannst Du die gleiche Syntax verwenden, um eine bestimmte, bereits existierende Zeile zu √ºberschreiben. Das tun wir hier aber nicht, da wir mit den originalen Daten weiterarbeiten m√∂chten. Entsprechend wollen wir die letzte(n) Zeile(n) mit Fantasiew√∂rtern auch wieder entfernen.\n",
    "\n",
    "## Spalten und Zeilen entfernen\n",
    "\n",
    "Zu diesem Zweck gibt es die `drop`-Methode, die wir sowohl zum Entfernen von Spalten als auch Zeilen benutzen k√∂nnen. Als erstes Argument √ºbergeben wir ihr den Namen der zu entfernenden Spalte bzw. den numerischen Index (oder Namen, s.o.) der zu entfernenden Zeile. Um mehrere Spalten oder Zeilen zu entfernen, k√∂nnen jeweils auch Listen √ºbergeben werden. Anschlie√üend spezifizieren wir mithilfe des `axis`-Parameters, ob es sich um eine Spalte oder eine Zeile handelt, die entfernt werden soll. `axis=1` steht f√ºr Spalten und `axis=0` f√ºr Zeilen (was der Standardwert ist und nicht zwingend angegeben werden muss). Die Syntax mit Standardwerten lautet also folgenderma√üen:\n",
    "\n",
    "`DataFrame.drop(index_or_name, axis=0)`\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 6:** F√ºhre die Zelle oben, in der wir `songkorpus` Zeilen mit Fantasiew√∂rtern hinzugef√ºgt haben, noch ein paar Mal aus, ohne darauf zu achten wie oft. Verwende nun `drop` in einer geeigneten Kontrollstruktur (vgl. drittes Notebook) sowie die anfangs eingef√ºhrte Variable `original_len`, um die Fantasiew√∂rter wieder zu entfernen und `songkorpus`, was die Anzahl an Zeilen betrifft, wieder in seinen Originalzustand zu bringen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e66df2-a536-414e-a50c-1dbbc835148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007a3a2-42ad-4324-bb09-280f80d6aa50",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Wunderbar! \n",
    "\n",
    "## Deskriptive Statistiken\n",
    "\n",
    "Einige der Spalten in `songkorpus` enthalten ja numerische Werte, konkret die Spalten \"Jahr\", \"H√§ufigkeit\" und \"L√§nge\" (die Werte in \"Jahrzehnt\" haben wir als string abgespeichert, s.o.). Numerischen Werten n√§hern wir uns am besten √ºber despriptive Statistiken, also etwa √ºber Minimal- und Maximalwerte.\n",
    "\n",
    "Pandas bietet daf√ºr eine Reihe n√ºtzlicher Methoden: Angewandt auf eine Spalte, gibt `min` den kleinsten Wert darin zur√ºck, `max` den gr√∂√üten, `mean` den Durchschnitt, `median` den Median und `sum` die Summe aller Werte. \n",
    "\n",
    "Bevor wir dies tun, stellen wir noch sicher, dass die oben hinzugef√ºgten Zeilen auch wirklich nicht mehr vorhanden sind, schlie√ülich soll das achthundertfach vorkommende \"Fantasiewort\" unsere Statistiken nicht verzerren. Anstatt mit der `drop`-Methode von oben, w√§hlen wir hier einen anderen Weg, n√§mlich Slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9fdce4-ac4b-4c80-a0ac-515da5178f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus = songkorpus[:original_len]\n",
    "\n",
    "print(songkorpus[\"H√§ufigkeit\"].min())\n",
    "print(songkorpus[\"H√§ufigkeit\"].max())\n",
    "print(songkorpus[\"H√§ufigkeit\"].mean())\n",
    "print(songkorpus[\"H√§ufigkeit\"].median())\n",
    "print(songkorpus[\"H√§ufigkeit\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96489fbb-f633-4796-bacb-49157a8910b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenig √ºberraschend ist 1 der kleinste Wert in der Spalte \"H√§ufigkeit\". W√∂rter, die gar nie vorkommen, befinden sich ja nicht im Datensatz. \n",
    "\n",
    "Spannend ist jedoch, zu erfahren, dass das meistgesungene Token 2007 Mal in einen bestimmten Jahr vorkommt. Interessant ist auch, dass der Durchschnitt zwar bei fast 6 Nennungen liegt, mindestens die H√§lfte aller Werte jedoch genau 1 sind. Der Median ist ja der Wert, der genau in der Mitte aller \"aufgereihten\" Werte steht: links von ihm k√∂nnen also nur weitere Einsen stehen, in der Mitte steht selbst auch eine 1. Diese Logik funktioniert nat√ºrlich nur, weil wir wissen, dass alle Werte in dieser Spalte Ganzzahlen sind.\n",
    "\n",
    "Einen kompakten √úberblick √ºber diese und ein paar weitere Statistiken liefert auch `describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1a985-e045-49cd-96ce-8282783293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"H√§ufigkeit\"].describe() #entgegen ihrer Bezeichnung liefert describe auch die nicht-deskriptive, sondern inferentielle Standardabweichung (std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03ad88-c3df-4c7d-8b36-719a9de0b41a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Dabei lernen wir u.a., dass drei Viertel aller Tokens nur maximal drei Mal in einem bestimmten Jahr vorkommen.\n",
    "\n",
    "`describe` l√§sst sich nicht nur auf eine Series, sondern auch auf ein DataFrame anwenden, wobei wir die Statistiken nur bei Spalten mit numerischen Werten zur√ºckerhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc714a9-af4a-4a91-a2ff-fac3e40d827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ace1a-785d-4369-ab6d-afb0a7819fdc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sehr n√ºtzlich ist auch die `value_counts`-Methode, die s√§mtliche Werte in einer Spalte ausz√§hlt und uns eine Art Frequenzw√∂rterbuch zur√ºckgibt. Die Methode liefert also genau das, was wir im f√ºnften Notebook manuell f√ºr die 100 fl√§chengr√∂√üten Gemeinden Deutschlands errechnet haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50125980-c033-4780-8cc3-4bb76fa43143",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Jahrzehnt\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bbcc3-c642-4858-bb59-4b536c0caee7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Zehnerjahre sind dieser Auswertung zufolge am h√§ufigsten vertreten im `songkorpus`. \n",
    "\n",
    "Da absolute Zahlen oft schwer miteinander zu vergleichen sind, bietet `value_counts` auch die M√∂glichkeit, die Werte zu normalisieren, d.h. relativ auszugeben. Dazu spezifizieren wir ganz einfach `normalize=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5386b40-a205-4b30-b6a2-ce8187d6d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Jahrzehnt\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fc0db-6b04-4751-a0f8-b910ff197c64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "So l√§sst sich leicht ablesen, dass fast die H√§lfte aller Tokens in `songkorpus` aus den Nuller- und Zehnerjahren stammen. Dieses Ungleichgewicht m√ºssen wir bei k√ºnftigen Analysen im Hinterkopf behalten.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 7:** Mithilfe von `describe` haben wir oben herausgefunden, dass die durchschnittliche Wortl√§nge in `songkorpus` 6.88 Buchstaben betr√§gt. Die maximale Wortl√§nge betr√§gt hingegen sagenhafte 53 Buchstaben. Die Verteilung scheint alles andere als gleichm√§√üig zu sein, was wir auch an den sog. *Quartilen* 25% und 75% sehen (Quartile werden wie der Median berechnet, nur geht es nicht um den Mittelwert sondern um die Werte nach einem Viertel bzw. drei Vierteln aller aufgereihten Werte). Finde heraus, welche Wortl√§ngen f√ºr jeweils mindestens 10 % aller W√∂rter gelten. Finde ebenfalls heraus, welche Wortl√§ngen f√ºr jeweils maximal 1 % aller W√∂rter gelten.\n",
    "\n",
    "üí° Tipp: Einer von verschiedenen denkbaren L√∂sungswegen involviert die Tatsache, dass DataFrames und Series mit dictionaries verwandt sind und sich auch in ein solches casten lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39edd4-5c88-4b54-94b1-8803dfcb811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5955e-fad7-41b2-80ca-402d49662581",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "Zwei weitere hilfreiche Methoden sind `nlargest` und `nsmallest`, die das DataFrame nach einer bestimmten Spalte (spezifiziert als zweites Argument) sortieren und die *n* (spezifiziert als erstes Argument) obersten bzw. untersten Zeilen ausgibt. Folgender Code liefert also die obersten zehn Zeilen eines nach der Spalte \"H√§ufigkeit\" absteigend sortierten DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e342c-fc27-4dbd-b8dd-d73b4be4ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.nlargest(10, \"H√§ufigkeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d3440-94b9-4762-b2ba-88f3d723dc0f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wasser auf die M√ºhlen der Selbstbezogenheitsthese! üòÖ\n",
    "\n",
    "Nat√ºrlich k√∂nnen wir ein DataFrame auch als Ganzes sortieren, anstatt blo√ü die *n* obersten bzw. untersten Zeilen zur√ºckzukriegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf28cc2-2581-4795-a00d-002929e17b3c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Werte sortieren\n",
    "\n",
    "Dazu benutzen wir die Methode `sort_values`, der wir als erstes Argument die Spalte √ºbergeben, anhand derer wir sortieren wollen, und als zweites Argument die Richtung der Sortierung, wobei `ascending=True` f√ºr aufsteigend (Standardwert) und `ascending=False` f√ºr absteigend steht.\n",
    "\n",
    "Folgender Code sortiert `songkorpus` aufsteigend nach der Spalte \"Jahr\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358fb4c-6b84-4c72-adc5-ccbd8b98339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus = songkorpus.sort_values(\"Jahr\", ascending=True)\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f9b69-38fb-4bfd-a888-4665790b8976",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nach der Verwendung von `sort_values` lohnt es sich i.d.R., den Index des DataFrames, der ja durch die Sortierung ganz durcheinander geraten ist, zur√ºckzusetzen. Dies k√∂nnen wir mithilfe von `reset_index` tun. Zus√§tzlich spezifizieren wir, dass der alte Index gel√∂scht werden soll (`drop=True`), andernfalls wird er in einer neuen Spalte gespeichert):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4de64-be0e-4c36-91a5-3195503f5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus = songkorpus.reset_index(drop=True)\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb9b5f-cceb-4d53-b8b5-244d9b719cf8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "W√ºrden wir den Index nicht zur√ºcksetzen, bek√§men wir beim Zeilenzugriff √ºber `loc` u.U. nicht die Ergebnisse zur√ºck, die wir erwarten. Etwa erhielten wir √ºber `songkorpus.loc[0]` nicht die erste Zeile des neuen DataFrames zur√ºck, sondern die erste Zeile des alten, unsortierten DataFrames. Das liegt daran, dass Zeilen ihre Indizes bei der Sortierung standardm√§√üig behalten. Dieses Verhalten wird verst√§ndlicher, wenn Du Dir vorstellst, Du w√ºrdest `songkorpus_labelled_rows` sortieren. \n",
    "\n",
    "Wenn wir weder an der H√§ufigkeitsverteilung aller Werte in einer bestimmten Spalte (`value_counts`), noch an deren Reihenfolge (`nlargest`, `nsmallest` und `sort_values`) interessiert sind, sondern an der blo√üen Existenz eines Wertes (egal wie oft er auftritt), gibt es eine weitere praktische Methode.\n",
    "\n",
    "## Einzigartige Werte\n",
    "\n",
    "N√§mlich `unique`, das √§hnlich wie die Python-Funktion `set` (vgl. zweites Notebook) alle einzigartigen Werte in einer bestimmten Spalte zur√ºckgibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfab86-b49e-4d2c-bfba-ebc551019d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Jahr\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb0168-7550-4e4c-9e66-83b11b75b70f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 8:** Wir wissen bereits, wieviele Tokens in unserem DataFrame vorkommen, n√§mlich 386.510. Finde heraus, wieviele einzigartige Token, also Types (vgl. viertes Notebook) es gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f90df-1ee0-446d-a810-291caaf8e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6807ea8-319a-42b1-a7d0-986eccf77a1b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "## DataFrame filtern \n",
    "\n",
    "Als n√§chstes wollen wir herausfinden, wie wir ein DataFrame filtern k√∂nnen. Die grundlegende Syntax sieht wie folgt aus:\n",
    "\n",
    "`DataFrame[filter]`\n",
    "\n",
    "`filter` wiederum kann unterschiedlich ausschauen, je nach dem, wie wir unser DataFrame filtern wollen. Ein einfaches Beispiel f√ºr `filter` sieht so aus:\n",
    "\n",
    "`DataFrame[column] == value`\n",
    "\n",
    "Dieser Filter verlangt, dass bei `DataFrame` in der Spalte `column` exakt der Wert `value` steht.\n",
    "\n",
    "F√ºgen wir diesen Filter in der obigen Syntax ein und schaffen ein Sub-DataFrame, das alle Zeilen des `songkorpus` beinh√§lt, in denen in der Spalte `Token` das Wort \"Liebe\" steht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbaea10-a71a-4175-9d79-556f021cde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "liebe = songkorpus[songkorpus[\"Token\"] == \"Liebe\"]\n",
    "liebe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67aeef-7a83-4d63-b6a5-7a4a79c0f1f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das klappt wunderbar. Spiel gerne mit anderen Begriffen herum.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 9:** Erstelle ein Sub-DataFrame, das nur Tokens beinh√§lt, die mindestes 20 Zeichen lang sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9eeb7a-1896-46a0-8bd9-0515b00678f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa95c1-5f3d-4af9-9e3c-31e3b8f303c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Abgsehen von Vergleichsoperatoren (`==`, `!=`, `>`, `<`, `>=` und `<=`, vgl. erstes Notebook) bei numerischen Werten (alle Operatoren) bzw. strings (nur die ersten beiden) k√∂nnen wir bei strings auch andere Methoden in den Filter einbauen. Pandas bietet sowohl solche an, die wir bereits von gew√∂hnlichen strings kennen (vgl. viertes Notebook), als auch ein paar eigene. Wichtig ist, dass die Methoden die Boolschen Werte `True` oder `False` zur√ºckgeben. Das hei√üt, `startswith` funktioniert, `split` hingegen nicht. String-Methoden bei pandas beginnen immer mit `str`, gefolgt von der Methode, also etwa `str.startswith()`. Au√üerdem m√ºssen wir ihnen in einigen F√§llen den Parameter `na=False` √ºbergeben. Hier ein paar Beispiele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17553cc2-c465-4b85-a8b7-ab91ea46fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "liebe_startswith = songkorpus[songkorpus[\"Token\"].str.startswith(\"liebe\", na=False)] #wie normale string-Methode in Python\n",
    "liebe_endswith = songkorpus[songkorpus[\"Token\"].str.endswith(\"liebe\", na=False)] #wie normale string-Methode in Python\n",
    "liebe_contains = songkorpus[songkorpus[\"Token\"].str.contains(\"liebe\", na=False)] #pandas-eigene Methode\n",
    "\n",
    "print(len(liebe_startswith), len(liebe_endswith), len(liebe_contains))\n",
    "liebe_contains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ab133-bfee-479e-b80c-6ac37ad4dc7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 10:** Erstelle das gleiche Sub-DataFrame wie in √úbung 9 (also eines, das nur Tokens beinh√§lt, die mindestes 20 Zeichen lang sind), allerdings ohne dabei die Spalte \"L√§nge\" zu bem√ºhen. Du kannst dazu eine Methode verwenden, die auch bei normalen strings funktioniert. Stelle sicher, dass die Ergebnisse der beiden √úbungen identisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b0b58-14b6-49b6-b4a6-c2117b34fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9839a9-fcf7-42cd-88d2-7492a17e1fbf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Gut zu wissen: Filter k√∂nnen auch miteinander kombiniert werden. Dazu verwenden wir die logischen Operatoren aus dem vierten Notebook, die bei pandas allerdings in einem anderen Gewand daherkommen:\n",
    "\n",
    "- `&` steht f√ºr f√ºr `and`\n",
    "- `|` steht f√ºr `or` \n",
    "\n",
    "Au√üerdem steht `~` steht f√ºr `not` und kann zur Negation eines in runde Klammern gesetzten, einzelnen Filters benutzt werden.\n",
    "\n",
    "Unter Verwendung von `&` k√∂nnen wir beispielsweise alle (potenziellen) regelm√§√üigen Partizip II-Formen extrahieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97271f58-6d35-438c-ab3d-fecc5ec97824",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[songkorpus[\"Token\"].str.startswith(\"ge\", na=False) & songkorpus[\"Token\"].str.endswith(\"t\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4bb00-3246-4568-98ab-a75e1caf9e2b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Bedenke, dass auch falsch positive Ergebnisse dabei sein k√∂nnten sowie, dass falsch negative fehlen k√∂nnten (vgl. f√ºnftes Notebook).\n",
    "\n",
    "Nun wissen wir, wie wir ein DataFrame filtern k√∂nnen. \n",
    "\n",
    "## Werte z√§hlen\n",
    "\n",
    "Dieses Wissen k√∂nnen wir auch einsetzen, um spezifische Werte ‚Äì im Gegensatz zu allen Werten wie bei `value_counts` oben ‚Äì in einer Spalte auszuz√§hlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffe10b-df4a-4eed-ac55-88c91351cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(songkorpus[songkorpus[\"Token\"] == \"Wunderkind\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa962672-ed81-4900-bad3-9f7a93f41564",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir filtern also das DataFrame (\"alle Zeilen, in denen 'Wunderkind' in der Spalte 'Token' steht\") und lassen uns ganz einfach seine L√§nge (sprich die Anzahl an Zeilen) ausgeben.\n",
    "\n",
    "## Werte bearbeiten\n",
    "\n",
    "Auch zum Bearbeiten von Werten ben√∂tigen wir nur bereits erlerntes Wissen. Grunds√§tzlich k√∂nnen wir alles von einem kompletten DataFrame, √ºber eine Series (in Form einer Spalte oder Zeile) bis hin zu einzelnen, spezifischen Werten bearbeiten. \n",
    "\n",
    "Die M√∂glichkeiten der Bearbeitung h√§ngen nat√ºrlich vom Datentyp der Werte ab. In unserem DataFrame haben wir einerseits strings und andererseits numerische Werte und Spalten weisen jeweils einen homogen Datentyp auf.\n",
    "\n",
    "Die Logik ist unabh√§ngig davon, was wir wie bearbeiten, immer die gleiche: Wir greifen auf den gew√ºnschten Ausschnitt des DataFrames zu (s.o.) und √ºberschreiben ihn mit demselben Ausschnitt in bearbeiteter Form. Anstatt √úberschreiben k√∂nnen wir die bearbeiteten Werte nat√ºrlich immer auch einer neuen Spalte oder Zeile (desgleichen oder eines neuen DataFrames) zuweisen, sofern die jeweiligen Dimensionen √ºbereinstimmen  (s.o.). \n",
    "\n",
    "### Strings\n",
    "\n",
    "Auf strings angewandt, sieht das so aus, wenn wir etwa alle Tokens kleinschreiben wollen. Auch hier setzen wir `str` vor die pandas-string-Methode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ccb6-4b3b-433e-a3c9-1f362c480f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Token\"] = songkorpus[\"Token\"].str.lower()\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff80b29-37ca-407d-8f47-f498622ae901",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Diese einzeilige Syntax hat es in sich: Man kann sie sich in gewohnter Python-Logik wie eine Iteration vorstellen: Im vorliegenden Fall wird Wort f√ºr Wort (in der Spalte \"Token\") kleingeschrieben. Mit dem Resultat wird die Spalte √ºberschrieben. Sie ist dennoch nicht mit einer List Comprehension, die ja auch nur eine einzige Zeile ben√∂tigt, zu verwechseln. Denn im Gegensatz zu pythonischen `for`-Loops und ihre simplifizierte Version List Comprehension, wird der Code mit der pandas-eigenen Syntax oft wesentlich schneller berechnet (teils √ºber 1000 Mal schneller!). Grund daf√ºr ist die sog. *Vektorisierung*. Ganz einfach forumuliert wird dabei dieselbe Operation nicht auf ein Element nach dem anderen angewandt (wie bei `for`-Loops), sondern auf mehrere gleichzeitig. Au√üerdem sind pandas-Operationen im Gegensatz zu nativem Python-Code (`for`-Loops) speziell auf Effizienz ausgelegt. Wenn Du Dich daf√ºr interessierst, findest Du u.a. in [diesem Artikel](https://medium.com/analytics-vidhya/understanding-vectorization-in-numpy-and-pandas-188b6ebc5398) und [diesem Video](https://www.youtube.com/watch?v=nxWginnBklU) Ankn√ºpfungspunkte. Weiter unten folgen √úbungen zum Vergleich von nativem Python-Code und pandas-Code.\n",
    "\n",
    "Zus√§tzlich zu den bisher verwendeten string-Methoden `lower`, `startswith`, `endswith` und `len` bietet pandas u.a. folgende an, die allesamt wie ihre nativen Python-Pendants funktionieren (vgl. viertes Notebook): \n",
    "- `upper`, `capitalize`, `swapcase`, `isupper` und `islower` zur Bearbeitung/√úberpr√ºfung von Gro√ü-/Kleinschreibung der strings.\n",
    "- `split` zum Splitten der strings, optional mit dem Parameter `expand=True`, um jedem unterteilten Element eine neue Spalte zuzuweisen.\n",
    "- `replace` zum Ersetzen aller Vorkommen eines strings/regul√§ren Ausdrucks (hier zus√§tzlich `regex=True` spezifizieren) mit einem anderen string.\n",
    "- `count` zum Berechnen der Auftretensh√§ufigkeit eines strings/regul√§ren Ausdrucks in den strings.\n",
    "- `strip`, `lstrip` und `rstrip` zum Entfernen von (leading/trailing) whitespace in den strings.\n",
    "\n",
    "Neben `contains` (s.o.) ist au√üerdem `slice` eine n√ºtzliche pandas-string-Methode, die abweichend von ihrem nativen Python-Pendant hei√üt: `slice` mit den Argumentenen `start`, `stop`, `step` implementiert die Funktionalit√§t der eckigen Klammern, die wir bei normalen Python-strings zum Slicen verwenden.\n",
    "\n",
    "[Hier](https://pandas.pydata.org/docs/user_guide/text.html) findest Du mehr Infos zu s√§mlichen string-Methoden bei pandas. Denke stets daran, `str` vor die jeweilige string-Methode zu h√§ngen!\n",
    "\n",
    "Eine letzte praktische Methode ist `isin(list)`. Sie √ºberpr√ºft, ob ein Wert Element der √ºbergebenen Liste ist und gibt eine Series mit Boolschen Werten zur√ºck. `isin` l√§sst nicht nur bei strings anwenden, deshalb h√§ngen wir auch kein `str` davor.\n",
    "\n",
    "### Numerische Werte\n",
    "\n",
    "Bei numerischen Werten wiederum k√∂nnen wir ganz einfach arithmetische Operatoren (vgl. erstes Notebook) verwenden, etwa um alle Werte einer Spalte zu verdoppeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e7c6b-7ad5-4e90-8d23-e5b3e229fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f√ºhre diese Zeile nur einmal aus, denn mit jedem Mal verdoppeln sich die Werte\n",
    "songkorpus[\"H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] * 2\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e1f9c-5293-42eb-85da-611bfc6702b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Hierf√ºr funktionieren auch die anderen uns bekannten arithmetischen Operatoren: ```+``` f√ºr Addition (eignet sich √ºberdies zur Konkatenation von strings), ```-``` f√ºr Subtraktion,  ```/``` f√ºr Division und ```**``` f√ºrs Potenzieren. \n",
    "\n",
    "### Datentyp √§ndern\n",
    "\n",
    "Sollten Werte mal im falschen Datentyp vorliegen, kann man (sofern sinnvoll) die Methode `astype` verwenden, um Werte in den gew√ºnschten Datentyp zu casten. Wenn wir z.B. die H√§ufigkeiten wieder in den Originalzustand versetzen wollen, k√∂nnen wir erst alle Werte in der entsprechenden Spalte halbieren..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29624f0-fe1f-41da-a5ae-17ce0110f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] / 2\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af036cd4-6bae-4eba-b55f-ed5ddbf0482e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "...und, da Resultat einer Division immer Dezimalzahlen sind (s. Nachkommastelle), anschlie√üend in Ganzzahlen casten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ebc2f-1200-45d0-92b1-b12403c87a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"].astype(int)\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27d54d-3a15-485b-8fd4-0accd4c6080c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 11:** Oben haben wir die Spalte \"Jahrzehnt\" basierend auf den Jahreszahlen mithilfe eines `for`-Loops geschaffen. Gehe abermals von der Spalte \"Jahr\" aus, um eine neue Spalte \"Jahrzehnt_ohne_Loop\" zu schaffen, allerdings ‚Äì wie der Name verr√§t ‚Äì ohne daf√ºr einen Loop, auch nicht in Form einer List Comprehension, zu benutzen. Mit anderen Worten: Du sollst Pandas-Syntax daf√ºr einsetzen. Wenn Dein Code stimmt, ergibt die bereits geschriebene (derzeit auskommentierte) Zeile `True`.\n",
    "\n",
    "üí° Tipp: Es sind dieselben einzelnen Schritte wie im `for`-Loop oben n√∂tig, allerdings formuliert in pandas-Syntax. Gegebenfalls musst Du in der [pandas-Dokumentation](https://pandas.pydata.org/docs/) nachschlagen, wie die jeweilige Syntax der pandas-Pendants ausschaut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660cf89-9950-4363-9134-de1f5c300c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n",
    "#print(songkorpus[\"Jahrzehnt\"].equals(songkorpus[\"Jahrzehnt_ohne_Loop\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadd3d4-40b6-4ae7-8bbd-7603fbee5b29",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Sehr gut! Die simple Iteration von oben, die s√§mtliche Werte nacheinander auf dieselbe Weise bearbeitet, k√∂nnen wir also auch ganz einfach in vektorisierter Form nachbilden. \n",
    "\n",
    "### Bedingte Bearbeitung\n",
    "\n",
    "`for`-Loops bieten aber nat√ºrlich viel mehr Funktionalit√§t. Etwa k√∂nnen wir bedingte Anweisungen einbauen, sodass die Werte je nach Bedingung unterschiedlich bearbeitet werden. Aber auch daf√ºr bietet pandas, oder besser gesagt *numpy* (eine weitere Bibliothek, die eng mit pandas verwoben ist) eine Funktion, die sich Vektorisierung zunutze macht. Auch numpy m√ºssen wir erst importieren (ggf. sogar noch zuerst installieren, s.o.), g√§ngigerweise weisen wir der Bibliothek den Namen `np` zu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e5127-ebbc-480f-a27a-6334231dd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0191b-5ebf-41fa-be6c-030a7409ddcb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Funktion hei√üt `where` und hat folgende Syntax:\n",
    "\n",
    "`where(if, then, else)`\n",
    "\n",
    "Als erstes Argument (\"if\") spezifizieren wir eine bedingte Anweisung, die bei jedem Wert entweder `True` oder `False` ergibt. Im Falle von `True` wird der Wert wie im zweiten Argument (\"then\") angegeben eingetragen bzw. bearbeitet. Andernfalls greift, was wir als drittes Argument (\"else\") definiert haben. \n",
    "\n",
    "Angenommen wir m√∂chten zus√§tzlich zur Spalte \"Jahrzehnt\" eine Spalte \"Jahrhundert\", k√∂nnen wir `where` folgenderma√üen dazu einsetzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702bd48-8582-45df-aea3-3d91288c86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vor where steht wie gewohnt der Modulname, damit Python wei√ü, wo sich die Funktion befindet\n",
    "songkorpus[\"Jahrhundert\"] = np.where(songkorpus[\"Jahr\"] < 2000, \"20. Jhd.\", \"21. Jhd.\")\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f9267-ec62-4128-bbce-aa318ddd5c38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sehr gut! Bedenke, dass die Begriffe `if` und `else`, die wir bei bedingten Anweisungen in normalem Python verwenden, nicht ben√∂tigt werden. Die Logik ergibt sich einzig √ºber die Reihenfolge der Argumente in `where`.\n",
    "\n",
    "In diesem Fall haben wir als \"then\" bzw. \"else\" ganz einfach strings √ºbergeben, die je nach dem in der neuen Spalte \"Jahrhundert\" eingetragen wurden. In der folgenden √úbung wollen wir bei \"then\" und \"else\" bestimmte Werte in der jeweilige Zeile bearbeiten.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 12:** Bearbeite die Werte in der Spalte \"Token\" so, dass jedes Wort, das aus genau f√ºnf Buchstaben besteht, gro√ügeschrieben wird. Einfach weil wir's k√∂nnen! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf54a3-1a1e-4e43-b364-1bf5e4287536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6175bc6-2b4f-4980-9c84-56622b32c049",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Super! \n",
    "\n",
    "F√ºr den Fall, dass Du mehrere bedingte Anweisungen aneinanderh√§ngen willst (`if`-`elif`-...-`else`) kannst Du statt `where` die Numpy-Funktion `select` benutzen. Wir setzen sie weiter unten noch ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d5f67-d86c-4e59-8d37-bc65bc376e13",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### `apply` und `applymap`\n",
    "\n",
    "Wie erw√§hnt ist die vektorisierte Art der Datenbearbeitung in pandas meistens √§u√üerst effizient. Es gibt aber F√§lle, in denen wir dennoch eine Funktion mit nativem Python-Code anwenden wollen. Entweder, weil pandas die ben√∂tigen Operationen nicht implementiert, oder weil es mit nativem Python-Code trotz allem effizienter ist (dazu gleich mehr).  \n",
    "\n",
    "In jedem Fall bieten die Methoden `apply` und `applymap` die M√∂glichkeit, jede beliebige Funktion (und in der Verl√§ngerung auch jede beliebige Methode) auf eine Series oder gleich ein ganzes DataFrame anzuwenden. `apply` verwenden wir bei einer Series, `applymap` bei einem ganzen DataFrame. Angeh√§ngt an die Series bzw. das DataFrame √ºbergeben wir ihnen schlicht den Namen der gew√ºnschten Funktion. Es spielt keine Rolle, ob die Funktion aus der Grundausstattung von Python stammt, importiert wurde oder von Dir selbst geschrieben ist.\n",
    "\n",
    "Machen wir es konkret, und zwar in zwei kleinen Experimenten. Wir wollen die gleiche Art der Datenbearbeitung je einmal vektorisiert implementieren, und einmal √ºber eine eigene Funktion, die wir mithilfe von `apply` auf die Daten *appli*zieren. Zum Verst√§ndnis: Rufen wir eine Funktion √ºber `apply` (oder `applymap`) auf, wird dieser wie bei einem `for`-Loop *Wert f√ºr Wert* √ºbergeben. Will hei√üen: Bei `apply` k√∂nnen wir nicht von der Verarbeitung mehrerer Daten auf einmal profitieren.\n",
    "\n",
    "F√ºr das erste Experiment rufen wir ein DataFrame ins Leben, das aus einer Million Zeilen und zwei Spalten, \"A\" und \"B\", besteht. Das DataFrame bef√ºllen wir mit zuf√§lligen Zahlen zwischen 0 und 100 (unter Verwendung der numpy-Funktion `random.randint`). Insgesamt also ein ziemlich gro√ües DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4b763-4d31-4414-9e88-79083498ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = pd.DataFrame(np.random.randint(0,100, size=(1000000,2)), columns=[\"A\", \"B\"])\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f16227-f17c-4cab-b396-274dca988365",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun wollen wir eine dritte Spalte \"C\" schaffen, die ganz einfach das jeweilige Produkt der Werte in den Spalten \"A\" und \"B\" enth√§lt. In der ersten Zelle unten tun wir dies auf vektorisierte Weise, in der zweiten mithilfe einer eigenen Funktion und `apply`. Um zu messen, wie lange das jeweils dauert, verwenden wir das `time`-Modul aus der Grundausstattung von Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97446a0-b890-4816-aa17-df491ddee17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vektorisiert\n",
    "import time\n",
    "start = time.time() #Zeit zum Startpunkt\n",
    "\n",
    "exp1[\"C\"] = exp1[\"A\"] * exp1[\"B\"]\n",
    "vectorized = time.time()-start #Zeit nach Beendigung der Berechnung minus Startzeit, ergibt Dauer\n",
    "\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd67e62-30d2-4800-9038-7aac3feba728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for-Loop\n",
    "start = time.time() #Zeit zum Startpunkt\n",
    "\n",
    "def multiply(row):\n",
    "    return row[\"A\"]*row[\"B\"]\n",
    "\n",
    "#dem Funktionsnamen (hier: multiply) folgen keine Klammern!\n",
    "#axis=1 spezifiziert, dass wir die Funktion auf Spalten anwenden (s.o.)\n",
    "exp1[\"C\"] = exp1.apply(multiply, axis=1) \n",
    "\n",
    "for_loop = time.time()-start #Zeit nach Beendigung der Berechnung minus Startzeit, ergibt Dauer\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b726e8a8-12c5-4559-842e-6f87f2545fe3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die effektive Berechnungsdauer h√§ngt von verschiedenen Faktoren ab und variiert auch zwischen mehreren Durchg√§ngen. In jedem Fall aber sollte sich ein gro√üer Unterschied zeigen. Typischerweise ist die vektorisierte Berechnung mehrere Hundert Male schneller als die Verwendung einer eigenen Python-Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e6363-71e0-4bdd-afda-19c291f790df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vektorisiert:\", vectorized, \"\\nfor-Loop\", for_loop, \"\\nFaktor:\", for_loop/vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b742f3f-1e8c-4889-83b2-051d11bf5bb8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sehr eindrucksvoll! \n",
    "\n",
    "Gehen wir zum zweiten Experiment √ºber, indem wir wieder ein DataFrame mit einer Million Zeilen, aber nur einer Spalte, \"Satz\", schaffen. Diesmal bef√ºllen wir das DataFrame mit dem immergleichen string (unter Verwendung der numpy-Funktion `repeat`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef883a-0187-4bac-89c0-e1e84923a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = pd.DataFrame(np.repeat(\"Dies ist ein nicht besonders langer Satz.\", 1000000, axis=0), columns=[\"Satz\"])\n",
    "exp2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d43151-bde7-4ce5-80bc-f37d5bbb9f86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Hier wollen wir ebenfalls eine weitere Spalte schaffen. Sie soll ganz unspektakul√§r die Anzahl an W√∂rtern des jeweiligen strings in der Spalte \"Satz\" enthalten. In diesem konstruierten Beispiel ergibt dies selbstverst√§ndlich immer sieben. Die erste Zelle enth√§lt wieder die vektorisierte pandas-Variante, w√§hrend die zweite √ºber `apply` eine selbst geschriebene Funktion mit Python-Code aufruft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d523cbc-947f-474e-abf9-50c88cad3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vektorisiert\n",
    "start = time.time()\n",
    "\n",
    "exp2[\"L√§nge\"] = exp2[\"Satz\"].str.split().str.len()\n",
    "\n",
    "vectorized = time.time()-start\n",
    "\n",
    "exp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba63d6-76b5-41e7-a3b4-dec71706d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for-Loop\n",
    "start = time.time()\n",
    "\n",
    "def split(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "#dem Funktionsnamen (hier: split) folgen keine Klammern!\n",
    "exp2[\"L√§nge\"] = exp2[\"Satz\"].apply(split)\n",
    "for_loop = time.time()-start\n",
    "\n",
    "exp2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c41862-b0b3-422b-bdc8-079556e8bf33",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Auch hier variieren die effektiven Berechnungszeiten mitunter stark, dennoch sollte sich zeigen, dass in diesem Fall die zweite Variante mit nativem Python-Code und `apply` um einiges schneller berechnet wird, selbst wenn der Faktor nicht gleich eindrucksvoll wie oben ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d7067-9234-43d6-a918-2300c7afbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vektorisiert:\", vectorized, \"\\nfor-Loop\", for_loop, \"\\nFaktor:\", vectorized/for_loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6e33d-dc17-4667-bef8-de111fd2a10c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir k√∂nnen festhalten, dass Vektorisierung bei Zahlen unglaublich effizient ist. Bei der Bearbeitung von strings hinken pandas-Operationen, jedenfalls bei gro√üen Datenmengen, nativem Python-Code hinterher. Es sei denn Du hast riesige Mengen an strings zu bearbeiten, empfiehlt sich der Einsatz von pandas-Operationen der Einheitlichkeit halber i.d.R. dennoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d34365-3889-44c1-8beb-1692f93d1359",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 13:** Caste s√§mtliche Werte in `songkorpus` in strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4fbbc-4a93-43bf-8c64-67de2ac399c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4a23d-dea7-4994-a861-304fe140efde",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "## üîß Anwendungsfall: Wortverlaufskurven visualisieren üìà\n",
    "\n",
    "Im Anwendungsfall f√ºr dieses Notebook wollen wir wie gesagt Wortverlaufskurven visualisieren. Das hei√üt, wir wollen die H√§ufigkeit, mit der ein beliebiges Wort auftritt, √ºber die Zeit hinweg darstellen. F√ºr die vier Personalpronomen \"ich\", \"du\", \"er\" und \"sie\" s√§he das z.B. wie in der kombinierten Grafik unten aus. Die linke Darstellung visualisiert die Daten nach einzelnen Jahren (wie der originale Datensatz), in der mittleren und rechten Darstellung werden die Daten aggregiert nach F√ºnfjahresabschnitten bzw. Zehnjahresabschnitten visualisiert. Einzelne Aussschl√§ge nach oben und unten werden so ausgeb√ºgelt und Trends sind leichter zu erkennen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533d536",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<img src=\"../3_Dateien/Grafiken_und_Videos/Wortverlaufskurve_kombiniert.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abad895-c1c6-4b30-b444-4d1c317a98dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Deine Aufgabe ist es erst einmal, Code zu schreiben, der die linke Grafik f√ºr beliebige W√∂rter produziert. Die erforderliche Aggregation f√ºr die mittlere und rechte Darstellung schauen wir uns im Anschluss an den Anwendungsfall gemeinsam an. \n",
    "\n",
    "Wie im vierten und f√ºnften Notebook hast Du wieder die Wahl, den Anwendungsfall ohne weitere Anleitung in Angriff zu nehmen oder einer Schritt-f√ºr-Schritt-Anleitung zu folgen. In letzterem Fall kannst Du jetzt ans Ende der n√§chsten Code-Zelle springen. Wenn Du es alleine probieren m√∂chstest, dann analysiere das gew√ºnschte Resultat oben links und frage Dich, welche Daten wie und wo visualisiert werden. \n",
    "\n",
    "üí° Tipp 1: Die relativen H√§ufigkeiten pro Wort und Jahr liegen noch nicht in unserem DataFrame vor. Du musst sie also erst ausrechnen. √úberleg Dir genau, wie Du von den existierenden, absoluten H√§ufigkeiten zu den relativen H√§ufigkeiten pro Jahr kommst. Dazu seien zwei n√ºtzliche Methoden erw√§hnt (klicke auf ihren Namen, um zur offiziellen Dokumentation zu gelangen):\n",
    "- [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html): Nach dem Motto \"split-apply-combine\" erlaubt Dir diese Methode, das DataFrame nach den Werten der Spalte \"Jahr\" zu gruppieren (aufzu*split*ten). Indem Du im gleichen Statement die `sum`-Methode auf die Spalte \"H√§ufigkeit\" jedes durch `groupby` entstehenden Sub-DataFrame anwendest (*apply*), erh√§ltst Du eine zusammengef√ºhrte Series (*combine*), die f√ºr jedes Jahr die Summe aller H√§ufigkeiten aller Tokens enth√§lt. Schau Dir diese Series genau an. \n",
    "- [`replace`](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html): Diese Methode l√§sst sich auf eine Series (etwa eine Spalte in unserem DataFrame) anwenden und nimmt u.a. eine zweite Series als Argument (etwa eine durch `groupby([...])[...].sum()` entstandene). `replace` schaut dann, ob sich Indizes der zweiten Series als Werte in der ersten Series befinden und wenn ja, ersetzt sie diese durch die dazugeh√∂rigen Werte aus der zweiten Series. Die dictionary-Analogie von oben macht den Prozess greifbarer: `replace` ersetzt in der Series, auf die sie angewandt wird, Schl√ºssel durch ihre jeweiligen Werte aus der als Argument √ºbergebenen Series. \n",
    "\n",
    "üí° Tipp 2: Mach Dich in der [Dokumentation](https://matplotlib.org/stable/users/index.html) von matplotlib, der Bibliothek zum Visualisieren von Daten, schlau, wie Du die errechneten Werte visualisieren kannst. \n",
    "\n",
    "Beginne in jedem Fall damit, die Datei \"songkorpus.tsv\" neu einzulesen und die Spalten wie am Anfang des Notebooks umzubenennen. Dadurch stellst Du sicher, dass Du auch wirklich mit den urspr√ºnglichen Daten arbeitest.\n",
    "\n",
    "Viel Erfolg! üôå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598a633-a08d-47f7-b15f-15fe300781ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf93902-ed8f-46d5-92f1-c7328bbae3ff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "**Schritt-f√ºr-Schritt-Anleitung**\n",
    "\n",
    "1. Um sicherzugehen, dass wir wirklich mit den originalen Daten arbeiten, lies die Datei \"songkorpus_token.tsv\" abermals ein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf6619-c03c-4368-9853-14146e30377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19277743-8247-406c-8f2d-e9c67cbafee4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "2. Benenne die Spalten in \"Token\", \"Jahr\" und \"H√§ufigkeit\" um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c7d87-77be-4cdb-913b-22e6b745dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba33f5-41c4-40e8-9039-0d091848673b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3. Im DataFrame verf√ºgen wir bislang nur √ºber absolute H√§ufigkeiten. Um die Werte zwischen einzelnen Jahren besser vergleichbar zu machen, wollen wir aber relative H√§ufigkeiten f√ºr die Visualisierung verwenden. Schaffe dazu eine Spalte \"Relative H√§ufigkeit\", die f√ºr jedes Token vermerkt, wie h√§ufig es in Relation zur Summe aller H√§ufigkeiten aller Tokens im gegebenen Jahr vorkommt. F√ºr diese Berechnung brauchst Du jeweils zwei Werte: erstens die absolute H√§ufigkeit (bereits in der Spalte \"H√§ufigkeit\") und zweitens die Summe aller H√§ufigkeiten aller Tokens im gegebenen Jahr.\n",
    "\n",
    "     Verwende die Methode [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) zur Berechnung der Summe aller H√§ufigkeiten pro Jahr. Nach dem Motto \"split-apply-combine\" erlaubt Dir diese Methode, das DataFrame nach den Werten der Spalte \"Jahr\" zu gruppieren (aufzu*split*ten). Indem Du im gleichen Statement die `sum`-Methode auf die Spalte \"H√§ufigkeit\" jedes durch `groupby` entstehenden Sub-DataFrame anwendest (*apply*), erh√§ltst Du eine zusammengef√ºhrte Series (*combine*), die f√ºr jedes Jahr die Summe aller H√§ufigkeiten aller Tokens enth√§lt. Weise die Series der Variablen `total_freq_per_year` zu und inspiziere sie.\n",
    "    \n",
    "    Um nun zur relativen H√§ufigkeit zu gelangen, musst Du f√ºr jedes Token in `songkorpus` den Wert in der Spalte \"H√§ufigkeit\" durch die jeweilige Summe an H√§ufigkeiten im gegebenen Jahr teilen. Da wir letzteren Wert in einer anderen Series (n√§mlich in `total_freq_per_year`) vorliegen haben, m√ºssen wir zu einem Trick greifen: Wende die `replace`-Methode auf die Spalte \"Jahr\" an und √ºbergib ihr `total_freq_per_year`. Wir machen uns hier den Umstand zunutze, dass eine Series wie ein dictionary funktioniert. Will hei√üen: `replace` ersetzt kurzerhand jedes Jahr (Schl√ºssel) durch die jeweilige Summe der H√§ufigkeiten pro Jahr (Wert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f3060-7230-4d82-9814-c5bb08f856ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0e505-b8c3-4308-a51a-f18fcba1a8c3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "4. Installiere ggf. `matplotlib` √ºber das Terminal oder die Eingabeaufforderung und importiere anschlie√üend `matplotlib.pyplot as plt` (wieder so eine g√§ngige Abk√ºrzung). matplotlib ist die Bibliothek, die wir zum Visualisieren unserer Daten verwenden. Mithilfe der Funktion `plot(x, y)` (denk an den Modulnamen davor) k√∂nnen wir einfach Grafiken produzieren. `x` ist dabei eine Liste oder Series an Werten, die auf der x-Achse abgebildet werden sollen und `y` eine Liste oder Series derjenigen Werte, die auf der y-Achse dargestellt werden sollen. `x` und `y` m√ºssen gleich lange sein. Konkret wird der erste Punkt in der Grafik bei den Koordinaten `x[0]` und `y[0]` eingezeichnet, der zweite bei `x[1]` und `y[1]`, etc. Standardm√§√üig werden die einzelnen Punkte wie oben zu einem Graphen verbunden. Schau in den Beispieldarstellungen oben, welche Werte wir entlang der x-Achse bzw. entlang der y-Achsen plotten wollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61f63e-15e9-4ee1-b0ce-5c1146f1120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263d752-d684-49ac-bb5f-58939d2fb96e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "5. Definiere eine Liste an W√∂rtern, die Du visualisieren m√∂chtest. Diesen Schritt kannst Du auch interaktiv umsetzen, sodass Du bei jeder Ausf√ºhrung aufgefordert wirst, W√∂rter zur Visualisierung anzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a60b35-d4d8-4361-adea-c622376562a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481daded-afdd-421b-a33b-9a70b9d2e2fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "6. Plotte nun nacheinander eine Verlaufskurve f√ºr jedes Wort auf der Liste. Gehe dazu f√ºr jedes Wort wie folgt vor:\n",
    "    - Schaffe ein Sub-DataFrame, in dem in der Spalte \"Token\" nur das gegebene Wort steht.\n",
    "    - Sortiere das Sub-DataFrame aufsteigend nach der Spalte \"Jahr\" und setze den Index anschlie√üend zur√ºck.\n",
    "    - √úbergib der `plot`-Funktion die relevanten Spalten des Sub-DataFrames an Stelle von `x` und `y`. √úbergib als drittes Argument den string \"o-\", der den Stil des Graphen (Linie mit Punkten) definiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8158d2-a776-47a5-b96a-6804ec651fc3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "7. Nachdem Du alle W√∂rter der Liste entsprechend geplotted hast, kannst Du **in derselben Zelle** folgende Funktionen verwenden, um den Plot zu verfeinern:\n",
    "    - `title`, um einen Titel zu setzen.\n",
    "    - `xlabel` und  `ylabel`, um die Achsen zu beschriften.\n",
    "    - `xlim`, um der x-Achse Grenzen zu setzen, z.B. von 1969 bis 2022 (dies vereinheitlicht die Plots, da diese sonst automatisch an den Wertebereich der zu plottenden W√∂rter angepasst wird und der Plot dadurch mitunter anders beschnitten sein kann).\n",
    "    - `legend`, um eine Legende einzuf√ºgen, indem Du der Funktion die Liste mit W√∂rtern √ºbergibst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b936a0-3311-4f8f-9ed1-0fcb1611021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5f9c1-4392-43c5-83e5-9508c5b0dbe7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Super! ü§©\n",
    "\n",
    "Bevor wir uns zum Abschluss noch den Output von DataFrames anschauen, wollen wir die Daten wie gesagt zu gr√∂√üeren Zeiteinheiten aggregieren, und zwar zu Zehn- und F√ºnfjahresabschnitten.\n",
    "\n",
    "Auch hier laden wir zur Sicherheit nochmal die originale Datei, benennen die Spalten um und schaffen zus√§tzlich die Spalten \"Jahrzehnt\" und \"Relative H√§ufigkeit\". Letztere wird nach wie vor relativ zur H√§ufigkeit aller Tokens in *einem* Jahr berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5082b5-9fe0-4ac4-b832-54e633a2bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus = pd.read_csv(\"../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\") \n",
    "\n",
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"]\n",
    "\n",
    "#hier verwenden wir im Gegensatz zu oben die pandas-eigene Syntax\n",
    "songkorpus[\"Jahrzehnt\"] = (songkorpus[\"Jahr\"].astype(str).str.slice(0,-1) + \"0\").astype(int) \n",
    "\n",
    "total_freq_per_year = songkorpus.groupby([\"Jahr\"])[\"H√§ufigkeit\"].sum()\n",
    "songkorpus[\"Relative H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] / songkorpus[\"Jahr\"].replace(total_freq_per_year) \n",
    "\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957c305-891f-456a-bc68-1970efbd7037",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Eine Spalte mit sog. *Jahrf√ºnften* k√∂nnen wir nun unter Verwendung von numpys `select` erstellen. Dazu definieren wir zwei Listen, eine mit \"if\"-Bedingungen (etwa \"Wert in Spalte 'Jahr' kleiner als 1970...\") und eine mit \"then\"-Statements (\"...dann setze den Wert 1965 ein\"). Diese Listen √ºbergeben wir der Funktion zusammen mit dem dritten Argument, das ganz einfach im \"else\"-Fall greift. Bedenke, dass die Reihenfolge der Elemente auf den beiden Listen ebenso wie die Reihenfolge von `if`-`elif`-...-Statements in normalem Python-Code entscheidend ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486b827-1685-4c36-87d2-3f06bdbba776",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = songkorpus[\"Jahr\"]\n",
    "if_list   = [x<1970, x<1975, x<1980, x<1985, x<1990, x<1995, x<2000, x<2005, x<2010, x<2015, x<2020] #hier zeigt sich auch, warum wir die Spalte \"Jahr\" oben in Ganzzahlen gecasted haben\n",
    "then_list = [1965, 1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015]\n",
    "songkorpus[\"Jahrf√ºnft\"] = np.select(if_list, then_list, 2020)\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50693c97-d8da-4d46-81fb-b36b7e3445b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun fehlt nur noch der Aggregationsschritt. Bei den jahresbasierten relativen H√§ufigkeiten konnten wir uns ja darauf verlassen, dass jedes Wort nur ein einziges Mal pro Jahr in unserem DataFrame steht, so sind unsere Daten ganz einfach strukturiert. \n",
    "\n",
    "Bei den Jahrf√ºnften und Jahrzehnten kann ein einzelnes Wort hingegen bis zu f√ºnf bzw. zehn Mal vorkommen. Da wir aber nur einen Wert pro Zeitabschnitt plotten wollen, m√ºssen wir s√§mtliche relativen H√§ufigkeiten in einem Jahrf√ºnft bzw. Jahrzehnt aufsummieren und anschlie√üend durch 5 resp. 10 teilen. Dadurch erhalten wir die durchschnittliche relative H√§ufigkeit pro Wort und Zeitabschnitt. \n",
    "\n",
    "Genau dies tun wir im neu eingef√ºgten Aggregationsschritt unten: Wir gruppieren das Sub-DataFrame `word_df` abermals mithilfe von `groupby` nach dem gew√ºnschten Zeitabschnitt (wahlweise Jahrzehnt oder Jahrf√ºnft) und aggregieren die Werte in der Spalte \"Relative H√§ufigkeit\", indem wir sie pro Zeitabschnitt aufsummieren. Anschlie√üend teilen wir die Summe durch die Anzahl an Jahre des Zeitabschnitts (10 oder 5), um den Durchschnitt zu errechnen. Um wirklich nur mit kompletten Jahrf√ºnften bzw. Jahrzehnten zu rechnen, exkludieren wir zu Beginn noch s√§mtliche Tokens in den Jahren 1969, 2020, 2021 und 2022 (die Division durch 5 bzw. 10 w√ºrde ja sonst zu zu kleinen Durchschnitten f√ºhren).\n",
    "\n",
    "Abgesehen vom Aggregationsschritt und dem Ausschluss inkompletter Jahrf√ºnfte bzw. Jahrzehnte, wurde im Code unten die Variable `span` f√ºr die Zeiteinheit eingesetzt, sodass diese neben zu den zu plottenden W√∂rtern initial definiert werden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555eaee6-f59d-41dc-87b2-f030e985eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "span, span_dict = \"Jahrzehnt\", {\"Jahrzehnt\": 10, \"Jahrf√ºnft\": 5}\n",
    "words = [\"ich\", \"du\", \"er\", \"sie\"]\n",
    "\n",
    "#Ausschluss inkompletter Jahrf√ºnfte bzw. Jahrzehnte durch Kombination zweier Filter\n",
    "songkorpus = songkorpus[(songkorpus[\"Jahr\"] > 1969) & (songkorpus[\"Jahr\"] < 2020)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word in words:\n",
    "    word_df = songkorpus[songkorpus[\"Token\"] == word]\n",
    "\n",
    "    \"\"\"NEUER SCHRITT: AGGREGATION\"\"\"\n",
    "    word_df = word_df.groupby([span]).aggregate({\"Relative H√§ufigkeit\": \"sum\"}) / span_dict[span]\n",
    "    \"\"\"NEUER SCHRITT: AGGREGATION\"\"\"\n",
    "    \n",
    "    \n",
    "    word_df = word_df.sort_values(by=span, ascending=True).reset_index()\n",
    "    x = word_df[span]\n",
    "    y = word_df[f\"Relative H√§ufigkeit\"]\n",
    "    plt.plot(x, y, 'o-')\n",
    "\n",
    "plt.title(f\"Wortverlaufskurve f√ºr {', '.join([word for word in words])}\")\n",
    "plt.xlabel(span)\n",
    "plt.ylabel(f\"Relative H√§ufigkeit ({span})\")\n",
    "plt.xlim(1969, 2011) #Anpassen, je nach Zeitabschnitt\n",
    "plt.legend(words, loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57db405-026d-4488-83b2-d1414ac610ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wunderbar. \n",
    "\n",
    "Sollte hier neben dem Plot auch eine `SettingWithCopyWarning` zur√ºckgegeben worden sein, kannst du diese ignorieren.\n",
    "\n",
    "Mit `plt.savefig(path)` kannst Du Grafiken √ºbrigens auch auf Deiner Festplatte speichern.\n",
    "\n",
    "Damit sind wir fast am Ende des Notebooks angelangt.\n",
    "\n",
    "## Output\n",
    "\n",
    "√úbrig bleibt noch, die Methode `to_csv` vorzustellen, die wir verwenden k√∂nnen, um ein DataFrame als kommaseparierte Datei extern zu speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbf3fb-d6b0-46ad-a485-2d8ca2f846d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.to_csv(\"../3_Dateien/Output/songkorpus_new.csv\", sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30eeee-6c91-43d1-af0d-fc6daf64d162",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Neben dem Ausgabepfad k√∂nnen wir das gew√ºnschte Trennzeichen und Encoding spezifizieren. Neben `to_csv` gibt es analog zum Input auch spezifische Output-Methoden f√ºr XML (`to_xml`), JSON (`to_json`) und Excel (`to_excel`).\n",
    "\n",
    "Damit sind wir am Ende des Notebooks angelangt. Gute Arbeit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
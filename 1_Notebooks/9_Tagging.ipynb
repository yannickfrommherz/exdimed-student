{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d36ba4-abc7-4228-ad0d-387c12c9ece2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Tagging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f6fc31-e29c-42cb-8440-8afaf1d8eb48",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In diesem Notebook besch√§ftigen wir uns mit *Tagging*. Beim Tagging (auch *Annotation* genannt) reichern wir Sprachdaten an, indem wir die einzelnen Bestandteile unserer Daten, etwa W√∂rter oder S√§tze, um Zusatzinformationen wie die Wortart oder die durch den Satz ausgedr√ºckte \"Stimmung\" erg√§nzen. Wir versehen sozusagen jedes zu annotierende Element mit einem Schildchen (engl. *tag*), auf dem die Zusatzinformation(en) festgehalten werden.\n",
    "\n",
    "Indem wir unsere Daten taggen, k√∂nnen wir sie leichter auswerten. So k√∂nnen wir z.&nbsp;B. bei nach Wortart annotierten Daten einfach alle Funktionsw√∂rter (Artikel, Pr√§positionen, Konjunktionen, etc.) herausfiltern, um sie gesondert zu untersuchen (z.&nbsp;B. \"Werden in Zeitungstexten die gleichen Konjunktionen verwendet wie in Social Media-Beitr√§gen?\") oder auch, um die Daten bereinigt von diesen inhaltsarmen (Stopp-)W√∂rtern unter die Lupe zu nehmen.\n",
    "\n",
    "Um Sprachdaten zu *taggen*, ben√∂tigen wir einen *Tagger*. F√ºr die meisten Taggingarten stehen uns bei Python gleich mehrere Tagger zu Verf√ºgung. Viele Tagger wiederum beherrschen mehrere Taggingarten. Tagging ist nat√ºrlich sprachabh√§ngig, weshalb wir jeweils einen f√ºr unsere Daten geeigneten Tagger benutzen m√ºssen. Unten lernen wir pro Taggingart einen besonders guten Tagger f√ºr deutschsprachige Daten kennen, z.&nbsp;T. erg√§nzt um Alternativen (s. auch folgende Tabelle).\n",
    "\n",
    "Wir schauen uns in diesem Notebook sechs Arten des Taggings an:\n",
    "\n",
    "| **Art** | **Resultat** | **Beispiel (vereinfacht)** | **Tagger (Auswahl)**\n",
    "|:-:|:-|:-|:-\n",
    "| **Lemmatisierung** | Grundform (sog. *Lemma*) von W√∂rtern, wie sie in einem W√∂rterbuch stehen | W√∂rter<sub> Wort</sub> sind<sub>sein</sub> sch√∂n<sub>sch√∂n</sub> | `HanoverTagger`, `RNNTagger`, `stanza`, `spacy`\n",
    "| **Part-of-Speech-Tagging<br>(POS-Tagging)** | Wortart von W√∂rtern (aber mit feineren Kategorien als in der klassischen Wortartenlehre) | W√∂rter<sub>NN</sub> sind<sub>VVFIN</sub> sch√∂n<sub>ADJD</sub><br><sub>*(NN: Nomen, VVFIN: Finites Verb, ADJD: Adjektiv)*</sub> | `HanoverTagger`, `RNNTagger`, `stanza`, `spacy`\n",
    "| **Morphologisches Tagging** | Informationen zu Flexion und grammatischen Eigenschaften von W√∂rtern  | W√∂rter<sub>Neutrum Nominativ Plural</sub> sind<sub>3. Person Plural Pr√§sens Indikativ</sub> sch√∂n<sub>Positiv</sub> | `RNNTagger`,`stanza`, `spacy`\n",
    "| **Syntaktisches Parsing** | Informationen zum Satzbau  | Ich<sub>Subjekt</sub> liebe<sub>ROOT</sub> W√∂rter<sub>Akkusativobjekt</sub>| `stanza`, `spacy`\n",
    "| **Named Entity Recognition** | Identifikation von Eigennamen (Personen, Orte, Institutionen, etc.) | [Peter Meier]<sub>Person</sub> arbeitet beim [Bundesgerichtshof]<sub>Institution</sub> in [Karlsruhe]<sub>Ort</sub> | `stanza`, `spacy`\n",
    "| **Sentiment Analysis** | \"Stimmung\" eines Satzes oder Texts | [W√∂rter sind sch√∂n]<sub>positiv</sub><br>[Peter mag seinen aktuellen Fall nicht]<sub>negativ</sub> | `germansentiment`, `stanza`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c86b46-2932-4f20-823f-06f9ffd9f2f9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das eigentliche Tagging ist jeweils sehr unkompliziert ‚Äì einzig die richtige Syntax muss man kennen. Die √úbungen in diesem Notebook umfassen deshalb neben dem Taggingschritt auch die Auswertung getaggter Daten. Dazu verwenden wir gr√∂√ütenteils `pandas`. Dieses Notebook bietet Dir also auch eine gute Gelegenheit, Deine Datenanalyse-Skills auszubauen.\n",
    "\n",
    "## Allgemein\n",
    "\n",
    "Tagger k√∂nnen grunds√§tzlich entweder regelbasiert oder statistisch operieren. **Regelbasierte Tagger** f√§llen ihr Urteil (\"Welche Wortart ist 'Bundesgerichtshof'?\") anhand von festgelegten Regeln (etwa \"Gro√ügeschriebene W√∂rter sind Nomen\"). **Statistische Tagger** dagegen werden mit vielen Daten trainiert. Sie errechnen basierend darauf, wie wahrscheinlich ein bestimmtes Tag f√ºr ein zu taggendes Element ist und verleihen ihm ‚Äì vereinfacht formuliert ‚Äì¬†dasjenige mit der h√∂chsten Wahrscheinlichkeit. Unabh√§ngig von der Implementierung eines Taggers, liegt ihm jeweils ein **Tagset** zugrunde. Dieses umfasst alle m√∂glichen Tags, die \"vergebbar\" sind. Beim Part-of-Speech-Tagging im Deutschen ist z.&nbsp;B. das [Stuttgart-T√ºbingen-TagSet](https://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/germantagsets/#id-cfcbf0a7-0) (kurz *STTS*) g√§ngig (die Tags in der Tabelle oben stammen auch daraus).\n",
    "\n",
    "Ebenfalls unabh√§ngig von der Implementierung eines Taggers, ist die Tatsache, dass der Output nicht *per se* korrekt ist, sondern nur die Regeln bzw. Trainingsdaten widerspiegelt. Je mehr unsere Daten von regelhafter Standardsprache bzw. den Trainingsdaten abweichen, desto weniger zuverl√§ssig wird die darauf basierende Annotation unserer Daten ausfallen. In jedem Fall empfiehlt es sich stets, den Output von (verschiedenen) Taggern manuell zu evaluieren.\n",
    "\n",
    "Auch in diesem Notebook gibt es einen Anwendungsfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9475a3c-82de-44a6-8cb3-f713ef48a150",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "## üîß Anwendungsfall: (D)ein Korpus taggen üè∑Ô∏è\n",
    "\n",
    "Diesmal hast Du die Gelegenheit, Deine eigenen Daten zu taggen. Vielleicht hast Du inspiriert vom Notebook \"Web Scraping\" Dein eigenes Korpus zusammengestellt? Wenn nicht, kannst Du einen beliebigen anderen Text taggen, etwa eine fr√ºhere schriftliche Arbeit von Dir. Wichtig ist einzig, dass Deine Daten in einem f√ºr Python einlesbaren Format vorliegen, idealerweise mit der Endung \".txt\" (s. aber in den Zusatz√ºbungen zum Notebook \"Input und Output\", wie Word-Dateien mit der Endung \".docx\" bei Python eingelesen werden k√∂nnen). Dir ist freigestellt, mit welchen Zusatzinformationen Du Deine Daten anreicherst. Lemmatisierung und POS-Tagging sind aber meistens sinnvoll.\n",
    "\n",
    "In den L√∂sungen wird ein Musteranwendungsfall bearbeitet. Konkret soll die Verteilung von POS-Tags in Beh√∂rdentexten in Standardsprache versus Leichter Sprache untersucht werden. F√ºr dieses kleine Projekt wird neben dem eigentlichen Tagging auch der vorgelagerte Datenbeschaffungsschritt (Web Scraping) sowie die nachgelagerte Analyse und Visualisierung der Ergebnisse demonstriert. Schau Dir die L√∂sung zu diesem Musteranwendungsfall an, auch wenn Du Dein eigenes Korpus taggst ‚Äì m√∂glicherweise erh√§ltst Du so wertvolle Anhaltspunkte und Inspiration.\n",
    "\n",
    "Den Anwendungsfall bearbeitest Du am Ende des Notebooks.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845bd1d-4191-4f8d-b40e-7b197dcc2e2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Installation \n",
    "\n",
    "Bevor wir loslegen, installieren wir s√§mtliche in diesem Notebook verwendeten Module √ºber die folgende Code-Zelle. Anstatt den uns bekannten Weg √ºber die Command Line, nutzen wir die Datei \"requirements.txt\", die spezifiziert, welche externen Module in diesem Notebook ben√∂tigt werden (sog. *dependencies*, also Module, von denen die Ausf√ºhrbarkeit dieses Notebooks *abh√§ngt*). Bei gr√∂√üeren Code-Projekten geh√∂rt es dazu, eine solche Datei mitzuliefern. \n",
    "\n",
    "Die Ausf√ºhrung der Zelle nimmt einige Zeit in Anspruch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2717c-4af4-4416-bc0c-952fe8d36b75",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Durch das vorangestellte Ausrufezeichen k√∂nnen wir Befehle an die Command Line auch innerhalb eines Notebooks ausf√ºhren.\n",
    "!pip3 install -r \"../3_Dateien/Tagging/requirements.txt\" \n",
    "\n",
    "#Solltest Du nach Ausf√ºhren dieser Zelle weiter unten unerwarteterweise auf einen 'ModuleNotFoundError' sto√üen,\n",
    "#dann f√ºhr statt dem obigen Code den folgenden aus:\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install -r \"../3_Dateien/Tagging/requirements.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff9341-bb3c-43b8-8cd3-72ed08b0ec7b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Scroll durch den Output und stell sicher, dass die Installation s√§mtlicher Module erfolgreich war.\n",
    "\n",
    "Wenden wir uns nun den einzelnen Taggingarten zu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53288711-8954-46bb-8a30-f7a0dba31709",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Lemmatisierung\n",
    "\n",
    "Bei der Lemmatisierung werden nach Genus, Kasus, Tempus etc. flektierte Wortformen auf ihre Grundform bzw. ihr Lemma (Plural: *Lemmata*), wie wir sie in einem W√∂rterbuch finden w√ºrden, reduziert. Bei der Wortform \"H√§user\" w√§re das Resultat etwa \"Haus\". Insbesondere bei stark flektierten Sprachen wie dem Deutschen ist Lemmatisierung etwa bei der Ausz√§hlung von W√∂rtern interessant, zumal wir eher (wenn auch nicht immer) wissen wollen, wie h√§ufig das Verb \"brauchen\" in einem bestimmten Text vorkommt, als die H√§ufigkeiten seiner flektierten Formen separat zu erfahren (\"brauchte\", \"br√§uchtest\", \"gebraucht\" etc.). \n",
    "\n",
    "In vielen F√§llen ist die Reduktion von Wortform zu Lemma eindeutig. Bei Homographen (gleichgeschriebene W√∂rter wie \"sein\" [Verb] und \"sein\" [Possessivpronomen zu \"er\"]), Eigennamen (\"Herr Finkenm√ºller\"), ungebr√§uchlichen Komposita (\"Programmierenlernen\") oder trennbaren Verben (\"<u>Ruf</u> mich <u>an</u>\") bestehen allerdings Fehlerquellen, die es im Blick zu behalten gilt.\n",
    "\n",
    "Zur Lemmatisierung eignet sich u.&nbsp;a. das Modul [`HanoverTagger`](https://serwiss.bib.hs-hannover.de/frontdoor/deliver/index/docId/2457/file/wartena2023-HanTa_v1.1.0.pdf), das wir in der folgenden Code-Zelle importieren und `ht` zuweisen. Anschlie√üend w√§hlen wir das deutsche Sprachmodell und weisen es `ht_tagger` zu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83936892-de0c-457a-b2ae-d7a622c61f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from HanTa import HanoverTagger as ht\n",
    "\n",
    "#Der 'HanoverTagger' stellt auch ein Modell f√ºr Englisch und Niederl√§ndisch zur Verf√ºgung, vgl. https://github.com/wartaal/HanTa/tree/master.\n",
    "ht_tagger = ht.HanoverTagger('morphmodel_ger.pgz') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cba992-e15e-4cdd-98ea-08ea95fed311",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das wollen wir gleich mal ausprobieren und zwar an einem l√§ngeren Text. Wir nutzen dazu das M√§rchen \"Des Kaisers neue Kleider\", das wir auch im Notebook \"Regul√§re Ausdr√ºcke\" bearbeiten. Zun√§chst lesen wir es ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cff1b-7594-4d3c-9b59-7765552752cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../3_Dateien/Des_Kaisers_neue_Kleider/Des_Kaisers_neue_Kleider.txt\") as f:\n",
    "    fairytale = f.read()\n",
    "    \n",
    "print(fairytale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38e1dc-0855-473e-b39a-d1112055f084",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Auf `ht_tagger` k√∂nnen wir nun die Methode `tag_sent` anwenden, der wir eine Liste mit W√∂rtern √ºbergeben m√ºssen. Wie wir selbst lange Texte (nach unseren eigenen Vorstellungen flexibel) tokenisieren k√∂nnen, haben wir im Notebook \"Funktionen und Methoden\" gelernt. Hier verwenden wir den Einfachheit halber die Funktion `word_tokenize` des Moduls `nltk` (f√ºr <u>N</u>atural <u>L</u>anguage <u>T</u>ool<u>k</u>it) zur Tokenisierung unseres M√§rchens. Die Liste mit W√∂rtern lassen wir direkt im Anschluss taggen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c90c8-76f2-46c8-8a60-0acbde057bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "fairytale_tokenized = nltk.word_tokenize(fairytale) #Tokenisierung\n",
    "\n",
    "fairytale_output_ht = ht_tagger.tag_sent(fairytale_tokenized) #Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926cdb4-c0f0-4b2a-90c4-55bcbebae5f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Werfen wir einen Blick in den Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8192ac1-3a86-47a9-9825-392c4b829d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairytale_output_ht[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a3d30-b666-44a0-a4cc-6d3b3cc2dcf4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wie wir sehen, gibt uns der `HanoverTagger` f√ºr jedes Wort ein Tupel zur√ºck, bestehend aus der ungetaggten Wortform, dem Lemma sowie ebenfalls dem POS-Tag ‚Äì letzteres kriegen wir \"frei Haus\" mitgeliefert.\n",
    "\n",
    "Ein Output dieser Art l√§sst sich wunderbar in ein DataFrame von `pandas` √ºbertragen (vgl. Notebook \"Datenanalyse\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88510930-9e53-41b0-8d47-727aea0dfdce",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 2500 #Erh√∂hen der maximal angezeigten Anzahl an Zeilen auf 2500\n",
    "\n",
    "fairytale_df_ht = pd.DataFrame(fairytale_output_ht, columns=['Wortform', 'Lemma', 'POS'])\n",
    "\n",
    "fairytale_df_ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74744a8f-1829-44d9-94c0-d26ccfcfa30a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das macht nicht nur die Darstellung ansehnlicher, sondern erleichtert auch anschlie√üende Auswertungen enorm. So k√∂nnen wir uns z.&nbsp;B. ganz einfach die h√§ufigsten Lemmata oder die Frequenz eines bestimmten Lemmas ausgeben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d435d30-4b9b-42e9-847b-d6d08cc04e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fairytale_df_ht.Lemma.value_counts().head(), \"\\n\") #H√§ufigste Lemmata mithilfe von 'value_counts' und 'head'\n",
    "print(len(fairytale_df_ht[fairytale_df_ht.Lemma == \"Kaiser\"])) #H√§ufigkeit eines bestimmten Lemmas mithilfe von Filter und 'len'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336bdc8-2266-4daf-880f-697e67e19263",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das Lemma \"Kaiser\" kommt also insgesamt 24 Mal vor. Und als Wortform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5557f7-e04e-4843-b937-1bee373458d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fairytale_df_ht[fairytale_df_ht.Wortform == \"Kaiser\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051855d-d51d-454b-b673-b24abd6e90e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenn wir also am Lemma \"Kaiser\" ‚Äì oder anders ausgedr√ºckt: am Konzept ·¥ã·¥Ä…™s·¥á Ä ‚Äì interessiert sind, zeigt sich an diesem Beispiel der Nutzen von Lemmatisierung. Und wie wir gesehen haben, liefert uns der `HanoverTagger` diese Lemmata auf unkomplizierte Weise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb6875-d35a-4b2c-be6f-5e53464aa123",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **√úbung 1:** Lemmatisier den Koalitionsvertrag von 2018, der sich im Ordner \"3_Dateien/Koalitionsvertraege\" befindet. Find dann erstens heraus, welches Lemma am h√§ufigsten darin vorkommt sowie wie oft. Ermittle zweitens, welchen Wortformen dieses h√§ufigste Lemma wie oft entspricht. Da der Koalitionsvertrag recht lang ist, dauert die Ausf√ºhrung des Codes vielleicht etwas l√§nger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446edbd-9192-458b-afb5-147f6fd1b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bac19d-0213-465d-82e1-7c798a016c82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "State of the Art f√ºr deutschsprachige Lemmatisierung ist eigentlich der `RNNTagger` (bzw. sein Vorg√§nger, der `TreeTagger`). Diesen gibt es jedoch nicht als Modul f√ºr Python, sondern nur als Command Line-Tool. Weiter ist seine Installation unter Windows zwar m√∂glich, aber kompliziert. Der folgende Abschnitt zum `RNNTagger` richtet sich nur an Nutzende mit macOS oder Linux. \n",
    "\n",
    "Wenn Windows Dein Betriebssystem ist, bringst Du den `RNNTagger` am einfachsten zum Laufen, indem Du Linux als zweites Betriebssystem (konkreter: als sogenanntes *Subsystem* in Windows) auf Deinem Rechner installierst. Das ist gar nicht so kompliziert, wie es klingt. Eine Anleitung dazu findest Du im Ordner \"5_Bonusmaterial\" im Notebook \"Linux auf Windows\". Dort steht auch, wie Du den `RNNTagger` √ºber Dein neues Subsystem ausf√ºhrst. Schau in dieses Notebook oder mach direkt hier bei [Part-of-Speech-Tagging](#Part-of-Speech-Tagging) weiter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f7ec5-b458-4861-bf5e-86cf6c40f1d7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Lemmatisierung mit dem `RNNTagger` f√ºr macOS/Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89023c-aa2d-4069-aeed-1035b7027518",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Installier den `RNNTagger` auf einem Rechner mit macOS oder Linux wie folgt:\n",
    "\n",
    "1. Lad den `RNNTagger` √ºber [diesen Link](https://www.cis.lmu.de/~schmid/tools/RNNTagger/data/RNNTagger-1.4.7.zip) (oder von [dieser Webseite](https://www.cis.lmu.de/~schmid/tools/RNNTagger/)) herunter. Die Datei ist fast 4 GB gro√ü, stell also sicher, dass Du eine stabile Internetverbindung sowie ausreichend Speicherplatz auf Deinem Rechner hast.\n",
    "2. Entpack die heruntergeladene Datei und speicher sie im bereits existierenden Ordner \"3_Dateien/RNNTagger\". Stell sicher, dass die Ordnerstruktur am Ende so ausschaut:\n",
    "\n",
    "    <img src=\"../3_Dateien/Grafiken_und_Videos/Ordnerstruktur_RNNTagger.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f184698-c079-42b5-beae-cacd72dcb19e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wie gesagt: Der `RNNTagger` ist ein Tool f√ºr die Command Line. Wie wir aber beim Installieren der ben√∂tigten Module oben gesehen haben, k√∂nnen wir die Command Line auch aus einem Jupyter Notebook heraus bedienen. Das wollen wir gleich tun. \n",
    "\n",
    "Zun√§chst √ºberpr√ºfen wir, ob die Installation geklappt hat: Dazu m√ºssen wir das Arbeitsverzeichnis in den Ordner verlegen, in dem sich der `RNNTagger` nun entpackt befindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d25fd4-90b4-488a-b36b-fdd947e0f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Diese Zelle nur einmal ausf√ºhren, sonst erh√§ltst Du eine Fehlermeldung, da relativ vom eben festgelegten\n",
    "Arbeitsverzeichnis '../3_Dateien/RNNTagger' kein Verzeichnis mit dem angegebenen Pfad existiert. \"\"\"\n",
    "%cd ../3_Dateien/RNNTagger "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788abfa-76b6-4163-aa9c-3278ff4a9f73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun legen wir im Ordner \"3_Dateien/Output\" eine Datei namens \"test.txt\" an, die wir anschlie√üend testweise taggen. Wir beschreiben die Datei mit \"Schauen wir, ob das klappt!\". `echo` ist der entsprechende Command Line-Befehl f√ºr diesen Vorgang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb4b73-2d83-467d-bb27-b3d064d32d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Der Pfad zur neuen Datei ist relativ vom eben festgelegten Arbeitsverzeichnis aus \n",
    "(dies gilt auch f√ºr die folgenden relativen Pfade in diesem Abschnitt).\"\"\"\n",
    "!echo \"Schauen wir, ob das klappt!\" > ../Output/test.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c86ad8-34bd-41ef-9f49-25b5c1267c70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Abschlie√üend rufen wir das Command Line-Tool `rnn-tagger-german.sh` (das sich im Unterordner \"cmd\" befindet) auf, und beauftragen es, den Text aus der eben geschaffenen Testdatei zu taggen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377819c9-7598-4818-a762-cee17c0524c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cmd/rnn-tagger-german.sh ../Output/test.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88072ef0-356b-435b-bce3-be8059b6f963",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "√Ñhnlich wie der `HanoverTagger` beherrscht der `RNNTagger` nicht nur Lemmatisierung (drittes Element je Zeile), sondern auch morphologisches Tagging (zweites Element). In den morphologischen Tags sind wiederum auch POS-Tags enthalten (jeweils am Anfang).\n",
    "\n",
    "Nun wollen wir ebenfalls \"Des Kaisers neue Kleider\" taggen, um anschlie√üend den Output des `RNNTagger` mit demjenigen des `HanoverTagger` zu vergleichen. Anstatt der Testdatei √ºbergeben wir dem Command Line-Tool ganz einfach das M√§rchen. Wir erg√§nzen den Befehl um `> ...`, sodass der Output direkt in eine neue Datei geschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03c497-9c6b-4ce8-b7ae-fca3dda81c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cmd/rnn-tagger-german.sh ../Des_Kaisers_neue_Kleider/Des_Kaisers_neue_Kleider.txt > ../Output/Des_Kaisers_neue_Kleider_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69962f8a-9f60-46a1-8e83-f7ba6d7b572b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die getaggte Datei lesen wir wiederum am besten mit `pandas` ein. Durch einen Blick in die Datei erfahren wir, dass die einzelnen Werte jeder Zeile, die wir in Spalten √ºberf√ºhren wollen, durch \"\\t\" voneinander abgetrennt sind. Entsprechend spezifizieren wir den `sep`-Parameter. Weiter benennen wir die Spalten mithilfe des `names`-Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b6939-04bd-4a1b-b004-681c58358844",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#'names' beim Einlesen von Dateien entspricht 'columns' beim Erstellen eines DataFrames basierend auf einem Objekt im Arbeitsspeicher, s. o.\n",
    "fairytale_df_rnn = pd.read_csv(\"../Output/Des_Kaisers_neue_Kleider_output.txt\", sep=\"\\t\", names=['Wortform', 'Morphologie/POS', 'Lemma'])\n",
    "fairytale_df_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4a3fc-2a4b-4152-9a97-c07ac281837b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wie gesagt, wir wollen den Output des `RNNTagger` mit demjenigen des `HanoverTagger` vergleichen. Leider k√∂nnen wir nicht einfach die Spalte \"Lemma\" in den beiden DataFrames miteinander vergleichen, denn die im `RNNTagger` integrierte Tokenisierung weicht von derjenigen von `nltk` ab, wie wir sehen, wenn wir uns die L√§nge der beiden DataFrames ausgeben lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf5c69-17c5-4d75-91d6-4b4a4135508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fairytale_df_ht), len(fairytale_df_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247798ab-702d-47d1-bd09-91459ffdd973",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Offensichtlich f√ºhrte die Tokenisierung des `RNNTagger` zu ein paar mehr W√∂rtern als diejenige von `nltk`, z.&nbsp;B. aufgrund unterschiedlicher Handhabung von Interpunktion. Dieser Umstand erschwert den zeilenweisen Vergleich der Werte in der Spalte \"Lemma\". \n",
    "\n",
    "Wir l√∂sen dieses Problem, indem wir die Lemmatisierung durch den `HanoverTagger` ganz einfach auf Basis der Tokenisierung des `RNNTagger` (statt `nltk`) noch einmal vornehmen. Das Resultat der Tokenisierung vom `RNNTagger` liegt uns ja in der Spalte \"Wortform\" in `fairytale_df_rnn` vor. Der Methode `tag_sent`  des `HanoverTagger` √ºbergeben wir ganz einfach die in eine Liste konvertierte Spalte \"Wortform\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0a2c3-fc54-40d9-9a65-3d3c87e627d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_tokenized_ht_output = ht_tagger.tag_sent(fairytale_df_rnn.Wortform.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea971e-7b7f-47bd-ac75-c99e5ff8bcff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Da wir nur an den Lemmata interessiert sind, isolieren wir diese aus den Tupeln in `rnn_tokenized_ht_output` mithilfe einer List Comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a38ab5-69b1-44e7-9936-378a845365ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_tokenized_ht_output = [element[1] for element in rnn_tokenized_ht_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48162987-621c-4a31-aec6-875c3467769b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun f√ºhren wir den Output der beiden Tagger zusammen, indem wir ein neues DataFrame mit den Wortformen und zwei Spalten f√ºr die beiden Lemmatisierungen schaffen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686477f6-e233-4063-89ae-9e292bf4694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairytale_comparison = pd.DataFrame({\"Wortform\": fairytale_df_rnn.Wortform, \n",
    "                                     \"Lemma_RNN\": fairytale_df_rnn.Lemma, \n",
    "                                     \"Lemma_ht\": rnn_tokenized_ht_output})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747856e3-6de5-4b89-9fdf-1773101a62e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Schauen wir uns `fairytale_comparison` an: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95076619-48c1-4045-bae9-18cb22246afc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fairytale_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2e91b-3fc1-4943-a063-9f53a4a4813b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Beim Scrollen durch `fairytale_comparison` zeigt sich, dass die beiden Tagger meistens gleich lemmatisiert haben. In einigen F√§llen resultierten jedoch unterschiedliche Lemmata. Folgender Code schneidet `fairytale_comparison` hinsichtlich unterschiedlicher Lemmatisierung zu und z√§hlt deren Vorkommen auch gleich aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd32886-3305-426c-9efd-93b911d4b172",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fairytale_comparison[fairytale_comparison.Lemma_RNN != fairytale_comparison.Lemma_ht].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6a2c4-3b07-43b1-8974-66b07eb31ec4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In einigen dieser F√§lle hat eindeutig einer der beiden Tagger recht (z.&nbsp;B. ist \"gestehen\" keine flektierte Form von \"stehen\", weswegen hier das Lemma \"gestehen\" des `RNNTagger` korrekt ist), in anderen m√ºsste man sich den Kontext genauer anschauen (z.&nbsp;B. kann \"gef√§llt\" eine flektierte Form sowohl von \"gefallen\" als auch von \"f√§llen\" sein). In den meisten F√§llen jedoch gibt es kein Richtig oder Falsch. So ist es schlicht Konvention, ob \"solche\" auf \"solcher\" oder \"solch\" reduziert werden soll. Solange dies konsistent gemacht wird, spielt es keine Rolle, welcher Konvention gefolgt wird. Schlie√ülich garantiert die Konsistenz, dass wir zuverl√§ssig Lemmata ausz√§hlen k√∂nnen.\n",
    "\n",
    "`rnn-tagger-german` f√ºrs Deutsche ist √ºbrigens bei Weitem nicht der einzige Tagger, der sich im Ordner \"cmd\" befindet. Den `RNNTagger` gibt es f√ºr so verschiedene Sprachen wie Arabisch, Isl√§ndisch, Koreanisch, Fr√ºhneuhochdeutsch, Schweizerdeutsch oder Obersorbisch... Um Daten in einer der anderen Sprachen zu taggen, musst Du einzig den Pfad zum Tagger ersetzen.\n",
    "\n",
    "Bevor wir mit Part-of-Speech-Tagging weitermachen, m√ºssen wir das aktuelle Arbeitsverzeichnis zur√ºcksetzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ab065-b10d-423a-be20-86641203fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diese Zelle nur einmal ausf√ºhren, s. Begr√ºndung oben\n",
    "%cd ../../1_Notebooks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc7a79-f435-4c8f-b764-b712dc49b57c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Part-of-Speech-Tagging\n",
    "\n",
    "Beim Part-of-Speech-Tagging (kurz: *POS-Tagging*) wird die Wortart eines Worts ermittelt. POS-Tags sind aber wesentlich feiner gegliedert als die herk√∂mmlichen paar Wortarten, die wir in der Schule gelernt haben (u.&nbsp;a. Nomen, Verben, Adjektive etc.). So wird etwa bei den Verben danach unterschieden, ob sie [finit](https://de.wikipedia.org/wiki/Finite_Verbform) sind sowie, ob es sich um ein Hilfs- oder Modalverb handelt. Wie bereits erw√§hnt ist f√ºrs Deutsche das [Stuttgart-T√ºbingen-TagSet](https://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/germantagsets/#id-cfcbf0a7-0) der Standard (die hier nicht behandelte, aber ebenfalls beliebte korpuslinguistische Software Sketch Engine verwendet jedoch ein eigenes [Tagset](https://www.cis.uni-muenchen.de/~schmid/papers/Schmid-Laws.pdf)). Das STTS umfasst insgesamt 54 Tags. Wie auch bei der Lemmatisierung, ist die Zuordnung eines POS-Tags nicht immer eindeutig.\n",
    "\n",
    "Zum POS-Taggen k√∂nnen wir, wie oben bereits gemacht, den `HanoverTagger` (sowie ebenfalls den `RNNTagger`) einsetzen. Spielen wir das noch an einem weiteren Text durch, z.&nbsp;B. dem ersten Kapitel von Niels Holgersen. Bevor wir den Text taggen k√∂nnen, m√ºssen wir ihn f√ºr den `HanoverTagger` tokenisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e693b8-baa7-41d7-933a-ee9e91f8406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../3_Dateien/Niels_Holgersen/Kapitel_1.txt\", encoding=\"utf8\") as f:\n",
    "    niels_holgersen = f.read()\n",
    "    \n",
    "niels_holgersen_tokenized = nltk.word_tokenize(niels_holgersen) #Tokenisierung\n",
    "\n",
    "niels_holgersen_output = ht_tagger.tag_sent(niels_holgersen_tokenized) #Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc794a97-3439-468e-bd50-28e9a2062f20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Schauen wir uns das Ergebnis wiederum in einem DataFrame an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e269430-4d7f-4d25-bc5d-7496dc9705e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "niels_holgersen_df = pd.DataFrame(niels_holgersen_output, columns=['Wortform', 'Lemma', 'POS'])\n",
    "\n",
    "niels_holgersen_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccbc78a-1a6b-44bf-a55b-367d69e68029",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das schaut doch wunderbar aus!\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "‚úèÔ∏è **√úbung 2:** Bring in Erfahrung, welche f√ºnf Adjektive am h√§ufigsten im ersten Kapitel von Niels Holgersen vorkommen.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1</summary>\n",
    "  <br>Schau in der <a href=\"https://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/germantagsets/#id-cfcbf0a7-0\">Dokumentation des POS-Tagsets</a> nach, welche Tags f√ºr Adjektive verwendet werden. Setzt der <code>HanoverTagger</code> das Tagset eins-zu-eins um?\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 2</summary>\n",
    "  <br>√úberleg Dir, ob Wortformen oder Lemmata besser zur Ausgabe der f√ºnf h√§ufigsten Adjektive geeignet sind.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed855a0-d2fd-4811-9551-18ea6b9e43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992fc4c-5f22-496b-a6ce-a62952746c18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Sehr gut. Machen wir mit morphologischem Tagging weiter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487153cd-0cb2-4c66-8718-3a404ff94db2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Morphologisches Tagging\n",
    "\n",
    "W√§hrend wir bei der Lemmatisierung flektierte Wortformen auf ihre unflektierte Grundform reduzieren, geht es beim morphologischen Tagging umgekehrt darum, herauszufinden, *wie* eine Wortform flektiert ist sowie welche grammatikalischen Merkmale sie aufweist. Die Wortform \"H√§user\" in einem Satz wie \"Sie verkauft H√§user\" liegt etwa als *neutrales* (Genus) Nomen im *Akkusativ* (Kasus) und *Plural* (Numerus) vor. Morphologische Tags werden √ºblicherweise kombiniert mit POS-Tags benutzt, z.&nbsp;B. um alle Verbformen in der dritten Person Singular zu extrahieren. \n",
    "\n",
    "Wenn Du den `RNNTagger` installiert hast, hast Du bereits gesehen, wie Du morphologische Tags (inkl. POS-Tags) erh√§ltst. Weiter bieten die Module `spacy` und `stanza` die M√∂glichkeit, Texte morphologisch zu taggen. In den folgenden Zellen tun wir Folgendes:\n",
    "\n",
    "1. Wir bereiten das morphologische Tagging mithilfe der beiden Tagger vor. \n",
    "2. Wir taggen wieder das erste Kapitel aus Niels Holgersen, wobei wir jeweils messen, wie lange das Tagging dauert. \n",
    "3. Wir √ºberf√ºhren den Output in zwei verschiedene DataFrames.\n",
    "\n",
    "Lies die Kommentare in den Code-Zellen aufmerksam durch, um nachzuvollziehen, wie `spacy` und `stanza` zum morphologischen Tagging eingesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578f701-e8a0-4399-943a-5f44f042205e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Erstens: Vorbereitung f√ºr 'spacy'\n",
    "import spacy, spacy.cli\n",
    "\n",
    "\"\"\"Download des deutschsprachigen Modells, das zum Taggen ben√∂tigt wird. Das Modell muss\n",
    "nur einmal heruntergeladen werden, danach befindet es sich lokal gespeichert.\"\"\"\n",
    "spacy.cli.download(\"de_core_news_sm\") \n",
    "\n",
    "#Initialisieren von 'spacy_tagger' mit dem deutschsprachigen Modell (anstatt 'spacy_tagger' wird auch oft die Variable 'nlp' benutzt)\n",
    "spacy_tagger = spacy.load(\"de_core_news_sm\") #'spacy' stellt weitere Modelle f√ºr Deutsch und andere Sprachen zur Verf√ºgung\n",
    "\n",
    "#Vorbereitung f√ºr 'stanza'\n",
    "import stanza\n",
    "\n",
    "\"\"\"Initialisieren von 'stanza_tagger' mit deutschsprachigem Modell sowie den ben√∂tigten Modellen bzw. Taggern: \n",
    "Morphologisches Tagging ist bei 'stanza' Teil von 'pos'; 'tokenize' und 'mwt' (Multiworttokenisierung) sind \n",
    "wiederum Voraussetzungen f√ºr 'pos'. Modelle werden automatisch heruntergeladen.\"\"\"\n",
    "stanza_tagger = stanza.Pipeline(lang=\"de\", processors=\"tokenize,mwt,pos\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a49b33-68e9-493f-93cf-78736a6679be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zweitens: Eigentliches Tagging inkl. Zeitmessung\n",
    "import time\n",
    "\n",
    "#Mit 'spacy'\n",
    "start_time = time.time()\n",
    "spacy_output = spacy_tagger(niels_holgersen)\n",
    "spacy_time = time.time() - start_time\n",
    "\n",
    "#Mit 'stanza'\n",
    "start_time = time.time()\n",
    "stanza_output = stanza_tagger(niels_holgersen)\n",
    "stanza_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10034eea-69b2-4606-9e0f-7317356970f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drittens: √úberf√ºhren in DataFrame\n",
    "\n",
    "#Output von 'spacy'\n",
    "\"\"\"Das √úberf√ºhren der getaggten Daten in ein DataFrame kann verschiedentlich umgesetzt werden, \n",
    "hier folgt eine besonders effiziente Variante: Wir erstellen erst eine Liste ('list_of_all_dicts'),\n",
    "an die wir unten bei der Iteration √ºber 'spacy_output' die einzelnen Zeilenwerte (Wortform und Morphologie) \n",
    "in Form eines dictionary ('dict_per_word') anh√§ngen. Aus dem dictionary konstruieren wir anschlie√üend\n",
    "ein DataFrame.\"\"\"\n",
    "list_of_all_dicts = []\n",
    "\n",
    "\"\"\"Iteration √ºber 'spacy_output', um Wortform (√ºber 'text'-Attribut) und morphologisches Tag ('morph') f√ºr jede \n",
    "Zeile (im finalen DataFrame) in 'dict_per_word' zu √ºbertragen und 'list_of_all_dicts' anzuh√§ngen. Die morphologischen Tags \n",
    "casten wir dabei in einen string und bereinigen sie von Klammern. Das Casting erm√∂glicht nicht nur die Bereinigung, \n",
    "sondern stellt auch sicher, dass die Tags im finalen DataFrame auch wirklich als strings vorliegen und nicht als \n",
    "spacy-eigener Datentyp. Dies ist f√ºr die Auswertung der Daten mit 'pandas'-string-Methoden entscheidend.\"\"\"\n",
    "for word in spacy_output:\n",
    "    dict_per_word = {\n",
    "        \"Wortform\": word.text,\n",
    "        \"Morphologie\": str(word.morph).strip(\"()\")}\n",
    "    list_of_all_dicts.append(dict_per_word)\n",
    "    \n",
    "niels_holgersen_df_spacy = pd.DataFrame(list_of_all_dicts) #Erstellen eines DataFrame auf Basis der Liste mit dictionaries\n",
    "\n",
    "#Output von 'stanza'\n",
    "\"\"\"Gleiche Logik wie oben, allerdings teilt 'stanza' den Text beim Tagging zun√§chst in S√§tze auf, weswegen wir erst √ºber \n",
    "die S√§tze (mithilfe des Attributs 'sentences') iterieren m√ºssen, dann √ºber die darin befindlichen W√∂rter ('words'), \n",
    "um schlie√ülich auf die Wortform ('text') sowie die morphologischen Informationen ('feats') zuzugreifen.\"\"\"\n",
    "list_of_all_dicts = []\n",
    "\n",
    "for sentence in stanza_output.sentences:\n",
    "    for word in sentence.words:\n",
    "        dict_per_word = {\n",
    "            \"Wortform\": word.text,\n",
    "            \"Morphologie\": word.feats}\n",
    "        list_of_all_dicts.append(dict_per_word)\n",
    "    \n",
    "niels_holgersen_df_stanza = pd.DataFrame(list_of_all_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b1762-16ac-4ce5-86f2-50a23238c71d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Werfen wir in den n√§chsten beiden Zellen einen Blick in die DataFrames mit den morphologischen Tags, konkret in den Schluss des Textes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e8870-320e-4792-8b15-b19d22d1a736",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "niels_holgersen_df_spacy.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58176bb7-1921-440e-a01c-0438a766f291",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "niels_holgersen_df_stanza.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e676336-078b-4e1c-8c27-072b5a08bf4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenngleich sich der Output der beiden Tagger √§hnelt, zeigen sich doch Unterschiede, etwa beim Wort \"Verdrie√ülichkeiten\", bei dem nur `stanza` das korrekte Genus taggt. Bei \"fl√∂ge\" hingegen liegt `spacy` in Bezug auf den Modus Konjuktiv (*<u>sub</u>junctive Mood* auf Englisch) richtig. Ein kompletter, zeilenweiser Vergleich aller Tags ist an dieser Stelle schwierig, da die beiden Tagger unterschiedlich tokenisiert haben, was zu einer abweichenden Gesamtzahl an Zeilen f√ºhrt (vgl. auch Abschnitt zum `RNNTagger`). Gemeinhin gilt der Output von `stanza` als zuverl√§ssiger als derjenige von `spacy`. √úbrigens kann es sein, dass sich die morphologischen Tags in Deinem Output von den hier erw√§hnten unterscheiden, was darauf zur√ºckzuf√ºhren w√§re, dass die zugrundeliegenden Sprachmodelle von `spacy` bzw. `stanza` aktualisiert wurden. Diese Einschr√§nkung gilt auch bei den √ºbrigen Taggingarten.\n",
    "\n",
    "Abgesehen von der Qualit√§t der Tags k√∂nnten sich die beiden Tagger (auch) mit Blick auf die Effizienz unterscheiden. Schauen wir, wie lange sie jeweils zum Taggen des gegebenen Texts ben√∂tigt haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02fe308-73d3-49ff-b95a-c3905c50c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_time, stanza_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f13fb3-edef-48d5-b254-7bc27073bffa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Hier hat `spacy` klar die Nase vorn. Die Zeiten m√∂gen leicht variieren, `spacy` ist aber immer um ein Vielfaches schneller als `stanza`. \n",
    "\n",
    "Je nach Daten und Forschungsinteresse m√ºssen wir folglich zwischen der Zuverl√§ssigkeit der Tags ‚Äì die es manuell zu beurteilen gilt ‚Äì und der Effizienz des Taggings abw√§gen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c1c4d-5c89-42f0-b0d8-457942d3cb21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 3:** Reicher den Koalitionsvertrag von 2021 nicht nur mit morphologischen Tags, sondern auch mit Lemmata und POS-Tags an. W√§hl selbst, welchen Tagger Du dazu verwendest und informier Dich ggf. in der entsprechenden Dokumentation zu den Taggingm√∂glichkeiten. √úberf√ºhr die getaggten Daten abschlie√üend in ein DataFrame. \n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1</summary>\n",
    "  <br>Da es sich um einen langen Text handelt, bietet sich die Nutzung des effizienteren Moduls, <code>spacy</code>, an. Alternativ k√∂nntest Du auch mit dem <code>RNNTagger</code> arbeiten.\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 2</summary>\n",
    "  <br>Stell sicher, dass Du die morphologischen Tags als strings in das DataFrame √ºberf√ºhrst (vgl. Kommentar in der Code-Zelle \"#Drittens: √úberf√ºhren in DataFrame\" oben). Dies ist wichtig f√ºr die anschlie√üende Datenauswertung in √úbung 4.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48eb4f-cbb3-4b8f-b5c4-1d08fcf9ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5983056-c5ab-4615-a127-605d838c7753",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 4:** Ermittle die 20 h√§ufigsten femininen Nomina im Koalitionsvertrag von 2021.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1</summary>\n",
    "  <br>Arbeite mit dem in √úbung 3 erstellten DataFrame sowie string-Methoden (vgl. Notebook \"Datenanalyse\") und √ºberleg Dir zun√§chst, wie Du das DataFrame filtern kannst, um nur Nomina zu erhalten, und nur solche, die auch <i>feminin</i> sind. \n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "  <summary>üí° Tipp 2</summary>\n",
    "  <br>Mehrere Filter kannst Du bei <code>pandas</code> durch den <code>&</code>-Operator verbinden. Setz aber die einzelnen Filter in runde Klammern.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "  <summary>üí° Tipp 3</summary>\n",
    "  <br>Nachdem Du das DataFrame gefiltert hast, musst Du Dir √ºberlegen, in welcher Spalte Du sinnvollerweise das Vorkommen der Werte ausz√§hlst (vgl. auch √úbung 2 oben).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbe125-d193-455a-bb62-7dbdaa7b87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6153aa-0bf2-4657-99d7-bb744e6e5e3b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Weiter geht's mit syntaktischem Parsing\n",
    "\n",
    "## Syntaktisches Parsing\n",
    "\n",
    "Beim syntaktischen Parsing (auch *dependency parsing* genannt) interessiert uns, welche syntaktischen Beziehungen zwischen den einzelnen W√∂rtern eines Satzes bestehen. Um beim minimalistischen Beispiel \"Sie verkauft H√§user\" zu bleiben: \"Sie\" entspricht in diesem Beispiel dem Subjekt, \"verkauft\" dem Pr√§dikat und \"H√§user\" dem (Akkusativ-)objekt. Das Pr√§dikat wird als Wurzel (engl. *root*) des Satzes bezeichnet.\n",
    "\n",
    "Auch f√ºr syntaktisches Parsing bieten sich sowohl `spacy` als auch `stanza` an. Im Falle von `spacy` k√∂nnen wir bereits den oben initialisierten `spacy_tagger` benutzen, denn `spacy` taggt Sprachdaten ‚Äì wie wir auch in √úbung 3 gesehen haben ‚Äì *standardm√§√üig* in Bezug auf Lemmata, POS, Morphologie und eben Syntax (sowie Named Entity Recognition, s.&nbsp;u.). √úber ein [`disable`-Argument](https://spacy.io/usage/linguistic-features#disabling) im `load`-Befehl (s.&nbsp;o.) k√∂nnten wir allerdings einzelne Tagger ausschalten, was vor allem bei gro√üen Datenmengen Sinn macht. F√ºr `stanza` hingegen m√ºssen wir den `stanza_tagger` modifizieren, um Daten syntaktisch taggen zu k√∂nnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fd5c3-f0a8-4c93-b9cf-b321896bb3e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Die Tagger vor 'depparse' sind Abh√§ngigkeiten desselben und m√ºssen entsprechend mitgeladen werden\n",
    "stanza_tagger = stanza.Pipeline(lang=\"de\", processors=\"tokenize,mwt,pos,lemma,depparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2c82c-4c70-4988-861d-80f12c73b4ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Lassen wir uns unseren leicht erg√§nzten Beispielsatz in `sentence` syntaktisch auseinandernehmen, und zwar von beiden Taggern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dec790-f34b-43b8-841e-acb55c260b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Sie verkauft dem jungen Herrn sch√∂ne H√§user\"\n",
    "\n",
    "#Tagging\n",
    "spacy_output = spacy_tagger(sentence)\n",
    "stanza_output = stanza_tagger(sentence)\n",
    "\n",
    "#Ausgabe der beiden Outputs nebeneinander mithilfe einer 'range'-Schleife\n",
    "print(f\"{'Wortform':10}{'spacy':10}{'stanza':10}\\n{'-'*30}\")\n",
    "for i in range(len(spacy_output)):\n",
    "    \"\"\"Zugriff auf jeweilige Wortform und syntaktische Tags (bei 'spacy' mit 'dep_'-Attribut, bei 'stanza' \n",
    "    mit 'deprel'-Attribut). Da 'stanza' den zu taggenden Text jeweils erst in S√§tze splittet (vgl. Kommentar oben) m√ºssen\n",
    "    wir zus√§tzlich den ersten (und einzigen) Satz mit dem Index null indizieren. Sch√∂ne Formatierung mit f-strings.\"\"\"\n",
    "    print(f\"{spacy_output[i].text:10}{spacy_output[i].dep_:10}{stanza_output.sentences[0].words[i].deprel:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f9be2-b726-4716-b550-c5611e60d342",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die beiden Tagger verwenden offenkundig unterschiedliche Tagsets. `stanza` verwendet die Tags von [Universal Dependencies](https://universaldependencies.org/de/dep/index.html), einem Projekt, das sich um einheitliche sprach√ºbergreifende Annotation bem√ºht. `spacy` richtet sich auch danach, nennt die Tags aber anders. S√§mtliche Tags bei `spacy` und ihre Bedeutung k√∂nnen wir so erfahren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf7fb3-b81c-45be-8f5a-fc4102e44364",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label in spacy_tagger.get_pipe(\"parser\").labels:\n",
    "    print(f\"{label:10}{spacy.explain(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1bfe5-4f24-42b2-8203-bd2f88e33e8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Im Beispiel oben unterscheidet `stanza` im Gegensatz zu `spacy` zwischen Adjektiv (\"amod\") und Artikel (\"det\"). `spacy` taggt hingegen schlicht \"noun kernel element\", was im Sinne von Bestandteilen der [Nominalphrase](https://de.wikipedia.org/wiki/Nominalphrase) zu verstehen ist. Andererseits punktet `spacy` bei der korrekten Kasuszuordnung der Objekte (\"da\" vs. \"oa\", also Dativ vs. Akkusativ). `stanza` auf der anderen Seite taggt in beiden F√§llen \"obj\", was gem√§√ü dem [Universal Dependencies-Tagset](https://universaldependencies.org/de/dep/obj.html) f√ºr das direkte Objekt, also das Akkusativobjekt, steht und insofern bei \"Herrn\" falsch ist. Auch hier gilt: Je nach Daten und Forschungsinteresse muss evaluiert werden, welcher Tagger die besten Ergebnisse liefert.\n",
    "\n",
    "`spacy` implementiert √ºbrigens die hilfreiche M√∂glichkeit, sich die syntaktischen Beziehungen in einem Satz visualisieren zu lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98500ff-b40a-4381-9f99-bab5bac9840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "sentence = \"Sie verkauft dem jungen Herrn sch√∂ne H√§user\"\n",
    "\n",
    "spacy_output = spacy_tagger(sentence)\n",
    "displacy.render(spacy_output, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e11ac-c2c3-4be0-b9dc-aeaa3a512647",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 5:** Find heraus, welche W√∂rter besonders h√§ufig als Subjekt im Koalitionsvertrag von 2021 stehen und lass Dir die zehn Spitzenreiter ausgeben.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp</summary>\n",
    "  <br>Musst Du den Koalitionsvertrag daf√ºr noch einmal taggen?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f06b6-c555-490e-bf1b-d34ec2c8ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d31cf-29c6-4c49-b21b-68e0a4475206",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Sehr gut. Wenden wir uns der Named Entity Recognition zu.\n",
    "\n",
    "## Named Entity Recognition\n",
    "\n",
    "Bei der Named Entity Recognition (abgek√ºrzt: *NER*) geht es darum, Eigennamen, etwa f√ºr Personen, geografische Orte oder Institutionen, in einem Text zu identifizieren. Statt wie bislang jedem Wort ein Tag zuzuweisen, werden bestimmte W√∂rter bzw. *Sequenzen* von W√∂rtern als *Named Entity* ausgewiesen. Named Entity Recognition erm√∂glicht es, bestimmte Informationen aus gro√üen, unstrukturierten Textmengen zu extrahieren und strukturiert, z.&nbsp;B. in Form einer Tabelle, zu speichern.\n",
    "\n",
    "F√ºr Named Entity Recognition k√∂nnen wir abermals `spacy` und `stanza` verwenden, wobei wir den `stanza_tagger` noch einmal \"umprogrammieren\" m√ºssen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216b445-c75a-4d96-8a33-54479fbe97d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Der Tagger vor 'ner' ist eine Abh√§ngigkeit desselben und muss entsprechend mitgeladen werden.\n",
    "stanza_tagger = stanza.Pipeline(lang=\"de\", processors=\"tokenize,ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d329ae0-b40e-43af-bc62-2007b058f8c1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun k√∂nnen wir uns den in `sentence` gegebenen Satz im Hinblick auf Eigennamen taggen lassen, und zwar von beiden Taggern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4089e65-8ad3-4d25-9350-abe1c71f8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Angela Merkel traf den Vorstand der Deutschen Bahn in Frankfurt am Main.\"\n",
    "\n",
    "#Tagging\n",
    "spacy_output = spacy_tagger(sentence)\n",
    "stanza_output = stanza_tagger(sentence)\n",
    "\n",
    "\"\"\"Ausgabe der beiden Outputs nebeneinander mithilfe einer 'range'-Schleife √ºber 'spacy_out.ents' \n",
    "('ents'-Attribut schafft ein Objekt zur Iteration √ºber getaggte Entit√§ten)\"\"\"\n",
    "print(f\"{'Wortform':30}{'spacy':10}{'stanza':10}\\n{'-'*50}\")\n",
    "for i in range(len(spacy_output.ents)):\n",
    "    \"\"\"Zugriff auf Wortform ('text'-Attribut) der getaggten Entit√§t, sowie das verliehene Tag\n",
    "    vonseiten 'spacy' ('label_'-Attribut) bzw. 'stanza' ('type'-Attribut). Diese Art der Iteration\n",
    "    und Ausgabe funktioniert nat√ºrlich nur so lange dieselben Entit√§ten getaggt wurden, was\n",
    "    bei diesem kurzen Beispielsatz der Fall ist.\"\"\"\n",
    "    print(f\"{spacy_output.ents[i].text:30}{spacy_output.ents[i].label_:10}{stanza_output.ents[i].type:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b117fe6-326b-47e5-a41e-c884f503640d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das klappt wunderbar: Angela Merkel wurde als Person (\"PER\"), die Deutsche Bahn als Organisation (\"ORG\") und Frankfurt am Main als geografischer Ort (\"LOC\") erkannt. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659af343-e115-4e0e-80ed-06f866753d4f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "`spacy` unterscheidet f√ºrs deutschsprachige NER-Tagging folgende vier Tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020b4a1-4534-4fba-b4e4-7d6114ad057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in spacy_tagger.get_pipe(\"ner\").labels:\n",
    "    print(f\"{label:10}{spacy.explain(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee06cc2d-6b11-4de5-853a-45018a3a83e0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[`stanza`](https://stanfordnlp.github.io/stanza/ner_models.html) verwendet dieselben vier Tags.\n",
    "\n",
    "`spacy` bietet auch hier die M√∂glichkeit der Visualisierung, einzig den Parameter `style` m√ºssen wir anpassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919b40f-e83b-4026-a910-6904b9398aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(spacy_output, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ddd5c-63ff-45ab-bdd4-093f68695cd1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "An der grafischen Ausgabe erkennt man gut, dass es sich nicht um eine Wort-f√ºr-Wort-Klassifikation wie bei allen anderen Taggingarten bisher handelt, sondern um eine *Sequence Labeling Task*. \n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 6:** Lad Dir mithilfe der [API f√ºr Wikipedia](https://pypi.org/project/Wikipedia-API/) `wikipediaapi` (vgl. Zusatz√ºbungen zum Notebook \"Regul√§re Ausdr√ºcke\") den *englischsprachigen* Artikel zu einer prominenten Person Deiner Wahl herunter und extrahier alle darin erw√§hnten Personen mithilfe von `spacy` und `stanza`. Welche Unterschiede zeigen sich beim Vergleich der zehn h√§ufigsten Personen in den beiden Outputs? Verwend `pandas` f√ºr diesen Vergleich.\n",
    "\n",
    "Lass Dir au√üerdem s√§mtliche von `spacy` gefundenen Named Entities visualisieren (also nicht nur die Personen). Erkennst Du einen Unterschied im Vergleich zum NER-Tagging deutschsprachiger Texte?\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1</summary>\n",
    "  <br>Spezifiziere die richtige Sprache beim Abrufen des Artikels mithilfe von <code>wikipediaapi</code>.\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 2</summary>\n",
    "  <br>Da Du nun einen englischsprachigen Text taggst, musst Du die beiden Tagger neu programmieren, d.&nbsp;h. ihnen ein englischsprachiges Modell zugrunde legen. Im Falle von <code>spacy</code> l√§dst Du daf√ºr z.&nbsp;B. das Modell \"en_core_web_sm\" herunter und √ºbergibst es dem <code>load</code>-Befehl (<a href=\"https://spacy.io/models\">hier</a> findest Du eine √úbersicht aller zur Verf√ºgung stehenden Modelle bei <code>spacy</code>). Bei <code>stanza</code> reicht die Spezifikation des <code>lang</code>-Parameter als \"en\" beim Initialisieren des Taggers.\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 3</summary>\n",
    "  <br>Die beiden Tagger verwenden dasselbe Tag f√ºr Personen, aber ist es auch das gleiche Tag wie beim Tagging deutschsprachiger Texte? \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a6347-c2d4-4573-9a73-aa743622dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c9082-877f-4713-b5d7-ea00ebb6a885",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wunderbar. Schauen wir uns abschlie√üend noch Sentiment Analysis an.\n",
    "\n",
    "***\n",
    "\n",
    "## Sentiment Analysis\n",
    "\n",
    "Bei der Sentiment Analysis werden einzelne S√§tze oder auch ganze Texte nach der in ihnen ausgedr√ºckten Stimmung (engl. *sentiment*) beurteilt. Je nach Tagger wird dieses Sentiment √ºber sprachliche Tags von \"positiv\" √ºber \"neutral\" bis \"negativ\" oder √ºber eine Zahl auf einer entsprechenden, numerischen Skala ausgedr√ºckt (etwa von 1 bis -1).\n",
    "\n",
    "Sentiment Analysis stellt eine sinnvolle Technik zur Operationalisierung bestimmter Fragestellungen dar, etwa wenn Kommentare in Sozialen Medien hinsichtlich besonders negativen Inhalten, in denen z.&nbsp;B. Hass ausgedr√ºckt wird, (vor-)gefiltert werden sollen. F√ºr weiterreichendere Aussagen √ºber Texte greift die Methode oft zu kurz, zumal die ihr zugrundeliegende Skala nur eine Dimension kennt. Weiter haben Sentiment Tagger oft M√ºhe, mit sprachlichen Ph√§nomenen wie mehrfacher Negation (\"etwas nicht ungern tun\") oder Ironie umzugehen.\n",
    "\n",
    "Wollen wir aber die Probe auf's Exempel machen. Wir nutzen dazu [`germansentiment`](https://pypi.org/project/germansentiment/) sowie ein paar simple S√§tze aus `sentences`. Die S√§tze sind aufsteigend nach Negativit√§t sortiert, wobei dies bis zu einem gewissen Grad nat√ºrlich eine subjektive Einsch√§tzung darstellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fb50c-bf81-4e20-8455-761e291b31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel\n",
    "\n",
    "sentiment_tagger = SentimentModel()\n",
    "\n",
    "sentences = [\"Ich bin ein riesengro√üer Fan von Schokolade.\",\n",
    "             \"Was ich auch durchaus mag, sind frisch gepfl√ºckte Himbeeren.\",\n",
    "             \"Salz und Pfeffer d√ºrfen nicht fehlen.\",\n",
    "             \"Von Kartoffelauflauf halte ich nichts.\",\n",
    "             \"Mit gekochten M√∂hren kannst Du mich jagen.\"]\n",
    "\n",
    "sentiment_tagger.predict_sentiment(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd935ff-3ad7-4c32-91b4-41da97d9e217",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Entsprechend der subjektiven Rangfolge, verleiht `germansentiment` den ersten beiden S√§tzen das Tag \"positive\", dem mittleren Satz \"neutral\" sowie dem vierten Satz \"negative\". Einzig beim letzten Satz weicht das verliehene Tag vom subjektiven Urteil ab, dass es sich um einen (sehr) negativen Satz handelt. Auch hier gilt: Die erw√§hnten Tags wurden zum Zeitpunkt des Verfassens dieses Notebooks verliehen und k√∂nnen nach einer Aktualisierung der Sprachmodelle anders ausfallen (s.&nbsp;o.).\n",
    "\n",
    "`germansentiment` vergibt insgesamt die drei Tags \"positive\", \"neutral\" und \"negative\", wobei es f√ºr jedes Tag separat errechnet, wie wahrscheinlich dieses beim gegebenen Satz zutrifft. Oben haben wir jeweils das wahrscheinlichste Tag zur√ºckerhalten. Indem wir den Parameter `output_probabilities` aber auf `True` setzen, erhalten wir neben den wahrscheinlichsten Tags auch Auskunft dar√ºber, wie wahrscheinlich jedes einzelne Tag war. \n",
    "\n",
    "Die beiden R√ºckgabewerte, die Tags und die Wahrscheinlichkeiten, weisen wir sinnvollerweise zwei verschiedenen Variablen zu. Anschlie√üend iterieren wir √ºber die einigerma√üen verschachtelten Objekte, um uns Tags und Wahrscheinlichkeitsverteilungen pro Satz ausgeben zu lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de58ad1-c14b-42e9-8b28-23358596ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, probabilities = sentiment_tagger.predict_sentiment(sentences, output_probabilities=True)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(f\"Der Satz '{sentences[i]}' ist am wahrscheinlichsten {tags[i]}. Insgesamt sieht die Wahrscheinlichkeitsverteilung so aus:\")\n",
    "    \n",
    "    for tag in probabilities[i]:\n",
    "        print(f\"\\t{tag[0]} hatte eine Wahrscheinlichkeit von {tag[1]:.2f}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a4459-6e64-4139-a522-53c7ccc4c591",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Es zeigt sich, dass sich `germansentiment` bei seiner Einsch√§tzung, dass der letzte Satz in `sentences` neutral ist, sogar sehr sicher ist. Vielleicht liegt dies daran, dass der Satz umgangssprachlich formuliert ist; vielleicht aber auch daran, dass der Tagger die vorangehenden S√§tze nicht als Kontext mit einbezieht. Anders chatGPT, das analog zur subjektiven Einsch√§tzung von oben urteilt:\n",
    "\n",
    "<img src=\"../3_Dateien/Grafiken_und_Videos/sentiment_analysis_chatGPT.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0a4c1-e1a6-4763-bcbc-f06f91eb4bd5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "OpenAI bietet √ºbrigens auch eine API, mit der wir √ºber Python Anfragen an chatGPT schicken k√∂nnen. Die Anzahl an Anfragen √ºber diesen Kanal ist allerdings stark eingeschr√§nkt und nur zahlende Nutzer:innen k√∂nnen die API sinnvoll einsetzen. \n",
    "\n",
    "√úben wir Sentiment Analysis!\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 7:** Find heraus, ob es sich beim Koalitionsvertrag von 2021 um einen positiven, neutralen oder negativen Text handelt. √úberleg Dir genau, was f√ºr Input `predict_sentiment` erwartet, d.&nbsp;h. wie Du den Koalitionsvertrag sinnvollerweise taggst.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1</summary>\n",
    "  <br><code>predict_sentiment</code> erwartet eine Liste mit strings. Zwar k√∂nntest Du den gesamten Koalitionsvertrag als ein string auf einer Liste √ºbergeben, angesichts der L√§nge des Texts ist es aber sinnvoller, diesen erst in S√§tze zu splitten (u.&nbsp;a. weil Du nur so den Fortschritt des Taggings verfolgen kannst, s. Tipp 2). <code>nltk</code> bietet √ºbrigens auch daf√ºr eine Funktion, n√§mlich <code>sent_tokenize</code> (vgl. <code>word_tokenize</code> oben). Nun √ºbergibst Du Satz f√ºr Satz an <code>germansentiment</code>, allerdings trotzdem als Element einer Liste, denn das ist das erwartete Inputformat. Abschlie√üend berechnest Du, welches Tag am h√§ufigsten verliehen wurde.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "  <summary>üí° Tipp 2</summary>\n",
    "    <br>Das Tagging dauert lange. Bau mithilfe von <code>tqdm</code> eine Fortschrittsanzeige ein, um den Prozess im Blick behalten zu k√∂nnen (vgl. Zusatz√ºbungen zum Notebook \"Web Scraping\"). F√ºhr den Code gerne auch √ºber Nacht aus und stell sicher, dass sich Dein Rechner nicht nach einer gewissen Zeit von alleine ausschaltet. \n",
    "    <br><br>Weiter empfiehlt es sich, den Tagging-Code zun√§chst bei einigen wenigen S√§tzen auszuprobieren. Ansonsten musst Du jeweils sehr lange warten, bis der Code ausgef√ºhrt wurde und Du √ºberpr√ºfen kannst, ob das Resultat wie gew√ºnscht aussieht.\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "<details><summary>ü¶ä Herausforderung</summary>\n",
    "<br>Find zus√§tzlich heraus, bei welchen S√§tzen des Koalitionsvertrags ein negatives bzw. positives Sentiment mit einer Wahrscheinlichkeit von √ºber 50% getaggt wurde.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147094ee-ddfc-4aee-9967-742bf46d2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56efb2-e011-46b7-b1f6-2aece4371eab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Bevor wir uns dem Anwendungsfall widmen, soll noch auf eine hilfreiche Ressource f√ºr Sentiment Analysis hingewiesen werden: [SentiWS](https://wortschatz.uni-leipzig.de/de/download). Das Projekt Deutscher Wortschatz stellt mit SentiWS eine umfangreiche Liste von W√∂rtern zur Verf√ºgung, die typischerweise Sentiment ausdr√ºcken. Jedes Wort wird mit einer Zahl zwischen 1 und -1 bewertet. Anstatt einen fertigen Tagger wie `germansentiment` √ºber Deine Daten laufen zu lassen, kannst Du auch das \"Sentiment-W√∂rterbuch\" von SentiWS benutzen. Dadurch ermittelst Du nicht nur, welches Sentiment Dein Text ausdr√ºckt, sondern erf√§hrst zudem, aufgrund welcher W√∂rter dieses Sentiment zustandekommt.\n",
    "\n",
    "***\n",
    "\n",
    "## üîß Anwendungsfall: (D)ein Korpus taggen üè∑Ô∏è\n",
    "\n",
    "Setz nun die erlernten Taggingkenntnisse um und reicher eigene Daten mit Zusatzinformationen an. Schau Dir ebenfalls den Musteranwendungsfall in den L√∂sungen an.\n",
    "\n",
    "***\n",
    "\n",
    "Gute Arbeit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15a822-a990-440c-ad5a-e611793631fe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "***\n",
    "<table>\n",
    "      <tr>\n",
    "        <td>\n",
    "            <img src=\"../3_Dateien/Lizenz/CC-BY-SA.png\" width=\"400\">\n",
    "        </td> \n",
    "        <td>\n",
    "            <p>Dieses Notebook sowie s√§mtliche weiteren <a href=\"https://github.com/yannickfrommherz/exdimed-student/tree/main\">Materialien zum Programmierenlernen f√ºr Geistes- und Sozialwissenschaftler:innen</a> sind im Rahmen des Projekts <i>Experimentierraum Digitale Medienkompetenz</i> als Teil von <a href=\"https://tu-dresden.de/gsw/virtuos/\">virTUos</a> entstanden. Erstellt wurden sie von Yannick Frommherz unter Mitarbeit von Anne Josephine Matz. Sie stehen als Open Educational Resource nach <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY SA</a> zur freien Verf√ºgung. F√ºr Feedback und bei Fragen nutz bitte das <a href=\"https://forms.gle/VsYJgy4bZTSqKioA7\">Kontaktformular</a>.\n",
    "        </td>\n",
    "      </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
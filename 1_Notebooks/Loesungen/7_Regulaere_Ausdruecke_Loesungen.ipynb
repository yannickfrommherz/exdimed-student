{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27ff4b2-2faf-4d13-9017-3d3c1a72232f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Reguläre Ausdrücke (Lösungen)\n",
    "\n",
    "☝️ Beachte: Es gibt beim Programmieren fast immer verschiedene Lösungswege. Deine Lösung mag anders aussehen, aber dennoch zum gewünschten Resultat führen. Das richtige Resultat ist das Wichtigste. \n",
    "\n",
    "⚠️ Führ folgenden Code aus, bevor Du einzelne Lösungen ausführst. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1335f2-1f05-447f-9d27-de084c059165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce356580-8d86-4b5d-9e51-24ecafb87d4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ **Übung 1:** Find heraus, wie viele Male drei aufeinanderfolgende \"f\" im string ```text``` vorkommen. ```regex``` soll Deinen regulären Ausdruck referenzieren. Es handelt sich dabei ebenfalls um einen string, allerdings mit einem dem öffnenden Anführungszeichen vorangestellten \"r\"/\"R\". Wie bei f-strings im Notebook \"Input und Output Teil 2\" teilen wir Python damit mit, dass der folgende string anders als ein normaler string zu interpretieren ist (wie genau, sind technische Details, die für uns nicht relevant sind, vgl. ebenfalls Notebook \"Input und Output Teil 1\" zu Dateipfaden bei Windows). \n",
    "\n",
    "Der Rest des Codes ist bereits fertig geschrieben. Grob formuliert, nimmt die ```findall```-Funktion des ```re```-Moduls Deinen regulären Ausdruck (```regex```) und sucht ```text``` von links nach rechts danach ab. Alle matches landen in einer Liste, die mit ```matches``` referenziert wird und deren Länge wir uns abschließend ausgeben lassen. Die Ausgabe sollte natürlich ```3``` sein, sobald Du den korrekten regulären Ausdruck bei ```regex``` ausgefüllt hast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0b4e5-70d3-4027-9f3b-a90070625974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Schadstofffreie Schifffahrt dank Auspufffilter\"\n",
    "regex = r\"f{3}\" #verlangt genau drei \"f\" hintereinander\n",
    "\n",
    "matches = re.findall(regex, text)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304110c-63d5-4dff-b4ae-18c053a92c14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ **Übung 2:** Kopier den Text eines beliebigen Artikels einer Online-Zeitung (z.&nbsp;B. von [ZEIT Online](https://www.zeit.de), [tagesschau.de](https://www.tagesschau.de) oder den [Dresdner Neuesten Nachrichten](https://www.dnn.de)). Einzige Bedingung: Der Artikel sollte Zitate beinhalten. Füg den Text als string bei ```text``` unten ein. Formulier nun reguläre Ausdrücke für folgende Suchaufträge:\n",
    "\n",
    "1. alle kleingeschriebenen Wörter mit drei Buchstaben\n",
    "2. alle Wörter mit Großbuchstaben am Anfang\n",
    "3. alle Zitate (dieser reguläre Ausdruck beinhaltet vermutlich doppelte Anführungszeichen; umschließ den string zwecks korrekter Abgrenzung daher mit drei einfachen Anführungszeichen)\n",
    "\n",
    "Lass Dir anschließend alle Listen schön formatiert ausgeben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659810a6-da26-44a9-92d5-ad11d0153278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zur Lösung verwendeter Text stammt von https://www.mdr.de/nachrichten/sachsen/bautzen/goerlitz-weisswasser-zittau/bahnstrecke-berlin-goerlitz-ice-ausbau-fahrgastverband-wirtschaftsministerium-100.html\n",
    "text = \"\"\"Ein ICE von Berlin nach Görlitz: Das ist allenfalls Zukunftsmusik. Auch wenn Sachsens Ministerpräsident Michael Kretschmer (CDU) unlängst mitteilte, die ICE-Strecke zwischen Berlin und Görlitz werde umgesetzt, fährt noch lange kein ICE aus der Bundeshauptstadt in die niederschlesische Metropole. Das SPD-geführte sächsische Wirtschaftsministerium stellt auf Nachfrage von MDR SACHSEN klar: Ziel sei es, \"die bestehende Schienenverbindung zwischen Cottbus und Görlitz durchgängig zweigleisig zu elektrifizieren sowie auf eine Geschwindigkeit von bis zu 160 km/h zu ertüchtigen.\" Dies sei im Investitionsgesetz für die Kohleregionen aufgelistet.\n",
    "Darüber hinaus soll die Elektrifizierung des Bahnhofes Görlitz als sogenannte Systemtrennstelle mit Anschluss an das polnische Gleichstromsystem umgesetzt werden. Den Begriff der \"ICE-Strecke\" erachte das Wirtschaftsministerium \"dabei als irreführend, da ein Ausbau von Schieneninfrastruktur grundsätzlich allen Verkehrsträgern dient und nicht auf den Einsatz bestimmter Produktgattungen ausgerichtet ist\". Im Klartext: Wenn kein Bedarf besteht, fahren auch künftig nur Regionalzüge zwischen Görlitz und Cottbus mit Umsteigen Richtung Berlin. Warum Kretschmer von einer ICE-Strecke spricht, wollte die Staatskanzlei auf Nachfrage nicht beantworten und verwies auf die Ausführungen des zuständigen Wirtschaftsministeriums.\n",
    "Ausbauplan bis 2038 Aus dem Wirtschaftsministerium hieß es weiter, \"nach Angaben der Deutschen Bahn sollen die Bauarbeiten bis Ende 2038 abgeschlossen werden\". Die Investitionssumme werde auf etwa 1,65 Milliarden Euro geschätzt. Über den bestellten Zugverkehr, der nach Ausbau angeboten und von den Ländern bezahlt werden soll, führe man mit Brandenburg Gespräche. Über möglichen Fernverkehr entscheidet die DB selbst. Auch ein anderer Anbieter, wie etwa Flixtrain, könnte theoretisch auf eigene Kosten dort fahren. \n",
    "Deutsche Bahn äußert sich zurückhaltend zu Kosten und Zeitplan Die Deutsche Bahn verweist auf noch laufende Planungen und äußert sich weder zu Zeitplan noch zu Kosten. \"Mit dem Investitionsgesetz Kohleregionen (InvKG) hat der Bund die Grundlage für den weiteren Ausbau der Bahnstrecke zwischen Berlin und Görlitz geschaffen.\" Im Abschnitt Berlin – Cottbus liege \"der Fokus auf Einzelmaßnahmen an der Strecke und den Bahnhöfen. Auf dem Abschnitt Cottbus - Görlitz sind ein durchgehend zweigleisiger Ausbau und die Elektrifizierung der Strecke vorgesehen.\" \n",
    "Es gehe darum, die bisherige Braunkohle-Regionen nach dem Ende des Abbaus besser an Metropolregionen anzubinden. \"Die mit der schrittweisen Umsetzung der strukturstärkenden Maßnahmen einhergehenden Nachfrageentwicklungen wird die DB bei der Angebotsplanung berücksichtigen\", verspricht der Verkehrskonzern, ohne konkret einen ICE anzukündigen.\n",
    "Fahrgastverband zweifelt an ICE nach Görlitz Vom Fahrgastverband Pro Bahn hieß es: \"Das Statement von Ministerpräsident Kretschmer ist in der Tat schwerlich einzuordnen, weil ein ICE-Zug als Besonderheit grundsätzlich nur eine elektrifizierte Trasse braucht.\" Frühere Pläne zum Ausbau für Geschwindigkeiten von 200 Stundenkilometer und mehr seien inzwischen Geschichte. Der Fahrgastverband sei skeptisch, dass die DB eigenwirtschaftlich ICE-Züge anbieten wird. Eine Bezahlung von Fernverkehr durch Länder, wie derzeit zwischen Dresden und Chemnitz oder Erfurt und Gera sei aber nur ein Notlösung. Seit der Bahnreform mit Fusion der Deutschen Reichsbahn und der Deutschen Bundesbahn zur Deutschen Bahn AG wird Regionalverkehr von Ländern bezahlt, Fernverkehrszüge betreibt die DB AG unter wirtschaftlichen\n",
    "Fokus auf Eurocity statt Binnenverkehrs-ICE Laut Fahrgastverband ist es \"ein generelles Versäumnis der Politik und der Bahn, dass die Fernverkehrsentwicklung auf den ICE fokussiert wurde und nicht die enormen Potentiale einer gemeinsamen Entwicklung des Fernverkehrs der Lausitz mit polnischen und tschechischen Nachbarn in den Blick genommen wurde\". Der ICE ist \"nicht polen- und tschechientauglich\" - also unter dortiger Oberleitung nicht einsetzbar. Das liegt an unterschiedlichen Stromsystemen der europäischen Eisenbahnen. \"DB Fernverkehr hat in seinem Bestand keine einzige Lok, die technisch in der Lage wäre, nach Polen und Tschechien zu fahren\", so der Fahrgastverband. (Im Bestand der DB AG gibt es ICE-Mehrsystemzüge, die planmäßig und täglich nach Frankreich, Belgien, in die Niederlande und in die Schweiz fahren. Anm. der Redaktion)\n",
    "Weiter heißt es: \"PKP Intercity würde längst Züge bis in den Görlitzer Hauptbahnhof fahren lassen, wenn die deutsche Seite die 800 Meter Fahrdraht, die zwischen 1923 und 1946 bereits hier hingen, vom Neißeviadukt bis in den Hauptbahnhof Görlitz gezogen hätte.\" 2003 hätten sich Polen und Deutschland in einem Staatsvertrag hierzu verpflichtet. \"Auf der polnischen Seite wurde dieser Staatsvertrag zeitnah realisiert, auf deutscher Seite nicht.\"\n",
    "Lausitz war einst europäisches Schienendrehkreuz Die Lausitz war laut Fahrgastverband \"einst ein Drehkreuz des europäischen Schienenverkehrs\". In Cottbus und Görlitz hätten sich Verkehrsströme des Ost-West und des Nord-Süd-Verkehrs gekreuzt. \"Würde man den Fokus statt auf ICE-Züge beispielsweise auf Eurocity-Züge Berlin - Cottbus - Wroclaw - Kraków - Przemysl -Lwiw - Kiew oder Frankfurt/Main - Leipzig - Dresden - Görlitz - Wroclaw - Warschau legen, so wären solche Verkehre sicherlich wirtschaftlicher realisierbar als innerdeutsche 'Endverkehre' Berlin - Cottbus - Görlitz. Zudem könnte die polnische Seite auch den Flughafen Berlin-Brandenburg BER aus Wroclaw kommend direkt anfahren. \"Daran hat sie schon vor Jahren großes Interesse bekundet.\"\n",
    "Zwischen Berlin und Cottbus, wo die Bahn ein ICE-Werk plant, ist die Strecke elektrifiziert und wird auch jetzt schon von einzelnen Intercitys befahren. Zwischen Cottbus und Görlitz über Weißwasser fahren Dieseltriebwagen der Ostdeutschen Eisenbahn-Gesellschaft (ODEG). In diesem Abschnitt muss ein Streckenausbau auch um den Tagebau Reichwalde geplant werden.\n",
    "Zugleich fordert der Fahrgastverband von Görlitz weiter bis Zittau die Bahnstrecke zu elektrifizieren, um auf tschechischer Seite über Liberec bis Prag modernen Fernverkehr anbieten zu können. Auch die Trasse Dresden - Bautzen - Görlitz müsse \"zeitnah\" elektrifiziert und ertüchtigt werden. \"Wichtig ist aber, dass diese Strecken finanziell nicht gegeneinander ausgespielt werden\", so Pro Bahn.\"\"\"\n",
    "\n",
    "\"\"\"Whitespace vor und nach den Ausdrücken in 'regex_1' und 'regex_2' sind notwendig, \n",
    "da 'findall' sonst auch innerhalb von Wörtern matcht (elegantere Lösung siehe 'Weitere Sonderzeichen').\"\"\"\n",
    "regex_1 = r\" [a-zäöüß]{3} \"\n",
    "regex_2 = r\" [A-ZÄÖÜ]\\w* \"\n",
    "\"\"\"Beachte, dass 'regex_3' auf den obigen Text zugeschnitten ist und bei Dir vermutlich anders aussieht\"\"\"\n",
    "regex_3 = r'''\".*?\"''' #Beliebig viele beliebige Zeichen innerhalb von Anführungszeichen, mit gebändigter Gier (d. h. kürzestmöglichster match).\n",
    "\n",
    "three_letter_words = re.findall(regex_1, text)\n",
    "capital_words = re.findall(regex_2, text)\n",
    "quotes = re.findall(regex_3, text)\n",
    "\n",
    "\"\"\"Konvertieren der Listen in einen string (mittels 'join', vgl. Notebook \"Datentypen\"), \n",
    "wobei wir erst mittels List Comprehension trailing und leading whitespace bei jedem Element entfernen\"\"\"\n",
    "print(\"Kleingeschriebene Wörter mit drei Buchstaben: \", \", \".join([word.strip() for word in three_letter_words]), \"\\n\")\n",
    "print(\"Großgeschriebene Wörter: \", \", \".join([word.strip() for word in capital_words]), \"\\n\")\n",
    "\n",
    "print(\"Zitate:\")\n",
    "print(len(quotes))\n",
    "for quote in quotes:\n",
    "    print(quote, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba09c4-f4d8-436c-8cbe-a2e3406fb5f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "✏️ **Übung 3:** Angelehnt an das Beispiel mit den Links auf [tu-dresden.de](https://tu-dresden.de) sollst Du in dieser Übung ebenfalls Links von einer bestimmten Webseite (bzw. aus dessen Quelltext) extrahieren. \n",
    "\n",
    "1. Öffne dazu den [Spielplan der Bundesligasaison 2019-2020 auf weltfussball.de](https://www.weltfussball.de/alle_spiele/bundesliga-2019-2020/). Nun wollen wir den Quelltext dieser Seite herunterladen. Da wir noch über keine Web-Scraping-Skills verfügen, machen wir es manuell. Geh dazu je nach Browser wie folgt vor:\n",
    "\n",
    "    - bei Google Chrome und Firefox mittels Rechtsklick \"Seitenquelltext anzeigen\" wählen\n",
    "    - bei Safari mittels Rechtsklick \"Seitenquelltext einblenden\" wählen\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    Markier und kopier nun den kompletten Quelltext und speicher ihn in einem neuen Dokument, das Du unter dem Namen \"quelltext.txt\" im Ordner \"3_Dateien/Fussball\" abspeicherst. Für diesen Vorgang empfiehlt sich das im Notebook \"Funktionen und Methoden Teil 2\" erwähnte [Sublime Text](https://www.sublimetext.com).\n",
    "\n",
    "    Der Quelltext im Browser sollte übrigens so oder so ähnlich ausschauen:\n",
    "\n",
    "    <img src=\"../../3_Dateien/Grafiken_und_Videos/Quelltext.png\">\n",
    "\n",
    "2. Öffne das Dokument wie im Notebook \"Input und Output Teil 1\" gelernt, lies es ein und weis es der Variablen ```source_code``` zu.\n",
    "\n",
    "3. Geh noch einmal zum [Spielplan](https://www.weltfussball.de/alle_spiele/bundesliga-2019-2020/) im Browser und öffne einige Spielberichte, indem Du auf die jeweiligen Spielergebnisse klickst. Schau Dir die Adresszeile an und analysier, wie die Links aufgebaut sind sowie worin sie sich unterscheiden. Schau ebenfalls im Quelltext nach, wie die Links da aussehen.\n",
    "\n",
    "4. Formulier darauf aufbauend einen regulären Ausdruck, der sämtliche Links zu allen Spielberichten im Quelltext matcht. Füg ihn als string bei der Variablen ```regex``` ein. Ist der reguläre Ausdruck korrekt, sollte ```matches``` 306 Links beinhalten. Sowohl bei ```regex``` als auch bei ```matches``` musst Du natürlich noch die Hashtags entfernen.\n",
    "\n",
    "5. Erstell eine Liste mit vollständigen Links zu allen Spielberichten und lass sie Dir ausgeben. Probier einige der Links aus.\n",
    "\n",
    "Quelle: Übung modifiziert übernommen von Prof. Simon Meier-Vierackers Kurs [Reading Machines - Einführung in die Korpuslinguistik](https://padlet.com/simonmeiervieracker/readingmachines), der unter dem angegebenen Link frei zugänglich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce8c1e-7103-4c7f-8644-e00a6dddb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das Lösungsnotebook in einem anderen Verzeichnis liegt \n",
    "#Code funktioniert erst, nachdem Du das Dokument \"quelltext.txt\" erstellt hast!\n",
    "with open(\"../../3_Dateien/Fussball/quelltext.txt\") as f:\n",
    "    source_code = f.read()\n",
    "    \n",
    "regex = r\"/spielbericht/[\\w-]+/\" #Literal \"/spielbericht/\", ein oder mehrere alphanumerische Zeichen bzw. literal \"-\", literal \"/\"\n",
    "matches = re.findall(regex, source_code)\n",
    "\n",
    "#Erstellen von vollständigen Links\n",
    "links = []\n",
    "for match in matches:\n",
    "    links.append(\"www.weltfussball.de\" + match)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9bb5a-4521-4771-9afc-8de074652c89",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ **Übung 4:** Lies das Märchen \"Des Kaisers neue Kleider\" von Hans Christian Andersen aus dem Ordner \"3_Dateien\" ein und weis es ```fairytale``` zu. Formulier nun reguläre Ausdrücke für folgende Suchaufträge:\n",
    "\n",
    "1. das erste Wort des Märchens\n",
    "2. regelmäßige Verben in der 3. Person Singular/Plural im Präteritum (z.&nbsp;B. \"lebte\" oder \"sagten\"; es ist in Ordnung, wenn Du mit diesem regulären Ausdruck auch ein paar falsch positive matches kriegst 🤫, vgl. Wahrheitsmatrix im Notebook \"Input und Output Teil 1\")\n",
    "3. letzte Wörter von Sätzen, die mit einem Punkt enden (z.&nbsp;B. \"einherzugehen\", vgl. erster Satz des Märchens)\n",
    "4. Wörter mit Doppel-a (z.&nbsp;B. \"Saal\")\n",
    "5. das letzte Wort des Märchens\n",
    "\n",
    "Da wir bei der ersten und letzten Aufgabe nicht nach *allen* matches suchen, sondern nur an einem einzigen interessiert sind (es kann ja auch nur jeweils einen match geben), verwenden wir eine neue Funktion, nämlich ```search```, auf die wir unten genauer eingehen. Dabei erhalten wir keine Liste zurück, sondern ein sog. *match-Objekt*, wobei wir auf den eigentlichen match wie im ```print```-Statement bereits vorgegeben zugreifen können. Überhaupt sollte das ```print```-Statement das Ergebnis aller fünf Suchaufträge schön formatiert ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365227b-3ad8-4a07-b596-d869385dd4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das Lösungsnotebook in einem anderen Verzeichnis liegt\n",
    "with open(\"../../3_Dateien/Des_Kaisers_neue_Kleider/Des_Kaisers_neue_Kleider.txt\") as f:\n",
    "    fairytale = f.read()\n",
    "\n",
    "regex_1 = r\"^\\w+\" #String-Anfang, ein oder mehrere ASCII-Zeichen (noch besser wäre eigene Klasse [A-Za-zÄäÖöÜüß], da sonst ein string-Anfang mit Umlaut/Eszett nicht gematcht würde; gilt auch unten)\n",
    "regex_2 = r\"\\b[a-zäöüß]+ten?\\b\" #Wortgrenze, ein oder mehrere kleingeschriebene Buchstaben, literal \"t\" und \"e\", optional literal \"n\", Wortgrenze\n",
    "regex_3 = r\"[A-Za-zÄäÖöÜüß]+\\.\" #Ein oder mehrere literale Buchstaben, literal \".\" (maskiert mit \"\\\", da sonst Wildcard)\n",
    "regex_4 = r\"\\b\\w*[a]{2}\\w*\\b\" #Wortgrenze, null oder mehrere ASCII-Zeichen, zwei literale \"a\", null oder mehrere ASCII-Zeichen, Wortgrenze\n",
    "regex_5 = r\"\\w+\\.$\" #Ein oder mehrere ASCII-Zeichen, ein literaler \".\" (maskiert), string-Ende\n",
    "\n",
    "first_word = re.search(regex_1, fairytale)\n",
    "verbs = re.findall(regex_2, fairytale)\n",
    "last_words = re.findall(regex_3, fairytale)\n",
    "double_vowel = re.findall(regex_4, fairytale)\n",
    "last_word = re.search(regex_5, fairytale)\n",
    "\n",
    "print(first_word.group(), \"\\n\\n\", verbs, \"\\n\\n\", [word.strip(\".\") for word in last_words], \"\\n\\n\", double_vowel, \"\\n\\n\", last_word.group().strip(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d7d5d-7f6d-4e84-8f30-577e984d6203",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "✏️ **Übung 5:** Im Notebook \"Funktionen und Methoden Teil 1\" in Übung 2 haben wir gesehen, dass das Wort \"Klima\" viel häufiger im Koalitionsvertrag von 2021 als in demjenigen von 2018 vorkommt. Nun wollen wir herausfinden, in welcher Form das Wort verwendet wird. Neben dem alleinstehenden Auftreten von \"Klima\" (als sog. *Simplex*, da es aus nur einem Morphem besteht) ist \"Klima\" bzw. \"klima\" häufig Teil von zusammengesetzten Wörtern, also sog. *Komposita*, wie etwa in \"Klimakrise\" oder \"klimapolitisch\".  \n",
    "\n",
    "Lies den Koalitionsvertrag von 2021 noch einmal ein und weis ihn der Variablen ```kv21``` zu. Durchsuch ihn nun nach einem regulären Ausdruck, der sämtliche Komposita, in denen \"Klima\" bzw. \"klima\" vorkommt, matcht. Häng alle Komposita der Liste ```climate_compounds``` an und lass Dir abschließend die Liste ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fae76-63db-4020-8cf4-ba003ba6269b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das Lösungsnotebook in einem anderen Verzeichnis liegt\n",
    "import re\n",
    "with open(\"../../3_Dateien/Koalitionsvertraege/koalitionsvertrag_2021.txt\", encoding=\"utf-8\") as f:\n",
    "    kv21 = f.read()\n",
    "    \n",
    "regex = r\"[Kk]lima\\S+\\b\" #Groß- oder kleingeschriebenes 'k', gefolgt von literal 'lima', einem oder mehr Zeichen, die nicht whitespace sind und einer Wortgrenze\n",
    "\n",
    "climate_compounds = re.findall(regex, kv21)\n",
    "    \n",
    "print(climate_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74a10e-2193-4f6d-b500-fdba33076769",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ **Übung 6:** Find alle Substantive mit definitem Artikel (z.&nbsp;B. \"der\" oder \"dem\") in `text`, der der Einleitung des [ Wikipedia-Artikels zu regulären Ausdrücken](https://de.wikipedia.org/wiki/Regulärer_Ausdruck) entspricht (Stand: 26.10.2022). Der Artikel (des Substantivs) sollte jeweils mitgemacht werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869fd7c-0069-438e-a135-cac39c71fb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Ein regulärer Ausdruck (englisch regular expression, Abkürzung RegExp oder Regex) ist in der theoretischen Informatik eine Zeichenkette, die der Beschreibung von Mengen von Zeichenketten mit Hilfe bestimmter syntaktischer Regeln dient. Reguläre Ausdrücke finden vor allem in der Softwareentwicklung Verwendung. Neben Implementierungen in vielen Programmiersprachen verarbeiten auch viele Texteditoren reguläre Ausdrücke in der Funktion „Suchen und Ersetzen“. Ein einfacher Anwendungsfall von regulären Ausdrücken sind Wildcards.\n",
    "Reguläre Ausdrücke können als Filterkriterien in der Textsuche verwendet werden, indem der Text mit dem Muster des regulären Ausdrucks abgeglichen wird. Dieser Vorgang wird auch Pattern Matching genannt. So ist es beispielsweise möglich, alle Wörter aus einer Wortliste herauszusuchen, die mit S beginnen und auf D enden, ohne die dazwischen liegenden Buchstaben oder deren Anzahl explizit vorgeben zu müssen.\n",
    "Der Begriff des regulären Ausdrucks geht im Wesentlichen auf den Mathematiker Stephen Kleene zurück, der die ähnliche Bezeichnung reguläre Menge verwendete.\"\"\"\n",
    "\n",
    "regex = r\"(\\b(D|d)(er|ie|as|es|em|en) [A-ZÄÖÜ][a-zäöüß]*\\b)\" #Wortgrenze, literal \"D\" oder \"d\", literal \"er\", \"ie\", \"as\", \"es\", \"em\" oder \"en\", Leerzeichen, beliebiger Großbuchstabe, beliebig viele Kleinbuchstaben, Wortgrenze\n",
    "matches = re.findall(regex, text)\n",
    "\n",
    "#Nur den gesamten match (Hauptgruppe) ausgeben lassen\n",
    "print([match[0] for match in matches])\n",
    "\n",
    "#Den gesamten match (Hauptgruppe) und alle anderen Gruppen ausgeben lassen\n",
    "print([match for match in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89be60-8e3c-492c-92d6-355d428e647c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ <b>Übung 7 (🦊 fortgeschritten)</b>: Gegeben sind kurze Beschreibungen von fünf Personen in ```people```. In jeder Beschreibung findet sich der Vor- und Nachname, das Geburtsdatum sowie die E-Mailadresse der Person. Wir wollen daraus ein kleines Adressbuch in tabellarischer Form schaffen. Ziel ist es, die Daten wie im Screenshot gezeigt in die Datei \"address_book.tsv\" im Ordner \"3_Dateien/Output\" zu schreiben: \n",
    "\n",
    "<img src=\"../../3_Dateien/Grafiken_und_Videos/address_book.png\">\n",
    "\n",
    "Zwischen den Namen und dem Geburtstag sowie dem Geburtstag und der E-Mailadresse soll also ein Tab stehen, da Dateien mit der Endung \".tsv\" tabulatorsepariert sind (dem gleichen Prinzip wie kommaseparierte Dateien folgend, vgl. Notebook \"Input und Output Teil 2\").\n",
    "\n",
    "Formulier *einen* regulären Ausdruck, um fünf matches zu erhalten (einen pro Person), und nutz Gruppen, um die Elemente *Nachname*, *Vorname*, *Geburtstag* und *E-Mailadresse* als Teilmatch separat zu erhalten. Öffne und beschreib anschließend die Datei \"address_book.tsv\", sodass jede Person in einer eigenen Zeile sowie jedes Element in einer eigenen Spalte abgespeichert wird.\n",
    "\n",
    "Quelle: Übung modifiziert übernommen von Prof. Simon Meier-Vierackers Kurs [Reading Machines - Einführung in die Korpuslinguistik](https://padlet.com/simonmeiervieracker/readingmachines), der unter dem angegebenen Link frei zugänglich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9a559-105e-4883-9405-820c5d81d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = \"\"\"Detlef SCHULZ hat am 21.03.1967 Geburtstag, und das ist seine Emailadresse: schulz-detlef@gmail.net \n",
    "Ina SCHULTER wurde am 02.04.1992 geboren und ihre E-Mail-Adresse lautet: inaschulter@gmx.de\n",
    "Katharina Anne LAMAI ist ein Dezemberkind, ihr Geburtstag ist der 08.12.1955 geboren und ihre E-Mail-Adresse lautet: KaAnLa@yahoo.com\n",
    "Anuk MARGA ist am 15.01.1988 auf die Welt gekommen, ihre E-Mail-Adresse lautet: MargAnuk@gmail.com\n",
    "Albus Percival Wulfric Brian DUMBLEDORE hat 17.06.1881 das Licht der Welt erblickt. Er hat sogar eine Emailadresse: fresh-dumbledore@hogwarts.com\"\"\"\n",
    " \n",
    "#Beachte: Mehr denn je können unzählige andere Lösungen auch korrekt sein!\n",
    "\n",
    "\"\"\"Mindestens ein beliebiges Zeichen (außer Zeilenumbruch), gefolgt von einem Leerschlag, gefolgt von mindestens einem Großbuchstaben,\n",
    "gefolgt von einem Leerschlag, gefolgt von mindestens einem beliebigen Zeichen (außer Zeilenumbruch), gefolgt von einem Leerschlag,\n",
    "gefolgt von zwei Zahlen, einem Punkt (maskiert), zwei Zahlen, einem Punkt (maskiert), vier Zahlen, gefolgt von einem Leerschlag,\n",
    "gefolgt von mindestens einem beliebigen Zeichen (außer Zeilenumbruch), gefolgt von Leerschlag, gefolgt von mindestens einem beliebigen Zeichen, \n",
    "das nicht whitespace ist, gefolgt von literal '@', gefolgt von mindestens einem beliebigen Zeichen, das nicht whitespace ist;\n",
    "regulärer Ausdruck funktioniert, da die Wildcard keinen Zeilenumbruch matcht und sich von daher nicht die ganze Beschreibung 'einverleiben' kann,\n",
    "da sonst der Rest des regulären Ausdrucks nicht mehr zuträfe (vgl. Tipp im zugehörigen Notebook)\"\"\"\n",
    "regex = r\"(.+) ([A-Z]+) .+ (\\d{2}\\.\\d{2}\\.\\d{4}) .+ (\\S+@\\S+)\"\n",
    "\n",
    "matches = re.findall(regex, people)\n",
    "\n",
    "#Achtung: anderer Pfad als im Notebook, da das Lösungsnotebook in einem anderen Verzeichnis liegt\n",
    "with open(\"../../3_Dateien/Output/address_book.tsv\", \"w\") as f:\n",
    "    f.write(\"Name\\tBirthday\\tMail address\\n\")\n",
    "    for match in matches:\n",
    "        f.write(match[1] + \", \" + match[0] + \"\\t\" + match[2] + \"\\t\" + match[3] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09267c5-2f4c-4db3-b172-cfa043e9312e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "✏️ **Übung 8:** Bei ```birth_notices``` handelt es nun um eine Liste mit mehreren Geburtsanzeigen. Deine Aufgabe ist es, die Geburtsdaten der Neugeboreren mithilfe eines regulären Ausdrucks sowie einer geeigneten Funktion des ```re```-Moduls aus den Anzeigen zu extrahieren und einer Liste namens ```birth_dates``` anzuhängen. Lass Dir abschließend ```birth_dates``` ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7deb52-659a-412c-bafc-7138f0e989c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "birth_notices = [\"Lena erblickte am 1. September 2022 die Welt.\",\n",
    "                 \"Petra kam am 28. Februar 2022 zur Welt.\",\n",
    "                 \"Yusuf strahlte uns am 14. Dezember 2022 mit glänzenden Äuglein an.\", \n",
    "                 \"Juans Leben begann am sonnigen 19. August 2022.\",\n",
    "                 \"Robert bereichert seit dem 5. Mai 2022 unser Leben.\",\n",
    "                 \"Mi beglückt uns seit dem 1. März 2022.\"]\n",
    "\n",
    "birth_dates = []\n",
    "\n",
    "'''Ein oder zwei Zahlen, gefolgt von escapdem \".\", einem Leerzeichen, einem oder mehreren alphanumerischen Zeichen bzw. \"ä\" (vgl. \"März\",\n",
    "einem Leerzeichen und vier Zahlen'''\n",
    "regex = r\"\\d{1,2}\\. (\\w|ä)+ \\d{4}\" \n",
    "\n",
    "for notice in birth_notices:\n",
    "    birth_dates.append(re.search(regex, notice).group())\n",
    "\n",
    "print(birth_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac1a0d-eda7-4f9d-ab82-37b86daf969f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ **Übung 9:** Gegeben sind in ```people``` noch einmal die Personenbeschreibungen aus Übung 7 sowie die Musterlösung für den regulären Ausdruck in ```regex```. ```regex``` beinhaltet Gruppen, auf deren Teilmatches wir zurückgreifen können. Formulier unter Zuhilfenahme von Rückreferenzen einen regulären Ausdruck für ```replacement```, um anschließend ```people``` mithilfe von ```re.sub``` in dasselbe Format wie in Übung 7 zu bringen:\n",
    "\n",
    "\"Nachname, Vorname \\t Geburtsdatum \\t E-Mailadresse\" \n",
    "\n",
    "Es reicht diesmal, wenn Du das Dir das Ergebnis einfach ausgeben lässt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53213fb7-93dd-4bac-97d2-bc7a3f2d8c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "people = \"\"\"Detlef SCHULZ hat am 21.03.1967 Geburtstag, und das ist seine Emailadresse: schulz-detlef@gmail.net \n",
    "Ina SCHULTER wurde am 02.04.1992 geboren und ihre E-Mail-Adresse lautet: inaschulter@gmx.de\n",
    "Katharina Anne LAMAI ist ein Dezemberkind, ihr Geburtstag ist der 08.12.1955 geboren und ihre E-Mail-Adresse lautet: KaAnLa@yahoo.com\n",
    "Anuk MARGA ist am 15.01.1988 auf die Welt gekommen, ihre E-Mail-Adresse lautet: MargAnuk@gmail.com\n",
    "Albus Percival Wulfric Brian DUMBLEDORE hat 17.06.1881 das Licht der Welt erblickt. Er hat sogar eine Emailadresse: fresh-dumbledore@hogwarts.com\"\"\"\n",
    " \n",
    "regex = r\"(.+) ([A-Z]+) .+ (\\d{2}\\.\\d{2}\\.\\d{4}) .+ (\\S+@\\S+)\" #Erklärung des regulären Ausdrucks siehe Lösung 7\n",
    "replacement = r\"\\2, \\1\\t\\3\\t\\4\" #Ersetzungsmuster: zweiter Teilmatch, ein Komma, Leerzeichen, erster Teilmatch, Tabstopp, dritter Teilmatch, Tabstopp, vierter Teilmatch\n",
    "\n",
    "people_formatted = re.sub(regex, replacement, people)\n",
    "\n",
    "print(people_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72efa2f3-0ace-40ac-a30d-af5ed76ba0f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "✏️ **Übung 10:** ```birth_dates``` von oben ist nun etwas länger und beinhaltet mehr Geburtsdaten. Ziel ist es, sämtliche Geburtsdaten in das Datumsformat nach [ISO 8601](https://de.wikipedia.org/wiki/Datumsformat#ISO_8601_und_EN_28601), also YYYY/MM/DD, zu bringen. Geh dazu wie folgt vor:\n",
    "\n",
    "1. Wenn nötig, pass ```regex``` an, damit auch alle neuen Geburtsdaten gematcht werden.\n",
    "2. Setz Klammern in ```regex```, um relevante Teile eines matches zu gruppieren.\n",
    "3. Pass die Funktion ```to_ISO_format``` an, damit jedes einzelne match-Objekt entsprechend IS0 8601 umstrukturiert wird. Bei zweistelligen Jahreszahlen unter und gleich 22 kannst Du davon ausgehen, dass sie sich auf das 21. Jahrhundert beziehen, ansonsten auf das 20. Jahrhundert.\n",
    "\n",
    "Der Funktionsaufruf innerhalb von ```re.sub(...)``` ist korrekt, so wie er gegeben ist (es fehlen also keine Klammern!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e7cce2-3023-4418-8aab-baf0ab329c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "birth_dates = \"\"\"Ich bin am 09.08.1992 geboren, meine Schwester am 3.4.95 und unser Bruder am 9.10.1998. \n",
    "Unsere Mutter ist am 23.10.1967 geboren und unser Vater am 14.1.68. \n",
    "Der letzte Familienzuwachs ist die Tochter meines Bruders, die am 1.1.2022 geboren wurde.\"\"\"\n",
    "\n",
    "'''Ein oder zwei Zahlen (1. Teilmatch), gefolgt von escapdem \".\", ein oder zwei Zahlen (2. Teilmatch),\n",
    "escapdem \".\", optionalem, literalem \"19\" oder \"20\" sowie zwei Zahlen (3. Teilmatch)'''\n",
    "regex = r\"(\\d{1,2})\\.(\\d{1,2})\\.((19|20)?\\d{2})\"\n",
    "\n",
    "def to_ISO_format(match_object):\n",
    "    \n",
    "    two_digit_year = match_object.group(3)[-2:] #Zugriff auf die letzten beiden Ziffern mittels Slicing\n",
    "    \n",
    "    year = f\"{'19' + two_digit_year if int(two_digit_year) > 22 else '20' + two_digit_year}\" #Ergänzen von 'two_digit_year' um \"19\" bzw. \"20\"\n",
    "    month = f\"{int(match_object.group(2)):02}\" #Zero-padden des zweiten Teilmatches auf zwei Stellen\n",
    "    day = f\"{int(match_object.group(1)):02}\" #Zero-padden des ersten Teilmatches auf zwei Stellen \n",
    "    \n",
    "    return year + \"/\" + month + \"/\" + day #Rückgabe des konvertierten Datums \n",
    "     \n",
    "iso_dates = re.sub(regex, to_ISO_format, birth_dates) #Matchen von 'regex' in 'birth_dates' und Ersetzen aller Matches entsprechend 'to_ISO_format'\n",
    "print(iso_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c1025-4db1-4585-9baf-e5a46be8a502",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "**🔧 Anwendungsfall:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4f6f0-2364-4d81-b355-70ac3fa6e288",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Lösung zu beiden Teilaufgaben befindet sich in den Dateien \"pizzabot_solved_documented.py\" und \"pizza_functions_documented\" im Ordner \"3_Dateien\". Der verbesserte Pizzabot kann in der folgenden Zelle getestet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dd53c-4972-465e-b64f-c95009823999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Diese beiden Zeilen kannst Du ignorieren (sie sind nötig, da sich das zu importierende Modul \n",
    "in einem anderen Verzeichnis als das Notebook befindet (vgl. Notebook \"Funktionen und Methoden Teil 2\")\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../../3_Dateien/Module/\")\n",
    "\n",
    "import pizzabot_solved_documented as pizzabot\n",
    "pizzabot.order_pizza()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee666f32-be9d-4073-a7d8-6f528babf0d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Weiter können die Muster-docstrings über folgende Zelle ausgegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb72bd7-4938-4c35-baa8-972a0fa59e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pizzabot_solved_documented import order_pizza\n",
    "from pizza_functions_documented import *\n",
    "\n",
    "print(\"order_pizza:\", order_pizza.__doc__, \"\\n\")\n",
    "print(\"yn_validator:\", yn_validator.__doc__, \"\\n\")\n",
    "print(\"choose_pizza:\", choose_pizza.__doc__, \"\\n\")\n",
    "print(\"remove_ingredient:\", remove_ingredient.__doc__, \"\\n\")\n",
    "print(\"add_ingredient:\", add_ingredient.__doc__, \"\\n\")\n",
    "print(\"request_address:\", request_address.__doc__, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb475ca-319b-4e53-b9ae-6c5be9532c4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "***\n",
    "<table>\n",
    "      <tr>\n",
    "        <td>\n",
    "            <img src=\"../../3_Dateien/Lizenz/CC-BY-SA.png\" width=\"400\">\n",
    "        </td> \n",
    "        <td>\n",
    "            <p>Dieses Notebook sowie sämtliche weiteren <a href=\"https://github.com/yannickfrommherz/exdimed-student/tree/main\">Materialien zum Programmierenlernen für Geistes- und Sozialwissenschaftler:innen</a> sind im Rahmen des Projekts <i>Experimentierraum Digitale Medienkompetenz</i> als Teil von <a href=\"https://tu-dresden.de/gsw/virtuos/\">virTUos</a> entstanden. Erstellt wurden sie von Yannick Frommherz unter Mitarbeit von Anne Josephine Matz. Sie stehen als Open Educational Resource nach <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY SA</a> zur freien Verfügung. Für Feedback und bei Fragen nutz bitte das <a href=\"https://forms.gle/VsYJgy4bZTSqKioA7\">Kontaktformular</a>.\n",
    "        </td>\n",
    "      </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
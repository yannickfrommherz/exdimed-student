{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27ff4b2-2faf-4d13-9017-3d3c1a72232f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Regul√§re Ausdr√ºcke (L√∂sungen)\n",
    "\n",
    "‚òùÔ∏è Beachte: Es gibt beim Programmieren fast immer verschiedene L√∂sungswege. Deine L√∂sung mag anders aussehen, aber dennoch zum gew√ºnschten Resultat f√ºhren. Das richtige Resultat ist das Wichtigste. \n",
    "\n",
    "‚ö†Ô∏è F√ºhr folgenden Code aus, bevor Du einzelne L√∂sungen ausf√ºhrst. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1335f2-1f05-447f-9d27-de084c059165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce356580-8d86-4b5d-9e51-24ecafb87d4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 1:** Find heraus, wie viele Male drei aufeinanderfolgende \"f\" im string ```text``` vorkommen. ```regex``` soll Deinen regul√§ren Ausdruck referenzieren. Es handelt sich dabei ebenfalls um einen string, allerdings mit einem dem √∂ffnenden Anf√ºhrungszeichen vorangestellten \"r\"/\"R\". Wie bei f-strings im Notebook \"Input und Output Teil 2\" teilen wir Python damit mit, dass der folgende string anders als ein normaler string zu interpretieren ist (wie genau, sind technische Details, die f√ºr uns nicht relevant sind, vgl. ebenfalls Notebook \"Input und Output Teil 1\" zu Dateipfaden bei Windows). \n",
    "\n",
    "Der Rest des Codes ist bereits fertig geschrieben. Grob formuliert, nimmt die ```findall```-Funktion des ```re```-Moduls Deinen regul√§ren Ausdruck (```regex```) und sucht ```text``` von links nach rechts danach ab. Alle matches landen in einer Liste, die mit ```matches``` referenziert wird und deren L√§nge wir uns abschlie√üend ausgeben lassen. Die Ausgabe sollte nat√ºrlich ```3``` sein, sobald Du den korrekten regul√§ren Ausdruck bei ```regex``` ausgef√ºllt hast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0b4e5-70d3-4027-9f3b-a90070625974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Schadstofffreie Schifffahrt dank Auspufffilter\"\n",
    "regex = r\"f{3}\" #verlangt genau drei \"f\" hintereinander\n",
    "\n",
    "matches = re.findall(regex, text)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304110c-63d5-4dff-b4ae-18c053a92c14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 2:** Kopier den Text eines beliebigen Artikels einer Online-Zeitung (z.&nbsp;B. von [ZEIT Online](https://www.zeit.de), [tagesschau.de](https://www.tagesschau.de) oder den [Dresdner Neuesten Nachrichten](https://www.dnn.de)). Einzige Bedingung: Der Artikel sollte Zitate beinhalten. F√ºg den Text als string bei ```text``` unten ein. Formulier nun regul√§re Ausdr√ºcke f√ºr folgende Suchauftr√§ge:\n",
    "\n",
    "1. alle kleingeschriebenen W√∂rter mit drei Buchstaben\n",
    "2. alle W√∂rter mit Gro√übuchstaben am Anfang\n",
    "3. alle Zitate (dieser regul√§re Ausdruck beinhaltet vermutlich doppelte Anf√ºhrungszeichen; umschlie√ü den string zwecks korrekter Abgrenzung daher mit drei einfachen Anf√ºhrungszeichen)\n",
    "\n",
    "Lass Dir anschlie√üend alle Listen sch√∂n formatiert ausgeben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659810a6-da26-44a9-92d5-ad11d0153278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zur L√∂sung verwendeter Text stammt von https://www.mdr.de/nachrichten/sachsen/bautzen/goerlitz-weisswasser-zittau/bahnstrecke-berlin-goerlitz-ice-ausbau-fahrgastverband-wirtschaftsministerium-100.html\n",
    "text = \"\"\"Ein ICE von Berlin nach G√∂rlitz: Das ist allenfalls Zukunftsmusik. Auch wenn Sachsens Ministerpr√§sident Michael Kretschmer (CDU) unl√§ngst mitteilte, die ICE-Strecke zwischen Berlin und G√∂rlitz werde umgesetzt, f√§hrt noch lange kein ICE aus der Bundeshauptstadt in die niederschlesische Metropole. Das SPD-gef√ºhrte s√§chsische Wirtschaftsministerium stellt auf Nachfrage von MDR SACHSEN klar: Ziel sei es, \"die bestehende Schienenverbindung zwischen Cottbus und G√∂rlitz durchg√§ngig zweigleisig zu elektrifizieren sowie auf eine Geschwindigkeit von bis zu 160 km/h zu ert√ºchtigen.\" Dies sei im Investitionsgesetz f√ºr die Kohleregionen aufgelistet.\n",
    "Dar√ºber hinaus soll die Elektrifizierung des Bahnhofes G√∂rlitz als sogenannte Systemtrennstelle mit Anschluss an das polnische Gleichstromsystem umgesetzt werden. Den Begriff der \"ICE-Strecke\" erachte das Wirtschaftsministerium \"dabei als irref√ºhrend, da ein Ausbau von Schieneninfrastruktur grunds√§tzlich allen Verkehrstr√§gern dient und nicht auf den Einsatz bestimmter Produktgattungen ausgerichtet ist\". Im Klartext: Wenn kein Bedarf besteht, fahren auch k√ºnftig nur Regionalz√ºge zwischen G√∂rlitz und Cottbus mit Umsteigen Richtung Berlin. Warum Kretschmer von einer ICE-Strecke spricht, wollte die Staatskanzlei auf Nachfrage nicht beantworten und verwies auf die Ausf√ºhrungen des zust√§ndigen Wirtschaftsministeriums.\n",
    "Ausbauplan bis 2038 Aus dem Wirtschaftsministerium hie√ü es weiter, \"nach Angaben der Deutschen Bahn sollen die Bauarbeiten bis Ende 2038 abgeschlossen werden\". Die Investitionssumme werde auf etwa 1,65 Milliarden Euro gesch√§tzt. √úber den bestellten Zugverkehr, der nach Ausbau angeboten und von den L√§ndern bezahlt werden soll, f√ºhre man mit Brandenburg Gespr√§che. √úber m√∂glichen Fernverkehr entscheidet die DB selbst. Auch ein anderer Anbieter, wie etwa Flixtrain, k√∂nnte theoretisch auf eigene Kosten dort fahren. \n",
    "Deutsche Bahn √§u√üert sich zur√ºckhaltend zu Kosten und Zeitplan Die Deutsche Bahn verweist auf noch laufende Planungen und √§u√üert sich weder zu Zeitplan noch zu Kosten. \"Mit dem Investitionsgesetz Kohleregionen (InvKG) hat der Bund die Grundlage f√ºr den weiteren Ausbau der Bahnstrecke zwischen Berlin und G√∂rlitz geschaffen.\" Im Abschnitt Berlin ‚Äì Cottbus liege \"der Fokus auf Einzelma√ünahmen an der Strecke und den Bahnh√∂fen. Auf dem Abschnitt Cottbus - G√∂rlitz sind ein durchgehend zweigleisiger Ausbau und die Elektrifizierung der Strecke vorgesehen.\" \n",
    "Es gehe darum, die bisherige Braunkohle-Regionen nach dem Ende des Abbaus besser an Metropolregionen anzubinden. \"Die mit der schrittweisen Umsetzung der strukturst√§rkenden Ma√ünahmen einhergehenden Nachfrageentwicklungen wird die DB bei der Angebotsplanung ber√ºcksichtigen\", verspricht der Verkehrskonzern, ohne konkret einen ICE anzuk√ºndigen.\n",
    "Fahrgastverband zweifelt an ICE nach G√∂rlitz Vom Fahrgastverband Pro Bahn hie√ü es: \"Das Statement von Ministerpr√§sident Kretschmer ist in der Tat schwerlich einzuordnen, weil ein ICE-Zug als Besonderheit grunds√§tzlich nur eine elektrifizierte Trasse braucht.\" Fr√ºhere Pl√§ne zum Ausbau f√ºr Geschwindigkeiten von 200 Stundenkilometer und mehr seien inzwischen Geschichte. Der Fahrgastverband sei skeptisch, dass die DB eigenwirtschaftlich ICE-Z√ºge anbieten wird. Eine Bezahlung von Fernverkehr durch L√§nder, wie derzeit zwischen Dresden und Chemnitz oder Erfurt und Gera sei aber nur ein Notl√∂sung. Seit der Bahnreform mit Fusion der Deutschen Reichsbahn und der Deutschen Bundesbahn zur Deutschen Bahn AG wird Regionalverkehr von L√§ndern bezahlt, Fernverkehrsz√ºge betreibt die DB AG unter wirtschaftlichen\n",
    "Fokus auf Eurocity statt Binnenverkehrs-ICE Laut Fahrgastverband ist es \"ein generelles Vers√§umnis der Politik und der Bahn, dass die Fernverkehrsentwicklung auf den ICE fokussiert wurde und nicht die enormen Potentiale einer gemeinsamen Entwicklung des Fernverkehrs der Lausitz mit polnischen und tschechischen Nachbarn in den Blick genommen wurde\". Der ICE ist \"nicht polen- und tschechientauglich\" - also unter dortiger Oberleitung nicht einsetzbar. Das liegt an unterschiedlichen Stromsystemen der europ√§ischen Eisenbahnen. \"DB Fernverkehr hat in seinem Bestand keine einzige Lok, die technisch in der Lage w√§re, nach Polen und Tschechien zu fahren\", so der Fahrgastverband. (Im Bestand der DB AG gibt es ICE-Mehrsystemz√ºge, die planm√§√üig und t√§glich nach Frankreich, Belgien, in die Niederlande und in die Schweiz fahren. Anm. der Redaktion)\n",
    "Weiter hei√üt es: \"PKP Intercity w√ºrde l√§ngst Z√ºge bis in den G√∂rlitzer Hauptbahnhof fahren lassen, wenn die deutsche Seite die 800 Meter Fahrdraht, die zwischen 1923 und 1946 bereits hier hingen, vom Nei√üeviadukt bis in den Hauptbahnhof G√∂rlitz gezogen h√§tte.\" 2003 h√§tten sich Polen und Deutschland in einem Staatsvertrag hierzu verpflichtet. \"Auf der polnischen Seite wurde dieser Staatsvertrag zeitnah realisiert, auf deutscher Seite nicht.\"\n",
    "Lausitz war einst europ√§isches Schienendrehkreuz Die Lausitz war laut Fahrgastverband \"einst ein Drehkreuz des europ√§ischen Schienenverkehrs\". In Cottbus und G√∂rlitz h√§tten sich Verkehrsstr√∂me des Ost-West und des Nord-S√ºd-Verkehrs gekreuzt. \"W√ºrde man den Fokus statt auf ICE-Z√ºge beispielsweise auf Eurocity-Z√ºge Berlin - Cottbus - Wroclaw - Krak√≥w - Przemysl -Lwiw - Kiew oder Frankfurt/Main - Leipzig - Dresden - G√∂rlitz - Wroclaw - Warschau legen, so w√§ren solche Verkehre sicherlich wirtschaftlicher realisierbar als innerdeutsche 'Endverkehre' Berlin - Cottbus - G√∂rlitz. Zudem k√∂nnte die polnische Seite auch den Flughafen Berlin-Brandenburg BER aus Wroclaw kommend direkt anfahren. \"Daran hat sie schon vor Jahren gro√ües Interesse bekundet.\"\n",
    "Zwischen Berlin und Cottbus, wo die Bahn ein ICE-Werk plant, ist die Strecke elektrifiziert und wird auch jetzt schon von einzelnen Intercitys befahren. Zwischen Cottbus und G√∂rlitz √ºber Wei√üwasser fahren Dieseltriebwagen der Ostdeutschen Eisenbahn-Gesellschaft (ODEG). In diesem Abschnitt muss ein Streckenausbau auch um den Tagebau Reichwalde geplant werden.\n",
    "Zugleich fordert der Fahrgastverband von G√∂rlitz weiter bis Zittau die Bahnstrecke zu elektrifizieren, um auf tschechischer Seite √ºber Liberec bis Prag modernen Fernverkehr anbieten zu k√∂nnen. Auch die Trasse Dresden - Bautzen - G√∂rlitz m√ºsse \"zeitnah\" elektrifiziert und ert√ºchtigt werden. \"Wichtig ist aber, dass diese Strecken finanziell nicht gegeneinander ausgespielt werden\", so Pro Bahn.\"\"\"\n",
    "\n",
    "\"\"\"Whitespace vor und nach den Ausdr√ºcken in 'regex_1' und 'regex_2' sind notwendig, \n",
    "da 'findall' sonst auch innerhalb von W√∂rtern matcht (elegantere L√∂sung siehe 'Weitere Sonderzeichen').\"\"\"\n",
    "regex_1 = r\" [a-z√§√∂√º√ü]{3} \"\n",
    "regex_2 = r\" [A-Z√Ñ√ñ√ú]\\w* \"\n",
    "\"\"\"Beachte, dass 'regex_3' auf den obigen Text zugeschnitten ist und bei Dir vermutlich anders aussieht\"\"\"\n",
    "regex_3 = r'''\".*?\"''' #Beliebig viele beliebige Zeichen innerhalb von Anf√ºhrungszeichen, mit geb√§ndigter Gier (d. h. k√ºrzestm√∂glichster match).\n",
    "\n",
    "three_letter_words = re.findall(regex_1, text)\n",
    "capital_words = re.findall(regex_2, text)\n",
    "quotes = re.findall(regex_3, text)\n",
    "\n",
    "\"\"\"Konvertieren der Listen in einen string (mittels 'join', vgl. Notebook \"Datentypen\"), \n",
    "wobei wir erst mittels List Comprehension trailing und leading whitespace bei jedem Element entfernen\"\"\"\n",
    "print(\"Kleingeschriebene W√∂rter mit drei Buchstaben: \", \", \".join([word.strip() for word in three_letter_words]), \"\\n\")\n",
    "print(\"Gro√ügeschriebene W√∂rter: \", \", \".join([word.strip() for word in capital_words]), \"\\n\")\n",
    "\n",
    "print(\"Zitate:\")\n",
    "print(len(quotes))\n",
    "for quote in quotes:\n",
    "    print(quote, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba09c4-f4d8-436c-8cbe-a2e3406fb5f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **√úbung 3:** Angelehnt an das Beispiel mit den Links auf [tu-dresden.de](https://tu-dresden.de) sollst Du in dieser √úbung ebenfalls Links von einer bestimmten Webseite (bzw. aus dessen Quelltext) extrahieren. \n",
    "\n",
    "1. √ñffne dazu den [Spielplan der Bundesligasaison 2019-2020 auf weltfussball.de](https://www.weltfussball.de/alle_spiele/bundesliga-2019-2020/). Nun wollen wir den Quelltext dieser Seite herunterladen. Da wir noch √ºber keine Web-Scraping-Skills verf√ºgen, machen wir es manuell. Geh dazu je nach Browser wie folgt vor:\n",
    "\n",
    "    - bei Google Chrome und Firefox mittels Rechtsklick \"Seitenquelltext anzeigen\" w√§hlen\n",
    "    - bei Safari mittels Rechtsklick \"Seitenquelltext einblenden\" w√§hlen\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    Markier und kopier nun den kompletten Quelltext und speicher ihn in einem neuen Dokument, das Du unter dem Namen \"quelltext.txt\" im Ordner \"3_Dateien/Fussball\" abspeicherst. F√ºr diesen Vorgang empfiehlt sich das im Notebook \"Funktionen und Methoden Teil 2\" erw√§hnte [Sublime Text](https://www.sublimetext.com).\n",
    "\n",
    "    Der Quelltext im Browser sollte √ºbrigens so oder so √§hnlich ausschauen:\n",
    "\n",
    "    <img src=\"../../3_Dateien/Grafiken_und_Videos/Quelltext.png\">\n",
    "\n",
    "2. √ñffne das Dokument wie im Notebook \"Input und Output Teil 1\" gelernt, lies es ein und weis es der Variablen ```source_code``` zu.\n",
    "\n",
    "3. Geh noch einmal zum [Spielplan](https://www.weltfussball.de/alle_spiele/bundesliga-2019-2020/) im Browser und √∂ffne einige Spielberichte, indem Du auf die jeweiligen Spielergebnisse klickst. Schau Dir die Adresszeile an und analysier, wie die Links aufgebaut sind sowie worin sie sich unterscheiden. Schau ebenfalls im Quelltext nach, wie die Links da aussehen.\n",
    "\n",
    "4. Formulier darauf aufbauend einen regul√§ren Ausdruck, der s√§mtliche Links zu allen Spielberichten im Quelltext matcht. F√ºg ihn als string bei der Variablen ```regex``` ein. Ist der regul√§re Ausdruck korrekt, sollte ```matches``` 306 Links beinhalten. Sowohl bei ```regex``` als auch bei ```matches``` musst Du nat√ºrlich noch die Hashtags entfernen.\n",
    "\n",
    "5. Erstell eine Liste mit vollst√§ndigen Links zu allen Spielberichten und lass sie Dir ausgeben. Probier einige der Links aus.\n",
    "\n",
    "Quelle: √úbung modifiziert √ºbernommen von Prof. Simon Meier-Vierackers Kurs [Reading Machines - Einf√ºhrung in die Korpuslinguistik](https://padlet.com/simonmeiervieracker/readingmachines), der unter dem angegebenen Link frei zug√§nglich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce8c1e-7103-4c7f-8644-e00a6dddb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "#Code funktioniert erst, nachdem Du das Dokument \"quelltext.txt\" erstellt hast!\n",
    "with open(\"../../3_Dateien/Fussball/quelltext.txt\") as f:\n",
    "    source_code = f.read()\n",
    "    \n",
    "regex = r\"/spielbericht/[\\w-]+/\" #Literal \"/spielbericht/\", ein oder mehrere alphanumerische Zeichen bzw. literal \"-\", literal \"/\"\n",
    "matches = re.findall(regex, source_code)\n",
    "\n",
    "#Erstellen von vollst√§ndigen Links\n",
    "links = []\n",
    "for match in matches:\n",
    "    links.append(\"www.weltfussball.de\" + match)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9bb5a-4521-4771-9afc-8de074652c89",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 4:** Lies das M√§rchen \"Des Kaisers neue Kleider\" von Hans Christian Andersen aus dem Ordner \"3_Dateien\" ein und weis es ```fairytale``` zu. Formulier nun regul√§re Ausdr√ºcke f√ºr folgende Suchauftr√§ge:\n",
    "\n",
    "1. das erste Wort des M√§rchens\n",
    "2. regelm√§√üige Verben in der 3. Person Singular/Plural im Pr√§teritum (z.&nbsp;B. \"lebte\" oder \"sagten\"; es ist in Ordnung, wenn Du mit diesem regul√§ren Ausdruck auch ein paar falsch positive matches kriegst ü§´, vgl. Wahrheitsmatrix im Notebook \"Input und Output Teil 1\")\n",
    "3. letzte W√∂rter von S√§tzen, die mit einem Punkt enden (z.&nbsp;B. \"einherzugehen\", vgl. erster Satz des M√§rchens)\n",
    "4. W√∂rter mit Doppel-a (z.&nbsp;B. \"Saal\")\n",
    "5. das letzte Wort des M√§rchens\n",
    "\n",
    "Da wir bei der ersten und letzten Aufgabe nicht nach *allen* matches suchen, sondern nur an einem einzigen interessiert sind (es kann ja auch nur jeweils einen match geben), verwenden wir eine neue Funktion, n√§mlich ```search```, auf die wir unten genauer eingehen. Dabei erhalten wir keine Liste zur√ºck, sondern ein sog. *match-Objekt*, wobei wir auf den eigentlichen match wie im ```print```-Statement bereits vorgegeben zugreifen k√∂nnen. √úberhaupt sollte das ```print```-Statement das Ergebnis aller f√ºnf Suchauftr√§ge sch√∂n formatiert ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365227b-3ad8-4a07-b596-d869385dd4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt\n",
    "with open(\"../../3_Dateien/Des_Kaisers_neue_Kleider/Des_Kaisers_neue_Kleider.txt\") as f:\n",
    "    fairytale = f.read()\n",
    "\n",
    "regex_1 = r\"^\\w+\" #String-Anfang, ein oder mehrere ASCII-Zeichen (noch besser w√§re eigene Klasse [A-Za-z√Ñ√§√ñ√∂√ú√º√ü], da sonst ein string-Anfang mit Umlaut/Eszett nicht gematcht w√ºrde; gilt auch unten)\n",
    "regex_2 = r\"\\b[a-z√§√∂√º√ü]+ten?\\b\" #Wortgrenze, ein oder mehrere kleingeschriebene Buchstaben, literal \"t\" und \"e\", optional literal \"n\", Wortgrenze\n",
    "regex_3 = r\"[A-Za-z√Ñ√§√ñ√∂√ú√º√ü]+\\.\" #Ein oder mehrere literale Buchstaben, literal \".\" (maskiert mit \"\\\", da sonst Wildcard)\n",
    "regex_4 = r\"\\b\\w*[a]{2}\\w*\\b\" #Wortgrenze, null oder mehrere ASCII-Zeichen, zwei literale \"a\", null oder mehrere ASCII-Zeichen, Wortgrenze\n",
    "regex_5 = r\"\\w+\\.$\" #Ein oder mehrere ASCII-Zeichen, ein literaler \".\" (maskiert), string-Ende\n",
    "\n",
    "first_word = re.search(regex_1, fairytale)\n",
    "verbs = re.findall(regex_2, fairytale)\n",
    "last_words = re.findall(regex_3, fairytale)\n",
    "double_vowel = re.findall(regex_4, fairytale)\n",
    "last_word = re.search(regex_5, fairytale)\n",
    "\n",
    "print(first_word.group(), \"\\n\\n\", verbs, \"\\n\\n\", [word.strip(\".\") for word in last_words], \"\\n\\n\", double_vowel, \"\\n\\n\", last_word.group().strip(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d7d5d-7f6d-4e84-8f30-577e984d6203",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **√úbung 5:** Im Notebook \"Funktionen und Methoden Teil 1\" in √úbung 2 haben wir gesehen, dass das Wort \"Klima\" viel h√§ufiger im Koalitionsvertrag von 2021 als in demjenigen von 2018 vorkommt. Nun wollen wir herausfinden, in welcher Form das Wort verwendet wird. Neben dem alleinstehenden Auftreten von \"Klima\" (als sog. *Simplex*, da es aus nur einem Morphem besteht) ist \"Klima\" bzw. \"klima\" h√§ufig Teil von zusammengesetzten W√∂rtern, also sog. *Komposita*, wie etwa in \"Klimakrise\" oder \"klimapolitisch\".  \n",
    "\n",
    "Lies den Koalitionsvertrag von 2021 noch einmal ein und weis ihn der Variablen ```kv21``` zu. Durchsuch ihn nun nach einem regul√§ren Ausdruck, der s√§mtliche Komposita, in denen \"Klima\" bzw. \"klima\" vorkommt, matcht. H√§ng alle Komposita der Liste ```climate_compounds``` an und lass Dir abschlie√üend die Liste ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fae76-63db-4020-8cf4-ba003ba6269b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt\n",
    "import re\n",
    "with open(\"../../3_Dateien/Koalitionsvertraege/koalitionsvertrag_2021.txt\", encoding=\"utf-8\") as f:\n",
    "    kv21 = f.read()\n",
    "    \n",
    "regex = r\"[Kk]lima\\S+\\b\" #Gro√ü- oder kleingeschriebenes 'k', gefolgt von literal 'lima', einem oder mehr Zeichen, die nicht whitespace sind und einer Wortgrenze\n",
    "\n",
    "climate_compounds = re.findall(regex, kv21)\n",
    "    \n",
    "print(climate_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74a10e-2193-4f6d-b500-fdba33076769",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 6:** Find alle Substantive mit definitem Artikel (z.&nbsp;B. \"der\" oder \"dem\") in `text`, der der Einleitung des [ Wikipedia-Artikels zu regul√§ren Ausdr√ºcken](https://de.wikipedia.org/wiki/Regul√§rer_Ausdruck) entspricht (Stand: 26.10.2022). Der Artikel (des Substantivs) sollte jeweils mitgemacht werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869fd7c-0069-438e-a135-cac39c71fb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Ein regul√§rer Ausdruck (englisch regular expression, Abk√ºrzung RegExp oder Regex) ist in der theoretischen Informatik eine Zeichenkette, die der Beschreibung von Mengen von Zeichenketten mit Hilfe bestimmter syntaktischer Regeln dient. Regul√§re Ausdr√ºcke finden vor allem in der Softwareentwicklung Verwendung. Neben Implementierungen in vielen Programmiersprachen verarbeiten auch viele Texteditoren regul√§re Ausdr√ºcke in der Funktion ‚ÄûSuchen und Ersetzen‚Äú. Ein einfacher Anwendungsfall von regul√§ren Ausdr√ºcken sind Wildcards.\n",
    "Regul√§re Ausdr√ºcke k√∂nnen als Filterkriterien in der Textsuche verwendet werden, indem der Text mit dem Muster des regul√§ren Ausdrucks abgeglichen wird. Dieser Vorgang wird auch Pattern Matching genannt. So ist es beispielsweise m√∂glich, alle W√∂rter aus einer Wortliste herauszusuchen, die mit S beginnen und auf D enden, ohne die dazwischen liegenden Buchstaben oder deren Anzahl explizit vorgeben zu m√ºssen.\n",
    "Der Begriff des regul√§ren Ausdrucks geht im Wesentlichen auf den Mathematiker Stephen Kleene zur√ºck, der die √§hnliche Bezeichnung regul√§re Menge verwendete.\"\"\"\n",
    "\n",
    "regex = r\"(\\b(D|d)(er|ie|as|es|em|en) [A-Z√Ñ√ñ√ú][a-z√§√∂√º√ü]*\\b)\" #Wortgrenze, literal \"D\" oder \"d\", literal \"er\", \"ie\", \"as\", \"es\", \"em\" oder \"en\", Leerzeichen, beliebiger Gro√übuchstabe, beliebig viele Kleinbuchstaben, Wortgrenze\n",
    "matches = re.findall(regex, text)\n",
    "\n",
    "#Nur den gesamten match (Hauptgruppe) ausgeben lassen\n",
    "print([match[0] for match in matches])\n",
    "\n",
    "#Den gesamten match (Hauptgruppe) und alle anderen Gruppen ausgeben lassen\n",
    "print([match for match in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89be60-8e3c-492c-92d6-355d428e647c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è <b>√úbung 7 (ü¶ä fortgeschritten)</b>: Gegeben sind kurze Beschreibungen von f√ºnf Personen in ```people```. In jeder Beschreibung findet sich der Vor- und Nachname, das Geburtsdatum sowie die E-Mailadresse der Person. Wir wollen daraus ein kleines Adressbuch in tabellarischer Form schaffen. Ziel ist es, die Daten wie im Screenshot gezeigt in die Datei \"address_book.tsv\" im Ordner \"3_Dateien/Output\" zu schreiben: \n",
    "\n",
    "<img src=\"../../3_Dateien/Grafiken_und_Videos/address_book.png\">\n",
    "\n",
    "Zwischen den Namen und dem Geburtstag sowie dem Geburtstag und der E-Mailadresse soll also ein Tab stehen, da Dateien mit der Endung \".tsv\" tabulatorsepariert sind (dem gleichen Prinzip wie kommaseparierte Dateien folgend, vgl. Notebook \"Input und Output Teil 2\").\n",
    "\n",
    "Formulier *einen* regul√§ren Ausdruck, um f√ºnf matches zu erhalten (einen pro Person), und nutz Gruppen, um die Elemente *Nachname*, *Vorname*, *Geburtstag* und *E-Mailadresse* als Teilmatch separat zu erhalten. √ñffne und beschreib anschlie√üend die Datei \"address_book.tsv\", sodass jede Person in einer eigenen Zeile sowie jedes Element in einer eigenen Spalte abgespeichert wird.\n",
    "\n",
    "Quelle: √úbung modifiziert √ºbernommen von Prof. Simon Meier-Vierackers Kurs [Reading Machines - Einf√ºhrung in die Korpuslinguistik](https://padlet.com/simonmeiervieracker/readingmachines), der unter dem angegebenen Link frei zug√§nglich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9a559-105e-4883-9405-820c5d81d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = \"\"\"Detlef SCHULZ hat am 21.03.1967 Geburtstag, und das ist seine Emailadresse: schulz-detlef@gmail.net \n",
    "Ina SCHULTER wurde am 02.04.1992 geboren und ihre E-Mail-Adresse lautet: inaschulter@gmx.de\n",
    "Katharina Anne LAMAI ist ein Dezemberkind, ihr Geburtstag ist der 08.12.1955 geboren und ihre E-Mail-Adresse lautet: KaAnLa@yahoo.com\n",
    "Anuk MARGA ist am 15.01.1988 auf die Welt gekommen, ihre E-Mail-Adresse lautet: MargAnuk@gmail.com\n",
    "Albus Percival Wulfric Brian DUMBLEDORE hat 17.06.1881 das Licht der Welt erblickt. Er hat sogar eine Emailadresse: fresh-dumbledore@hogwarts.com\"\"\"\n",
    " \n",
    "#Beachte: Mehr denn je k√∂nnen unz√§hlige andere L√∂sungen auch korrekt sein!\n",
    "\n",
    "\"\"\"Mindestens ein beliebiges Zeichen (au√üer Zeilenumbruch), gefolgt von einem Leerschlag, gefolgt von mindestens einem Gro√übuchstaben,\n",
    "gefolgt von einem Leerschlag, gefolgt von mindestens einem beliebigen Zeichen (au√üer Zeilenumbruch), gefolgt von einem Leerschlag,\n",
    "gefolgt von zwei Zahlen, einem Punkt (maskiert), zwei Zahlen, einem Punkt (maskiert), vier Zahlen, gefolgt von einem Leerschlag,\n",
    "gefolgt von mindestens einem beliebigen Zeichen (au√üer Zeilenumbruch), gefolgt von Leerschlag, gefolgt von mindestens einem beliebigen Zeichen, \n",
    "das nicht whitespace ist, gefolgt von literal '@', gefolgt von mindestens einem beliebigen Zeichen, das nicht whitespace ist;\n",
    "regul√§rer Ausdruck funktioniert, da die Wildcard keinen Zeilenumbruch matcht und sich von daher nicht die ganze Beschreibung 'einverleiben' kann,\n",
    "da sonst der Rest des regul√§ren Ausdrucks nicht mehr zutr√§fe (vgl. Tipp im zugeh√∂rigen Notebook)\"\"\"\n",
    "regex = r\"(.+) ([A-Z]+) .+ (\\d{2}\\.\\d{2}\\.\\d{4}) .+ (\\S+@\\S+)\"\n",
    "\n",
    "matches = re.findall(regex, people)\n",
    "\n",
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt\n",
    "with open(\"../../3_Dateien/Output/address_book.tsv\", \"w\") as f:\n",
    "    f.write(\"Name\\tBirthday\\tMail address\\n\")\n",
    "    for match in matches:\n",
    "        f.write(match[1] + \", \" + match[0] + \"\\t\" + match[2] + \"\\t\" + match[3] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09267c5-2f4c-4db3-b172-cfa043e9312e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **√úbung 8:** Bei ```birth_notices``` handelt es nun um eine Liste mit mehreren Geburtsanzeigen. Deine Aufgabe ist es, die Geburtsdaten der Neugeboreren mithilfe eines regul√§ren Ausdrucks sowie einer geeigneten Funktion des ```re```-Moduls aus den Anzeigen zu extrahieren und einer Liste namens ```birth_dates``` anzuh√§ngen. Lass Dir abschlie√üend ```birth_dates``` ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7deb52-659a-412c-bafc-7138f0e989c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "birth_notices = [\"Lena erblickte am 1. September 2022 die Welt.\",\n",
    "                 \"Petra kam am 28. Februar 2022 zur Welt.\",\n",
    "                 \"Yusuf strahlte uns am 14. Dezember 2022 mit gl√§nzenden √Ñuglein an.\", \n",
    "                 \"Juans Leben begann am sonnigen 19. August 2022.\",\n",
    "                 \"Robert bereichert seit dem 5. Mai 2022 unser Leben.\",\n",
    "                 \"Mi begl√ºckt uns seit dem 1. M√§rz 2022.\"]\n",
    "\n",
    "birth_dates = []\n",
    "\n",
    "'''Ein oder zwei Zahlen, gefolgt von escapdem \".\", einem Leerzeichen, einem oder mehreren alphanumerischen Zeichen bzw. \"√§\" (vgl. \"M√§rz\",\n",
    "einem Leerzeichen und vier Zahlen'''\n",
    "regex = r\"\\d{1,2}\\. (\\w|√§)+ \\d{4}\" \n",
    "\n",
    "for notice in birth_notices:\n",
    "    birth_dates.append(re.search(regex, notice).group())\n",
    "\n",
    "print(birth_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac1a0d-eda7-4f9d-ab82-37b86daf969f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 9:** Gegeben sind in ```people``` noch einmal die Personenbeschreibungen aus √úbung 7 sowie die Musterl√∂sung f√ºr den regul√§ren Ausdruck in ```regex```. ```regex``` beinhaltet Gruppen, auf deren Teilmatches wir zur√ºckgreifen k√∂nnen. Formulier unter Zuhilfenahme von R√ºckreferenzen einen regul√§ren Ausdruck f√ºr ```replacement```, um anschlie√üend ```people``` mithilfe von ```re.sub``` in dasselbe Format wie in √úbung 7 zu bringen:\n",
    "\n",
    "\"Nachname, Vorname \\t Geburtsdatum \\t E-Mailadresse\" \n",
    "\n",
    "Es reicht diesmal, wenn Du das Dir das Ergebnis einfach ausgeben l√§sst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53213fb7-93dd-4bac-97d2-bc7a3f2d8c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "people = \"\"\"Detlef SCHULZ hat am 21.03.1967 Geburtstag, und das ist seine Emailadresse: schulz-detlef@gmail.net \n",
    "Ina SCHULTER wurde am 02.04.1992 geboren und ihre E-Mail-Adresse lautet: inaschulter@gmx.de\n",
    "Katharina Anne LAMAI ist ein Dezemberkind, ihr Geburtstag ist der 08.12.1955 geboren und ihre E-Mail-Adresse lautet: KaAnLa@yahoo.com\n",
    "Anuk MARGA ist am 15.01.1988 auf die Welt gekommen, ihre E-Mail-Adresse lautet: MargAnuk@gmail.com\n",
    "Albus Percival Wulfric Brian DUMBLEDORE hat 17.06.1881 das Licht der Welt erblickt. Er hat sogar eine Emailadresse: fresh-dumbledore@hogwarts.com\"\"\"\n",
    " \n",
    "regex = r\"(.+) ([A-Z]+) .+ (\\d{2}\\.\\d{2}\\.\\d{4}) .+ (\\S+@\\S+)\" #Erkl√§rung des regul√§ren Ausdrucks siehe L√∂sung 7\n",
    "replacement = r\"\\2, \\1\\t\\3\\t\\4\" #Ersetzungsmuster: zweiter Teilmatch, ein Komma, Leerzeichen, erster Teilmatch, Tabstopp, dritter Teilmatch, Tabstopp, vierter Teilmatch\n",
    "\n",
    "people_formatted = re.sub(regex, replacement, people)\n",
    "\n",
    "print(people_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72efa2f3-0ace-40ac-a30d-af5ed76ba0f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 10:** ```birth_dates``` von oben ist nun etwas l√§nger und beinhaltet mehr Geburtsdaten. Ziel ist es, s√§mtliche Geburtsdaten in das Datumsformat nach [ISO 8601](https://de.wikipedia.org/wiki/Datumsformat#ISO_8601_und_EN_28601), also YYYY/MM/DD, zu bringen. Geh dazu wie folgt vor:\n",
    "\n",
    "1. Wenn n√∂tig, pass ```regex``` an, damit auch alle neuen Geburtsdaten gematcht werden.\n",
    "2. Setz Klammern in ```regex```, um relevante Teile eines matches zu gruppieren.\n",
    "3. Pass die Funktion ```to_ISO_format``` an, damit jedes einzelne match-Objekt entsprechend IS0 8601 umstrukturiert wird. Bei zweistelligen Jahreszahlen unter und gleich 22 kannst Du davon ausgehen, dass sie sich auf das 21. Jahrhundert beziehen, ansonsten auf das 20. Jahrhundert.\n",
    "\n",
    "Der Funktionsaufruf innerhalb von ```re.sub(...)``` ist korrekt, so wie er gegeben ist (es fehlen also keine Klammern!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e7cce2-3023-4418-8aab-baf0ab329c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "birth_dates = \"\"\"Ich bin am 09.08.1992 geboren, meine Schwester am 3.4.95 und unser Bruder am 9.10.1998. \n",
    "Unsere Mutter ist am 23.10.1967 geboren und unser Vater am 14.1.68. \n",
    "Der letzte Familienzuwachs ist die Tochter meines Bruders, die am 1.1.2022 geboren wurde.\"\"\"\n",
    "\n",
    "'''Ein oder zwei Zahlen (1. Teilmatch), gefolgt von escapdem \".\", ein oder zwei Zahlen (2. Teilmatch),\n",
    "escapdem \".\", optionalem, literalem \"19\" oder \"20\" sowie zwei Zahlen (3. Teilmatch)'''\n",
    "regex = r\"(\\d{1,2})\\.(\\d{1,2})\\.((19|20)?\\d{2})\"\n",
    "\n",
    "def to_ISO_format(match_object):\n",
    "    \n",
    "    two_digit_year = match_object.group(3)[-2:] #Zugriff auf die letzten beiden Ziffern mittels Slicing\n",
    "    \n",
    "    year = f\"{'19' + two_digit_year if int(two_digit_year) > 22 else '20' + two_digit_year}\" #Erg√§nzen von 'two_digit_year' um \"19\" bzw. \"20\"\n",
    "    month = f\"{int(match_object.group(2)):02}\" #Zero-padden des zweiten Teilmatches auf zwei Stellen\n",
    "    day = f\"{int(match_object.group(1)):02}\" #Zero-padden des ersten Teilmatches auf zwei Stellen \n",
    "    \n",
    "    return year + \"/\" + month + \"/\" + day #R√ºckgabe des konvertierten Datums \n",
    "     \n",
    "iso_dates = re.sub(regex, to_ISO_format, birth_dates) #Matchen von 'regex' in 'birth_dates' und Ersetzen aller Matches entsprechend 'to_ISO_format'\n",
    "print(iso_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c1025-4db1-4585-9baf-e5a46be8a502",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "**üîß Anwendungsfall:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4f6f0-2364-4d81-b355-70ac3fa6e288",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die L√∂sung zu beiden Teilaufgaben befindet sich in den Dateien \"pizzabot_solved_documented.py\" und \"pizza_functions_documented\" im Ordner \"3_Dateien\". Der verbesserte Pizzabot kann in der folgenden Zelle getestet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dd53c-4972-465e-b64f-c95009823999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Diese beiden Zeilen kannst Du ignorieren (sie sind n√∂tig, da sich das zu importierende Modul \n",
    "in einem anderen Verzeichnis als das Notebook befindet (vgl. Notebook \"Funktionen und Methoden Teil 2\")\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../../3_Dateien/Module/\")\n",
    "\n",
    "import pizzabot_solved_documented as pizzabot\n",
    "pizzabot.order_pizza()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee666f32-be9d-4073-a7d8-6f528babf0d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Weiter k√∂nnen die Muster-docstrings √ºber folgende Zelle ausgegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb72bd7-4938-4c35-baa8-972a0fa59e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pizzabot_solved_documented import order_pizza\n",
    "from pizza_functions_documented import *\n",
    "\n",
    "print(\"order_pizza:\", order_pizza.__doc__, \"\\n\")\n",
    "print(\"yn_validator:\", yn_validator.__doc__, \"\\n\")\n",
    "print(\"choose_pizza:\", choose_pizza.__doc__, \"\\n\")\n",
    "print(\"remove_ingredient:\", remove_ingredient.__doc__, \"\\n\")\n",
    "print(\"add_ingredient:\", add_ingredient.__doc__, \"\\n\")\n",
    "print(\"request_address:\", request_address.__doc__, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb475ca-319b-4e53-b9ae-6c5be9532c4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "***\n",
    "<table>\n",
    "      <tr>\n",
    "        <td>\n",
    "            <img src=\"../../3_Dateien/Lizenz/CC-BY-SA.png\" width=\"400\">\n",
    "        </td> \n",
    "        <td>\n",
    "            <p>Dieses Notebook sowie s√§mtliche weiteren <a href=\"https://github.com/yannickfrommherz/exdimed-student/tree/main\">Materialien zum Programmierenlernen f√ºr Geistes- und Sozialwissenschaftler:innen</a> sind im Rahmen des Projekts <i>Experimentierraum Digitale Medienkompetenz</i> als Teil von <a href=\"https://tu-dresden.de/gsw/virtuos/\">virTUos</a> entstanden. Erstellt wurden sie von Yannick Frommherz unter Mitarbeit von Anne Josephine Matz. Sie stehen als Open Educational Resource nach <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY SA</a> zur freien Verf√ºgung. F√ºr Feedback und bei Fragen nutz bitte das <a href=\"https://forms.gle/VsYJgy4bZTSqKioA7\">Kontaktformular</a>.\n",
    "        </td>\n",
    "      </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
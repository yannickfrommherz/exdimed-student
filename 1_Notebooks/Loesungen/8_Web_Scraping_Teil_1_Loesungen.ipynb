{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9b2abe-9dbc-4b0c-bd97-088470e5eca4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Web Scraping Teil 1 (L√∂sungen)\n",
    "\n",
    "‚òùÔ∏è Beachte: Es gibt beim Programmieren fast immer verschiedene L√∂sungswege. Deine L√∂sung mag anders aussehen, aber dennoch zum gew√ºnschten Resultat f√ºhren. Das richtige Resultat ist das Wichtigste. \n",
    "\n",
    "‚ö†Ô∏è F√ºhr folgenden Code aus, bevor Du einzelne L√∂sungen ausf√ºhrst. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001fff4-aee5-4103-a632-55331948d234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63429c5-bf09-47ba-84ad-f9230de9e187",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "‚úèÔ∏è **L√∂sung 1:** Besuch eine beliebige Webseite in einem Browser Deiner Wahl. Die Webseite sollte mehrere Links zu anderen Seiten beinhalten, was auf die meisten Webseiten zutrifft. Lass Dir wie oben beschrieben den Quelltext der Seite anzeigen. Geh nun wie folgt vor und verwend dabei die angegebenen Tastenkombinationen.\n",
    "\n",
    "1. Markier den gesamten Quelltext (`Strg` + `a` (Windows und Linux) bzw. `‚åò` + `a` (macOS)), kopier ihn (`Strg`/`‚åò` + `c`) und f√ºg ihn in ein leeres Dokument bei Sublime Text ein (`Strg`/`‚åò` + `v`). \n",
    "2. Formulier einen regul√§ren Ausdruck, der s√§mtliche Links in Deinem Quelltext matcht. Manche Webseiten enthalten komplette Links in ihrem Quelltext (z.&nbsp;B. \"ht<span>tps://www.</span>domain<span>.de/</span>subdomain/page\"), andere wiederum blo√ü abgek√ºrzte Links (\"subdomain/page\"), die, wenn man im Browser draufklickt, um den gemeinsamen \"Stammlink\" erg√§nzt werden. Dein regul√§rer Ausdruck soll sich nach dem Linkformat im Quelltext Deiner Webseite richten und m√∂glichst viele Links matchen.\n",
    "3. Aktivier die Suche bei Sublime Text √ºber `Strg`/`‚åò` + `f`). Gib den regul√§ren Ausdruck ein und such bzw. markier alle Matches √ºber die Tastenkombination `Alt`/`option` + `Enter` (dies entspricht der Schaltfl√§che \"Find All\"). Ggf. musst Du regul√§re Ausdr√ºcke f√ºr die Suche aktivieren (links neben dem Suchfeld √ºber `.*`).\n",
    "5. Kopier alle Links. √ñffne ein weiteres Dokument bei Sublime Text und f√ºg die Links dort ein. F√ºhr auch diese Schritte nach M√∂glichkeit mithilfe von Tastenkombinationen aus.\n",
    "\n",
    "*Keine L√∂sung, da jede Webseite unterschiedlich aufgebaut ist. Der regul√§re Ausdruck im Tipp bietet aber einen Anhaltspunkt, den Du vermutlich im Hinblick auf Deine Webseite anpassen musst.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d015d2a-af2f-4e54-9578-73f622777e79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "<!-- Da es sich um in Markdown eingebetteten HTML-Code handelt, ist die grundlegende HTML-Struktur mit Dokumenttypdeklaration, html- und body-Element nicht n√∂tig. Markdown-Code kommt ohne diese Struktur aus. Dieser Text hier ist √ºbrigens ein Kommentar, der nicht gerendert wird.-->\n",
    "\n",
    "<table style=\"font-size: 16px; font-family: sans-serif; letter-spacing: 0.2px;\">\n",
    "      <tr>\n",
    "        <td>\n",
    "            <p>‚úèÔ∏è <b>√úbung 2:</b> Um die Struktur von HTML-Code weiter zu verinnerlichen, wollen wir trotzdem eine (sehr basale) Webseite schreiben. \n",
    "                Deine Aufgabe ist es, die im Screenshot gezeigte Rezeptwebseite nachzuprogrammieren. \n",
    "                Viel mehr als die oben gegebene HTML-Grundstruktur ben√∂tigst Du daf√ºr nicht. Blo√ü zwei Dinge fehlen Dir:</p>\n",
    "            <ol>\n",
    "                <li>Um den Link zum <a href=\"https://www.eat-this.org/baba-ganoush-orientalischer-auberginensalat/#recipe\">Originalrezept</a> einzubetten, \n",
    "                    kannst Du folgende Syntax verwenden, wobei Du den Link bei \"link\" innerhalb der Anf√ºhrungszeichen einsetzt.<br><br>\n",
    "                    <code>&lt;a href=\"link\"&gt;Eat this&lt;/a&gt;</code></li><br>\n",
    "                <li>Um eine Liste zu nummerieren, verwendest Du das Tag <code>&lt;ol&gt;</code> f√ºr <u>o</u>rdered <u>l</u>ist \n",
    "                    statt <code>&lt;ul&gt;</code> (<u>u</u>nordered <u>l</u>ist).</li>\n",
    "            </ol>\n",
    "            <p>Schreib den Code in einem Sublime Text-Dokument und speichere es anschlie√üend mit der Endung \".html\". \n",
    "               Wenn Du es nun in einem beliebigen Browser √∂ffnest, sollte Dir Deine Rezeptwebseite angezeigt werden.</p>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"../../3_Dateien/Grafiken_und_Videos/lieblingsrezept.png\" width=\"1000\">\n",
    "        </td> \n",
    "      </tr>\n",
    "</table>\n",
    "    \n",
    "*Die L√∂sung findet sich im Ordner \"3_Dateien/HTML/lieblingsrezept.html\". √ñffne das Dokument mit Sublime Text, um den Code zu inspizieren, bzw. mit einem Browser, um die Webseite gerendert zu sehen.*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7b7e0-867f-47c5-b939-f21f7e13ecd2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "‚úèÔ∏è **L√∂sung 3:** In folgenden HTML-Code haben sich diverse Fehler eingeschlichen. Wieviele findest Du? Beheb sie alle.  \n",
    "\n",
    "*Es befinden sich acht Fehler im Code, und zwar:*\n",
    "\n",
    "- *Das erste Kind des `<html>`-Elements hei√üt `<head>` und nicht `<kopf>`.*\n",
    "- *Textinhalte werden **nicht** von Anf√ºhrungszeichen umrahmt, es sei denn diese sollen auch gerendert werden. Dieser Fehler betrifft alle Textinhalte.*\n",
    "- *Das Encoding \"UTF-9\" gibt es nicht, korrekt ist \"UTF-8\".*\n",
    "- *Das erste `<p>`-Element endet mit dem falschen Tag (`</q>`).*\n",
    "- *Dem `<div>`-Element fehlt das schlie√üende Tag (`</div>`).*\n",
    "- *Dem zweiten `<p>`-Element fehlt ebenfalls das schlie√üende Tag (`</p>`).*\n",
    "- *Der Wert im `href`-Attribut, also der Link, muss in Anf√ºhrungszeichen stehen. Au√üerdem k√∂nnen nur Links beginnend mit \"http(s)://\" angeklickt werden.*\n",
    "- *Im schlie√üenden `<html>`-Tag wird der falsche Schr√§gstrich verwendet.*\n",
    "\n",
    "*Keine Fehler sind hingegen:*\n",
    "\n",
    "- *die fehlende Einr√ºckung der `<head>`- und `<body>`-Elemente unter dem `<html>`-Element. Einr√ºckung spielt bei HTML keine Rolle. Einzig die korrekte Verschachtelung der Elemente ist relevant. HTML-Code wird meist einger√ºckt angezeigt, um die Beziehungen zwischen den Elementen zu verdeutlichen.*\n",
    "- *das vermeintlich fehlende schlie√üende Tag im `<img>`-Element. `<img>`-Elemente ben√∂tigen kein schlie√üendes Tag, da sie √ºber keinen Inhalt verf√ºgen (au√üer nat√ºrlich den Bildinhalt, der aber √ºber ein Attribut geladen wird).*\n",
    "\n",
    "*Korrekt sollte der Code so aussehen (mit optionalen Einr√ºckungen):*"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b36dc93-e0f1-4c8a-ae5a-77b325fe74ec",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Finde den Fehler!</title>\n",
    "        <meta charset=\"UTF-8\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>Es wimmelt nur so vor <b>Fehlern</b> in diesem HTML-Code</p>\n",
    "        <div>\n",
    "            <p>Eine gute Ressource zum Weiterlernen ist <a href=\"https://www.w3schools.com/html\">w3schools</a>.</p>\n",
    "            <img src=\"picture.png\">\n",
    "        </div>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a64422-d49f-4eae-836c-13c5d44567aa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 4:** Reproduzier folgenden Text mithilfe von HTML. Achte auf die korrekte Hierarchie der Elemente sowie darauf, alle Tags zu schlie√üen. Handelt es sich um formatierende Inline-Elemente oder um strukturierende Blockelemente?\n",
    "\n",
    "<img src=\"../../3_Dateien/Grafiken_und_Videos/HTML_Formatierung.png\"> \n",
    "\n",
    "*Doppelklick in die folgende Markdown-Zelle, um den zugrundeliegenden HTML-Code zu sehen. S√§mtliche Elemente sind formatierende Inline-Elemente.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae1eb7-379f-4fe8-85b7-de481adfea62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sog. <i><a href=\"https://irgendeinlink.com\">Definitionen</a></i> kursiv zu setzen, ist <u>strengstens <b>verboten</b></u>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016d47f-4f2f-44ea-b773-b4b1b89ab1f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 5:** Besuch die Webseite der [Tagesschau](https://www.tagesschau.de) (und √ºberpr√ºf gleich mal, ob die oben extrahierte Schlagzeile wirklich die aktuelle ist!) und erg√§nz die in `categories` bereits angefangene Liste mit Ressorts, die Nachrichten zu spezifischen Themen bieten. Besuch au√üerdem die Webseiten einiger Ressorts und analysier, wie die jeweiligen Links aufgebaut sind. Nutz dieses Wissen und iterier √ºber `categories`, um den Quelltext jedes Ressorts herunterzuladen. Benutz denselben Code wie oben, um die oberste Schlagzeile f√ºr jedes Ressort zu extrahieren. Lass Dir Ressort und aktuelle oberste Schlagzeile nacheinander ausgeben. \n",
    "\n",
    "Schreib den Code f√ºr den Abruf- bzw. Extraktionsschritt in separaten Zellen. In der ersten Zelle rufst Du alle Quelltexte ab und h√§ngst sie einer Liste an. In der zweiten Zelle extrahierst Du aus jedem Quelltext die gew√ºnschten Informationen. So f√ºhrst Du den Abrufschritt nicht mehr aus, wenn Du am Extraktionsschritt arbeitest, wodurch der Server der Tagesschau nicht unn√∂tig belastet wird. Dadurch sinkt das Risiko, dass Du blockiert wirst.\n",
    "\n",
    "<details><summary>üìå Herausforderung </summary>\n",
    "<br>Extrahier zus√§tzlich zur obersten Schlagzeile den Link, der zum entsprechenden Artikel f√ºhrt und lass ihn Dir ebenfalls ausgeben. Klick auf die ausgegebenen Links, um zu schauen, ob sie wie erwartet funktionieren.\n",
    "<br><br>\n",
    "Das entsprechende Element findest Du auf die gleiche Weise wie f√ºr die oberste Schlagzeile beschrieben. Da sich der Link aber im <code>href</code>-Attribut (und nicht im Elementinhalt) verbirgt, h√§ngst Du anstatt <code>text</code> die Methode <code>get(\"href\")</code> an das im Quelltext gefundene Element. \n",
    "</details>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b90dd4-8270-4d91-8a92-14b727da6233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Abrufschritt\n",
    "categories = [\"Inland\", \"Ausland\", \"Wirtschaft\", \"Wissen\", \"Faktenfinder\"]\n",
    "\n",
    "base_link = \"https://www.tagesschau.de\"\n",
    "\n",
    "source_codes = []\n",
    "\n",
    "for category in categories:\n",
    "    \n",
    "    #Abrufen des Quelltexts zum konkatenierten Link und Anh√§ngen an 'source_codes'\n",
    "    source_codes.append(requests.get(base_link + \"/\" + category, timeout=5, headers=headers).text)\n",
    "    \n",
    "    print(f'Fertig mit der Kategorie \"{category}\"') #Manuelle Fortschrittsausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71052948-1633-4e81-aee4-43a2856a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraktionsschritt\n",
    "for i in range(len(source_codes)):\n",
    "    \n",
    "    soup = BeautifulSoup(source_codes[i])\n",
    "    \n",
    "    headline = soup.find(\"span\", class_=\"teaser__headline\")\n",
    "    \n",
    "    #Herausforderung\n",
    "    link = soup.find(\"a\", class_=\"teaser__link\").get(\"href\")\n",
    "    \n",
    "    print(f\"Aktuelle oberste Schlagzeile aus dem Ressort: '{categories[i]}': '{headline.text}'\")\n",
    "    \n",
    "    #Herausforderung\n",
    "    print(f\"Artikellink: {base_link + link}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991c4e8-65cc-424d-9053-9cc0798d10d7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 6:** Extrahier die oberste √úberschrift (\"Schlecht vernetzt? Psychische St√∂rungen im Gehirn\") sowie die erste √úberschrift auf der n√§chstkleineren Ebene (\"Hirnforschung: Damals und heute\") aus dem Quelltext. Extrahier ebenfalls die erste Bildunterschrift (\"Die Phrenologie (Bildquelle)\"). Als Erstes musst Du daf√ºr herausfinden, mit welchen Tags diese Elemente versehen sind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ca9a3-224a-4568-9e0f-09594974a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapen bzw. Einlesen des Quelltexts sowie Parsen (nur im L√∂sungsnotebook notwendig)\n",
    "article = requests.get(\"https://scilogs.spektrum.de/hirn-und-weg/schlecht-vernetzt-psychische-stoerungen-im-gehirn/\", timeout=5, headers=headers).text\n",
    "#with open(\"../../3_Dateien/HTML/artikel.html\") as f:\n",
    "    #article = f.read()\n",
    "    \n",
    "soup = BeautifulSoup(article)\n",
    "\n",
    "#Eigentliche L√∂sung (Wichtig: 'text'-Attribut am Ende)\n",
    "print(soup.find(\"h1\").text) #Oberste √úberschrift\n",
    "print(soup.find(\"h3\").text) #N√§chstniedrigere √úberschrift, im Quelltext wird die von HTML vorgegebene Ebene h2 √ºbersprungen\n",
    "print(soup.figcaption.text) #Bildunterschrift √ºber dot-Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558f6b4-6972-4a93-bdf6-89a9765006b5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 7:** In dieser √úbung sollst Du die Kommentare unter dem Artikel extrahieren. Identifizier dazu ein oder mehrere Suchkriterien im Quelltext, anhand derer Du alle Kommentare extrahieren kannst. Konzentrier Dich vorerst auf die Kommentare auf der ersten Ebene (ignorier also Kommentare zu Kommentaren). \n",
    "\n",
    "Lass Dir f√ºr jeden Kommentar folgende Informationen ausgeben:\n",
    "\n",
    "1. Wer hat den Kommentar verfasst?\n",
    "2. Wann wurde der Kommentar verfasst?\n",
    "3. Wie lautet der Text des Kommentars?\n",
    "\n",
    "<details><summary>üìå Herausforderung </summary>\n",
    "<br>Extrahier zus√§tzlich die Kommentare zu den Kommentaren und lass sie Dir unterhalb des zugeh√∂rigen Hauptkommentars, wiederum mit Verfasser:in, Datum und Text, ausgeben. Benutz daf√ºr einen regul√§ren Ausdruck.\n",
    "</details>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b3c23-494b-4934-aeb4-b4313dcbb3e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: Code funktioniert nur, wenn der Code zur vorangehenden √úbung ausgef√ºhrt wurde!\n",
    "\n",
    "comments = soup.find(\"ol\", class_=\"commentlist\") #Extrahieren eines ma√ügeschneiderten Elements, das nur den Bereich mit den Kommentaren umfasst\n",
    "\n",
    "\"\"\"Zwei Alternativen, um die gew√ºnschten Werte des 'class'-Attributs zu spezifizieren: Erstens: Eine Liste an Werten, die im Quelltext \n",
    "f√ºr Kommentare auf erster Ebene verwendet werden (Achtung: Liste muss ggf. erweitert werden, sollten seit 03/24 weitere Kommentare gepostet \n",
    "worden sein, vgl. √úbung 8 unten; die hier verwendete Liste funktioniert in jedem Fall f√ºr den Quelltext, wie er in \"3_Dateien/HTML/artikel.html\" \n",
    "gespeichert wurde). Zweitens: mit regul√§rem Ausdruck.\"\"\"\n",
    "\n",
    "#Erste Alternative\n",
    "values = [\"comment even thread-even depth-1\", \"comment odd alt thread-odd thread-alt depth-1\"]\n",
    "\n",
    "#Zweite Alternative\n",
    "#import re\n",
    "#values = re.compile(\"comment[\\w\\s-]+depth-1\")\n",
    "\n",
    "#Suchen nach allen Elementen mit bestimmten Werten beim 'class'-Attribut\n",
    "for comment in comments.find_all(class_=values):\n",
    "  \n",
    "    #Suchen nach relevanter Tag-Attribut-Kombination f√ºr alle drei zu extrahierenden Informationen\n",
    "    author = comment.find(class_=\"comment-headline\").text #Extraktion des Textinhalts aus diesem Element (keine Unterelemente)\n",
    "    date = comment.find(\"li\", class_=\"comment-meta\").text #Extraktion des Textinhalts aus dem Unterelement\n",
    "    text = comment.find(class_=\"comment-text\").text #Extraktion s√§mtlichen Textinhalts aus den Unterelementen\n",
    "    print(f\"Kommentar von {author}, gepostet am {date.strip()}: {text.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032dfe8c-cb89-42e9-95b9-c2b09bed9556",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Herausforderung\n",
    "import re\n",
    "#Regul√§rer Ausdruck matcht Kommentare auf Ebene eins bis max. f√ºnf\n",
    "values = re.compile(\"comment[\\w\\s-]+depth-[1-5]\")\n",
    "\n",
    "for comment in comments.find_all(class_=values):\n",
    "  \n",
    "    #Suchen nach relevanter Tag-Attribut-Kombination f√ºr alle drei zu extrahierenden Informationen\n",
    "    author = comment.find(class_=\"comment-headline\").text #Extraktion des Textinhalts aus diesem Element (keine Unterelemente)\n",
    "    date = comment.find(\"li\", class_=\"comment-meta\").text #Extraktion des Textinhalts aus dem Unterelement\n",
    "    text = comment.find(class_=\"comment-text\").text #Extraktion s√§mtlichen Textinhalts aus den Unterelementen\n",
    "    \n",
    "    #Optionale Extraktion der Ebene, auf der sich der Kommentar befindet (f√ºr Ausgabe unten)\n",
    "    depth = int(comment.get(\"class\")[-1][-1])\n",
    "    \n",
    "    #Ausgabe der Informationen inkl. Einr√ºckung bei Kommentaren auf zweiter, dritter etc. Ebene\n",
    "    print(f\"{' '*depth*2 if depth > 1 else ''}Kommentar auf Ebene {depth} von {author}, ver√∂ffentlicht am {date.strip()}: {text.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386372ae-a8ce-4eb7-86ad-5506a49eccda",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 8:** Begib Dich auf die [SciLogs-Startseite](https://scilogs.spektrum.de) und trag einige Links zu Blogeintr√§gen manuell in `links` zusammen. Ruf in derselben Zelle die Quelltexte zu allen Seiten ab und speichere sie in einer weiteren Liste. \n",
    "\n",
    "Parse anschlie√üend in der zweiten Zelle iterativ einen Quelltext nach dem anderen und extrahier jeweils die Kommentare. Hierf√ºr kannst Du grunds√§tzlich den gleichen Code wie in √úbung 7 verwenden. Pass ihn aber (sofern n√∂tig) so an, dass nun alle Kommentare extrahiert werden, auch jene auf zweiter, dritter etc. Ebene. Stell sicher, dass Du auch wirklich alle Kommentare pro Blogeintrag extrahierst.\n",
    "\n",
    "Lass Dir zus√§tzlich zu den Informationen aus √úbung 7 vor den Kommentaren jeweils den Titel des Blogeintrags ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7594db-3863-4d91-b701-325dbcac7918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Abrufschritt\n",
    "links = [\"https://scilogs.spektrum.de/hirn-und-weg/das-raetsel-der-genitalien/\",\n",
    "         \"https://scilogs.spektrum.de/natur-des-glaubens/der-atheistische-evolutionsbiologe-richard-dawkins-und-das-kulturchristentum/\",\n",
    "         \"https://scilogs.spektrum.de/menschen-bilder/showdown-im-bundesrat-cannabis-ist-entkriminalisiert/\",\n",
    "         \"https://scilogs.spektrum.de/natur-des-glaubens/ki-experiment-kann-deep-ai-die-ressourcenfluch-und-rentierstaatstheorie-unterscheiden/\"]\n",
    "\n",
    "articles = []\n",
    "\n",
    "for link in links:\n",
    "    articles.append(requests.get(link, timeout=5, headers=headers).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f52ed-95ce-4229-8727-3490d5e856fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Extraktionsschritt\n",
    "for article in articles:\n",
    "        \n",
    "    soup = BeautifulSoup(article)\n",
    "    \n",
    "    #Ausgabe Titel des Blogeintrags\n",
    "    print(soup.find(\"h1\").text, \"\\n\")\n",
    "    \n",
    "    comments = soup.find(\"ol\", class_=\"commentlist\") #Extrahieren eines ma√ügeschneiderten Elements, das nur den Bereich mit den Kommentaren umfasst\n",
    "\n",
    "    i=0 #Z√§hler\n",
    "    \n",
    "    #Regul√§rer Ausdruck matcht Kommentare auf Ebene eins bis max. f√ºnf\n",
    "    values = re.compile(\"comment[\\w\\s-]+depth-[1-5]\")\n",
    "\n",
    "    for comment in comments.find_all(class_=values):\n",
    "\n",
    "        #Suchen nach relevanter Tag-Attribut-Kombination f√ºr alle drei zu extrahierenden Informationen\n",
    "        author = comment.find(class_=\"comment-headline\").text #Extraktion des Textinhalts aus diesem Element (keine Unterelemente)\n",
    "        date = comment.find(\"li\", class_=\"comment-meta\").text #Extraktion des Textinhalts aus dem Unterelement\n",
    "        text = comment.find(class_=\"comment-text\").text #Extraktion s√§mtlichen Textinhalts aus den Unterelementen\n",
    "\n",
    "        #Optionale Extraktion der Ebene, auf der sich der Kommentar befindet (f√ºr Ausgabe unten)\n",
    "        depth = int(comment.get(\"class\")[-1][-1])\n",
    "\n",
    "        #Ausgabe der Informationen inkl. Einr√ºckung bei Kommentaren auf zweiter, dritter etc. Ebene\n",
    "        print(f\"{' '*depth*2 if depth > 1 else ''}Kommentar auf Ebene {depth} von {author}, ver√∂ffentlicht am {date.strip()}: {text.strip()}\\n\")\n",
    "        i+=1      \n",
    "            \n",
    "    \"\"\"√úberpr√ºfung, ob alle Kommentare gescrapt wurden, indem der Z√§hler mit der aus dem Element mit id='comments-title'\n",
    "    herausgesclicten Zahl √ºbereinstimmt\"\"\"\n",
    "    if not soup.find(id=\"comments-title\").text.strip().split(\" \")[0] == str(i):\n",
    "        print(\"‚ö†Ô∏è NICHT ALLE KOMMENTARE WURDEN GESCRAPT!\")\n",
    "    \n",
    "    print(\"----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a87f95-d390-43d3-942a-cba555868d57",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 9:** Benutz `trafilatura`, um Dir die Artikeltexte s√§mtlicher Blogeintr√§ge ausgeben zu lassen, deren URLs Du in √úbung 8 in `links` zusammengetragen hast. Recherchier in der [Dokumentation](https://trafilatura.readthedocs.io/en/latest/corefunctions.html#trafilatura.bare_extraction) von `trafilatura`, wie Du die Kommentare dabei herausfiltern kannst. Lass Dir bei jedem Blogeintrag den Link, die ersten 300 Zeichen des Texts, das Auslassungszeichen \"[...]\" sowie die finalen 300 Zeichen ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a110115-ad84-492b-a88b-5910e7b7f100",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: Code funktioniert nur, wenn der Code zur vorangehenden √úbung ausgef√ºhrt wurde!\n",
    "\n",
    "import trafilatura\n",
    "\n",
    "for link in links:\n",
    "    downloaded = trafilatura.fetch_url(link) #Abrufschritt\n",
    "    extract = trafilatura.extract(downloaded, include_comments=False) #Extraktionsschritt mit Parameter zum Ausschlie√üen von Kommentaren\n",
    "    \n",
    "    #Ausgabe von Link und gew√ºnschtem Textausschnitt\n",
    "    print(f\"{link}: {extract[0:300]}\\n[...]\\n{extract[-300:]}\\n\")\n",
    "    \n",
    "    \"\"\"Wie sich zeigt, funktioniert das Herausfiltern von Kommentaren gut, allerdings erkennt 'trafilatura'\n",
    "    die Quellen als Teil des Haupttexts (was nat√ºrlich am HTML-Aufbau der Seiten liegt). Je nach Anwendungsfall \n",
    "    muss 'trafilatura'-Output nachbearbeitet werden bzw. stattdessen der Weg √ºber das zielgerichtete\n",
    "    Extrahieren mit 'BeautifulSoup' gew√§hlt werden.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da003c3-16ff-4575-a559-2cbf0e0402c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "***\n",
    "<table>\n",
    "      <tr>\n",
    "        <td>\n",
    "            <img src=\"../../3_Dateien/Lizenz/CC-BY-SA.png\" width=\"400\">\n",
    "        </td> \n",
    "        <td>\n",
    "            <p>Dieses Notebook sowie s√§mtliche weiteren <a href=\"https://github.com/yannickfrommherz/exdimed-student/tree/main\">Materialien zum Programmierenlernen f√ºr Geistes- und Sozialwissenschaftler:innen</a> sind im Rahmen des Projekts <i>Experimentierraum Digitale Medienkompetenz</i> als Teil von <a href=\"https://tu-dresden.de/gsw/virtuos/\">virTUos</a> entstanden. Erstellt wurden sie von Yannick Frommherz unter Mitarbeit von Anne Josephine Matz. Sie stehen als Open Educational Resource nach <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY SA</a> zur freien Verf√ºgung. F√ºr Feedback und bei Fragen nutz bitte das <a href=\"https://forms.gle/VsYJgy4bZTSqKioA7\">Kontaktformular</a>.\n",
    "        </td>\n",
    "      </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
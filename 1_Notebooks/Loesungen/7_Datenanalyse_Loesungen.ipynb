{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d9baad-a423-4ae2-a7bf-d2b73f848ffc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Datenanalyse (L√∂sungen)\n",
    "\n",
    "‚òùÔ∏è Beachte: es gibt beim Programmieren fast immer verschiedene L√∂sungswege. Deine L√∂sung mag anders aussehen, aber dennoch zum gew√ºnschten Resultat f√ºhren. Das richtige Resultat ist das Wichtigste. \n",
    "\n",
    "‚ö†Ô∏è F√ºhre folgenden Code aus, bevor du einzelne L√∂sungen ausf√ºhrst. Im Lehrnotebook sortieren wir das DataFrame zu einem bestimmten Zeitpunkt. Diese Sortierung nehmen wir im L√∂sungsnotebook nicht vor, weswegen die Reihenfolge der Zeilen ab einem gewissen Punkt abweicht. Dies ist nicht weiter schlimm und wird blo√ü erw√§hnt, dass Du nicht wunderst, warum die Daten zwischen den beiden Notebooks vermeintlich anders ausschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e03a4-b7bb-400b-b101-383ef481d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "with open(\"../../3_Dateien/Songkorpus/songkorpus_token.tsv\") as f:\n",
    "    songkorpus = pd.read_csv(f, sep=\"\\t\")\n",
    "    \n",
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"]\n",
    "\n",
    "tokens = songkorpus[\"Token\"]\n",
    "\n",
    "decades = []\n",
    "for year in (songkorpus[\"Jahr\"]):\n",
    "    decade = str(year)[:-1] + \"0\"\n",
    "    decades.append(decade)\n",
    "    \n",
    "songkorpus[\"Jahrzehnt\"] = decades\n",
    "original_len = len(songkorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22170b-c5be-4da7-91d7-ce4381124664",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 1:** Erstelle eine weitere Series, die nur das 100.000te, 200.000te und 300.000te Token der Series `tokens` beinh√§lt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcc6a6-ad19-48f9-ae3b-22227cb7c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens[[100000,200000,300000]]) #Alternative 1: Liste an Indizes (beachte die inneren eckigen Klammern!)\n",
    "print(tokens[100000::100000]) #Alternative 2: Slicing mit Start-Index 100000 und Step 100000, vgl. zweites Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5b42a-3e16-43c2-be74-4ac38f3b8987",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 2:** \n",
    "\n",
    "1. Lies die Datei `songkorpus_tokens.tsv` abermals ein und √ºbergib beim Erstellen des DataFrames zus√§tzlich den Parameter `index_col=0`. Dadurch wird die erste Spalte (mit dem Index 0), also diejenige mit den Tokens, zur sog. *Index-Spalte*. Jede Zeile hat nun statt einem numerischen Index einen Namen, n√§mlich das jeweilige Token. Weise das DataFrame der Variablen `songkorpus_labelled_rows` zu. \n",
    "2. Benenne die Spalten wie bei `songkorpus` um. Falls Du hier eine Fehlermeldung kriegst, lies sie aufmerksam und passe Deinen Code entsprechend an.\n",
    "3. √úberlege Dir, was die Tatsache, dass wir nun Tokens als Zeilennamen verwenden, zur Konsequenz hat. Experimentiere dazu gerne mit dem DataFrame herum und greife auf verschiedene Zeilen √ºber Namen zu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344fa88-b369-4be1-881c-c5ff50787505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "songkorpus_labelled_rows = pd.read_csv(\"../../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\", index_col=0) \n",
    "    \n",
    "songkorpus_labelled_rows.columns = [\"Jahr\", \"H√§ufigkeit\"] \n",
    "\n",
    "#Zu 3.: Zeilennamen k√∂nnen mehrfach vorkommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e86b4-202f-42fc-9010-fc64aafec336",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 3:** Setze die Tatsache, dass Zeilennamen mehrfach vorkommen d√ºrfen, produktiv ein und finde heraus, wie oft \"Dresden\" in `songkorpus_labelled_rows` vorkommt, indem Du die H√§ufigkeiten in allen Jahren, in denen das Wort gesungen wird, zusammenz√§hlst.\n",
    "\n",
    "üí° Tipp: Der erste Schritt besteht darin, aus dem gesamten DataFrame `songkorpus_labelled_rows` ein kleineres, sog. *Sub-DataFrame* zu erstellen, das mit einer neuen Variablen referenziert wird. Der zweite Schritt besteht darin, eine Series aus diesem Sub-DataFrame \"herauszuschneiden\", die Du anschlie√üend wie eine Liste behandeln kannst, um schlie√ülich zur Anzahl der Nennungen von \"Dresden\" zu gelangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de3f1d-17ec-4ba7-a4b9-5cf9af7fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dresden = songkorpus_labelled_rows.loc[\"Dresden\"] #erst greifen wir auf alle Zeilen zu, die \"Dresden\" als Label haben und weisen das Resultat der Variablen \"dresden\" zu\n",
    "occurrences_per_year = dresden[\"H√§ufigkeit\"] #anschlie√üend greifen wir auf die Spalte \"H√§ufigkeit\" im Sub-DataFrame \"dresden\" zu und weisen die resultierende Series der Variablen \"occurrences_per_year\" zu\n",
    "\n",
    "#Drei Alternativen ab hier:\n",
    "\n",
    "#1. for-Loop\n",
    "#nun iterieren wir √ºber \"occurrences_per_year\" wie bei einer Liste und erh√∂hen die Z√§hlvariable \"total\" um den jeweiligen Zeilenwert\n",
    "total = 0\n",
    "for year in occurrences_per_year:\n",
    "    total += year\n",
    "print(total)\n",
    "\n",
    "#2. sum-Funktion\n",
    "print(sum(occurrences_per_year))\n",
    "\n",
    "#3. sum-Methode von pandas\n",
    "print(occurrences_per_year.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711ea39-898d-4ae4-904d-18baca47f0ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 4:** F√ºge `songkorpus` eine weitere Spalte mit dem Namen \"L√§nge\" hinzu, in der die Anzahl Buchstaben je Token steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50a8d7-ab0b-46bd-bd3b-273ab8ee4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for token in songkorpus[\"Token\"]:\n",
    "    length = len(str(token)) #Casten in string ist n√∂tig, da manche Tokens Zahlen sind und Zahlen keine L√§nge haben, vgl. zweites Notebook\n",
    "    lengths.append(length)\n",
    "    \n",
    "songkorpus[\"L√§nge\"] = lengths\n",
    "\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683ed31-2a41-4d3c-8001-dcc6af6ec194",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 5:** Vereinfache den Code von oben, mit dessen Hilfe wir die Spalte \"Jahrzehnt\" hinzugef√ºgt haben, indem Du ihn mittels List Comprehension (vgl. viertes Notebook) auf eine einzige Zeile reduzierst. Hole den Abschnitt zu List Comprehensions nach, falls Du ihn damals ausgelassen hast, da er als fortgeschritten markiert war.\n",
    "\n",
    "Hinweis: `songkorpus` verf√ºgt ja bereits √ºber eine Spalte mit der Bezeichnung \"Jahrzehnt\". Indem Du das Resultat Deiner List Comprehension `songkorpus[\"Jahrzehnt\"]` zuweist, √ºberschreibst du die befindliche Spalte ganz einfach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b035b44-6ad4-4224-837a-4feacd47b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Jahrzehnt\"] = [str(year)[:-1] + \"0\" for year in songkorpus[\"Jahr\"]]\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d1ac0-f71c-4606-b82c-1f68d673a736",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 6:** F√ºhre die Zelle oben, in der wir `songkorpus` Zeilen mit Fantasiew√∂rtern hinzugef√ºgt haben, noch ein paar Mal aus, ohne darauf zu achten wie oft. Verwende nun `drop` in einer geeigneten Kontrollstruktur (vgl. drittes Notebook) sowie die anfangs eingef√ºhrte Variable `original_len`, um die Fantasiew√∂rter wieder zu entfernen und `songkorpus`, was die Anzahl an Zeilen betrifft, wieder in seinen Originalzustand zu bringen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7d2bf-aedc-4559-b9de-802ebc57ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vorbereitung, die im Lehrnotebook nicht notwendig ist: \n",
    "#Wir f√ºngen \"new_row\", sagen wir, 17 Mal \"songkorpus\" hinzu\n",
    "new_row = [\"Fantasiewort\", 2023, 800, 2020, 12]\n",
    "for i in range(17):\n",
    "    songkorpus.loc[len(songkorpus)] = new_row\n",
    "\n",
    "#hier beginnt die L√∂sung:\n",
    "#was im Schleifenk√∂rper steht, wird wiederholt ausgef√ºhrt, solange die L√§nge von \"songkorpus\"\n",
    "#gr√∂√üer als die urspr√ºngliche L√§nge ist, d.h. wir h√∂ren auf, wenn beide Werte gleich viel betragen\n",
    "while len(songkorpus) > original_len:\n",
    "    #als Index setzen wir die L√§nge von \"songkorpus\" minus 1 ein; minus 1, da Indizes bei 0 beginnen\n",
    "    songkorpus = songkorpus.drop(len(songkorpus)-1) #√úberschreiben von \"songkorpus\", alternativ \"inplace=True\" spezifizieren\n",
    "\n",
    "#hier √ºberpr√ºfen wir das Resultat\n",
    "songkorpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656866b-407e-4065-8e22-4d4615b6ac52",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 7:** Mithilfe von `describe` haben wir oben herausgefunden, dass die durchschnittliche Wortl√§nge in `songkorpus` 6.88 Buchstaben betr√§gt. Die maximale Wortl√§nge betr√§gt hingegen sagenhafte 53 Buchstaben. Die Verteilung scheint alles andere als gleichm√§√üig zu sein, was wir auch an den sog. *Quartilen* 25% und 75% sehen (Quartile werden wie der Median berechnet, nur geht es nicht um den Mittelwert sondern um die Werte nach einem Viertel bzw. drei Vierteln aller aufgereihten Werte). Finde heraus, welche Wortl√§ngen f√ºr jeweils mindestens 10 % aller W√∂rter gelten. Finde ebenfalls heraus, welche Wortl√§ngen f√ºr jeweils maximal 1 % aller W√∂rter gelten.\n",
    "\n",
    "üí° Tipp: Einer von verschiedenen denkbaren L√∂sungswegen involviert die Tatsache, dass DataFrames und Series mit dictionaries verwandt sind und sich auch in ein solches casten lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a247969-c66f-4350-91b0-43568955a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = dict(songkorpus[\"L√§nge\"].value_counts(normalize=True))\n",
    "\n",
    "#als List Comprehension\n",
    "min_10_pc = [str(key) for key, value in lengths.items() if value > 0.1]\n",
    "max_1_pc = [str(key) for key, value in lengths.items() if value < 0.01]\n",
    "\n",
    "#als klassischer for-Loop\n",
    "min_10_pc = [] \n",
    "max_1_pc = []\n",
    "\n",
    "for key, value in lengths.items():\n",
    "    if value > 0.1:\n",
    "        min_10_pc.append(str(key))\n",
    "    elif value < 0.01:\n",
    "        max_1_pc.append(str(key))\n",
    "\n",
    "print(\"Mind. 10 %:\", \", \".join(sorted(min_10_pc)), \"\\nMax. 1 %:\", \", \".join(sorted(max_1_pc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41973d7c-514c-4e53-bfd4-baed558e640e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832d86-43cb-4cfe-a116-910d0b5762d7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "‚úèÔ∏è **L√∂sung 8:** Wir wissen bereits, wieviele Tokens in unserem DataFrame vorkommen, n√§mlich 386.510. Finde heraus, wieviele einzigartige Token, also Types (vgl. viertes Notebook) es gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd12a9-ebc2-49b0-bbf7-091913dbb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(songkorpus[\"Token\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a9597-6f3e-47f1-9630-cdd1f25a32d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 9:** Erstelle ein Sub-DataFrame, das nur Tokens beinh√§lt, die mindestes 20 Zeichen lang sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe22d34-73ee-43a6-9023-6373280b5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words = songkorpus[songkorpus[\"L√§nge\"] >= 20]\n",
    "long_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662233c-4cb7-4ada-a27a-2ea3a752d705",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 10:** Erstelle das gleiche Sub-DataFrame wie in √úbung 9 (also eines, das nur Tokens beinh√§lt, die mindestes 20 Zeichen lang sind), allerdings ohne dabei die Spalte \"L√§nge\" zu bem√ºhen. Du kannst dazu eine Methode verwenden, die auch bei normalen strings funktioniert. Stelle sicher, dass die Ergebnisse der beiden √úbungen identisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a05b6-06df-463b-b2ab-e74ee9b922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words_2 = songkorpus[songkorpus[\"Token\"].str.len() >= 20]\n",
    "\n",
    "#√úberpr√ºfen, ob die beiden Ergebnisse identisch sind:\n",
    "\n",
    "#unsichere Methode, da ja in den Zeilen andere Werte stehen k√∂nnten:\n",
    "print(len(long_words_2) == len(long_words))\n",
    "\n",
    "#sichere Methode, da wir erst s√§mtliche Werte vergleichen und dann True bzw. False ausz√§hlen\n",
    "same_values = long_words_2 == long_words\n",
    "print(same_values.value_counts()) #es kommt nur jeweils True vor, also sind die beiden Ergebnisse identisch\n",
    "\n",
    "#Pandas bietet daf√ºr auch eine Methode, n√§mlich equals():\n",
    "long_words_2.equals(long_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb2a2f4-d8dd-4ef1-997a-17b3d8e47982",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "‚úèÔ∏è **L√∂sung 11:** Oben haben wir die Spalte \"Jahrzehnt\" basierend auf den Jahreszahlen mithilfe eines `for`-Loops geschaffen. Gehe abermals von der Spalte \"Jahr\" aus, um eine neue Spalte \"Jahrzehnt_ohne_Loop\" zu schaffen, allerdings ‚Äì wie der Name verr√§t ‚Äì ohne daf√ºr einen Loop ‚Äì auch nicht in Form einer List Comprehension ‚Äì zu benutzen. Mit anderen Worten: Du sollst Pandas-Syntax daf√ºr einsetzen. Wenn Dein Code stimmt, ergibt die bereits geschriebene (derzeit auskommentierte) Zeile `True`.\n",
    "\n",
    "üí° Tipp: Es sind dieselben einzelnen Schritte wie im `for`-Loop oben n√∂tig, allerdings formuliert in pandas-Syntax. Gegebenfalls musst Du in der [pandas-Dokumentation](https://pandas.pydata.org/docs/) nachschlagen, wie die jeweilige Syntax der pandas-Pendants ausschaut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf80545-8682-4dc3-b8a7-57391a94234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus[\"Jahrzehnt_ohne_Loop\"] = songkorpus[\"Jahr\"].astype(str).str.slice(0,-1) + \"0\"\n",
    "print(songkorpus[\"Jahrzehnt\"].equals(songkorpus[\"Jahrzehnt_ohne_Loop\"]))\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83523d-d26d-41b3-9912-171f2a17a742",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 12:** Bearbeite die Werte in der Spalte \"Token\" so, dass jedes Wort, das aus genau f√ºnf Buchstaben besteht, gro√ügeschrieben wird. Einfach weil wir's k√∂nnen! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91fd0f-cb8d-45a1-8735-d4f90cf9da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "songkorpus[\"Token\"] = np.where(songkorpus[\"L√§nge\"] == 5, songkorpus[\"Token\"].str.upper(), songkorpus[\"Token\"])\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a5c7a-6992-446b-8ea8-20fdb7191a2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **L√∂sung 13:** Caste s√§mtliche Werte in `songkorpus` in strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630dc78-259c-486f-b224-6f60b0d0e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus = songkorpus.applymap(str) #str ist ja auch eine Funktion!\n",
    "#songkorpus = songkorpus.astype(str) #Alternative\n",
    "print(type(songkorpus.loc[0][\"Jahrzehnt_ohne_Loop\"])) #√úberpr√ºfung an einem bestimmten Wert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591d9ad-95c9-4b8c-8b12-ca5008c8b441",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "üîß **Anwendungsfall (komplette L√∂sung):** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a576e9d-8c61-423a-9bc0-a9f065d42869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "songkorpus = pd.read_csv(\"../../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\") \n",
    "    \n",
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"] #Spalten umbenennen\n",
    "\n",
    "#neue Spalte f√ºr relative H√§ufigkeiten schaffen, indem absolute H√§ufigkeiten durch aufsummierte H√§ufigkeit pro Jahr geteilt werden (genaue Erkl√§rung s. Schritt-f√ºr-Schritt-Anleitung)\n",
    "total_freq_per_year = songkorpus.groupby([\"Jahr\"])[\"H√§ufigkeit\"].sum()\n",
    "songkorpus[\"Relative H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] / songkorpus[\"Jahr\"].replace(total_freq_per_year) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Abfragen der zu plottenden W√∂rter\n",
    "words = input(\"Welche W√∂rter sollen geplotted werden? Bsp.: 'ich, du'.\").split(\",\")\n",
    "words = [word.strip() for word in words]\n",
    "\n",
    "#Iterieren √ºber die zu plottenden W√∂rter\n",
    "for word in words:\n",
    "    #Schaffen eines Sub-DataFrames √ºber Filter\n",
    "    word_df = songkorpus[songkorpus[\"Token\"] == word]\n",
    "    #Sortieren des Sub-DataFrames nach der Spalte \"Jahr\" und Zur√ºcksetzen des Index\n",
    "    word_df = word_df.sort_values(by=\"Jahr\", ascending=True).reset_index()\n",
    "    #Definieren von x und y, \"Jahr\" soll auf x-Achse geplotted werden, \"Relative H√§ufigkeit\" auf y-Achse\n",
    "    x = word_df[\"Jahr\"]\n",
    "    y = word_df[\"Relative H√§ufigkeit\"]\n",
    "    #Eigentliches Plotten\n",
    "    plt.plot(x, y, 'o-')\n",
    "\n",
    "#Zus√§tzliches Verfeinern und Beschriften des Plots\n",
    "plt.title(f\"Wortverlaufskurve f√ºr {', '.join([word for word in words])}\")\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Relative H√§ufigkeit\")\n",
    "plt.xlim(1967, 2023)\n",
    "plt.legend(words, loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdae0a9-9d27-45e2-ae07-877661ded407",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "üîß **Anwendungsfall (Schritt-f√ºr-Schritt-L√∂sung):**\n",
    "\n",
    "1. Um sicherzugehen, dass wir wirklich mit den originalen Daten arbeiten, lies die Datei \"songkorpus_token.tsv\" abermals ein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35473fc-a5b8-4173-9cbe-bfa26af959ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt \n",
    "songkorpus = pd.read_csv(\"../../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19782675-b5ab-406c-8a2d-f0fbf9eacc0f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "2. Benenne die Spalten in \"Token\", \"Jahr\" und \"H√§ufigkeit\" um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0922a06-746f-4e51-a4d6-fa61bb19d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b19ede-8004-4a11-97ac-d4e587ad538b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3. Im DataFrame verf√ºgen wir bislang nur √ºber absolute H√§ufigkeiten. Um die Werte zwischen einzelnen Jahren besser vergleichbar zu machen, wollen wir aber relative H√§ufigkeiten f√ºr die Visualisierung verwenden. Schaffe dazu eine Spalte \"Relative H√§ufigkeit\", die f√ºr jedes Token vermerkt, wie h√§ufig es in Relation zur Summe aller H√§ufigkeiten aller Tokens im gegebenen Jahr vorkommt. F√ºr diese Berechnung brauchst Du jeweils zwei Werte: erstens die absolute H√§ufigkeit (bereits in der Spalte \"H√§ufigkeit\") und zweitens die Summe aller H√§ufigkeiten aller Tokens im gegebenen Jahr.\n",
    "\n",
    "     Verwende die Methode [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) zur Berechnung der Summe aller H√§ufigkeiten pro Jahr. Nach dem Motto \"split-apply-combine\" erlaubt Dir diese Methode, das DataFrame nach den Werten der Spalte \"Jahr\" zu gruppieren (aufzu*split*ten). Indem Du im gleichen Statement die `sum`-Methode auf die Spalte \"H√§ufigkeit\" jedes durch `groupby` entstehenden Sub-DataFrame anwendest (*apply*), erh√§ltst Du eine zusammengef√ºhrte Series (*combine*), die f√ºr jedes Jahr die Summe aller H√§ufigkeiten aller Tokens enth√§lt. Weise die Series der Variablen `total_freq_per_year` zu und inspiziere sie.\n",
    "    \n",
    "    Um nun zur relativen H√§ufigkeit zu gelangen, musst Du f√ºr jedes Token in `songkorpus` den Wert in der Spalte \"H√§ufigkeit\" durch die jeweilige Summe an H√§ufigkeiten im gegebenen Jahr teilen. Da wir letzteren Wert in einer anderen Series (n√§mlich in `total_freq_per_year`) vorliegen haben, m√ºssen wir zu einem Trick greifen: Wende die `replace`-Methode auf die Spalte \"Jahr\" an und √ºbergib ihr `total_freq_per_year`. Wir machen uns hier den Umstand zunutze, dass eine Series wie ein dictionary funktioniert. Will hei√üen: `replace` ersetzt kurzerhand jedes Jahr (Schl√ºssel) durch die jeweilige Summe der H√§ufigkeiten pro Jahr (Wert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb5eaf-6eac-48fc-9e2d-f87a0826f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_freq_per_year = songkorpus.groupby([\"Jahr\"])[\"H√§ufigkeit\"].sum()\n",
    "songkorpus[\"Relative H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] / songkorpus[\"Jahr\"].replace(total_freq_per_year) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211267b-7aed-42f1-9bcb-cb1ddd96bd66",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "4. Installiere ggf. `matplotlib` √ºber das Terminal oder die Eingabeaufforderung und importiere anschlie√üend `matplotlib.pyplot as plt` (wieder so eine g√§ngige Abk√ºrzung). matplotlib ist die Bibliothek, die wir zum Visualisieren unserer Daten verwenden. Mithilfe der Funktion `plot(x, y)` (denk an den Modulnamen davor) k√∂nnen wir einfach Grafiken produzieren. `x` ist dabei eine Liste oder Series an Werten, die auf der x-Achse abgebildet werden sollen und `y` eine Liste oder Series derjenigen Werte, die auf der y-Achse dargestellt werden sollen. `x` und `y` m√ºssen gleich lange sein. Konkret wird der erste Punkt in der Grafik bei den Koordinaten `x[0]` und `y[0]` eingezeichnet, der zweite bei `x[1]` und `y[1]`, etc. Standardm√§√üig werden die einzelnen Punkte wie oben zu einem Graphen verbunden. Schau in den Beispieldarstellungen oben, welche Werte wir entlang der x-Achse bzw. entlang der y-Achsen plotten wollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a38b3-d30f-4a1c-a127-ed6986cf36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'pip(3) install matplotlib' zur Installation von matplotlib via Terminal/Eingabeaufforderung\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f529adc-9163-441d-825d-d0bba10f69e4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "5. Definiere eine Liste an W√∂rtern, die Du visualisieren m√∂chtest. Diesen Schritt kannst Du auch interaktiv umsetzen, sodass Du bei jeder Ausf√ºhrung aufgefordert wirst, W√∂rter zur Visualisierung anzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe4a08-d194-41db-83b1-87b83e2934a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statische Definition\n",
    "words = [\"ich\", \"du\", \"er\", \"sie\"]\n",
    "\n",
    "#Interaktive Abfrage\n",
    "#words = input(\"Welche W√∂rter sollen geplotted werden? Bsp.: 'ich, du'.\").split(\",\")\n",
    "#words = [word.strip() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367f496-5520-4002-98c7-7e50f828d11d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "6. Plotte nun nacheinander eine Verlaufskurve f√ºr jedes Wort auf der Liste. Gehe dazu f√ºr jedes Wort wie folgt vor:\n",
    "    - Schaffe ein Sub-DataFrame, in dem in der Spalte \"Token\" nur das gegebene Wort steht.\n",
    "    - Sortiere das Sub-DataFrame aufsteigend nach der Spalte \"Jahr\" und setze den Index anschlie√üend zur√ºck.\n",
    "    - √úbergib der `plot`-Funktion die relevanten Spalten des Sub-DataFrames an Stelle von `x` und `y`. √úbergib als drittes Argument den string \"o-\", der den Stil des Graphen (Linie mit Punkten) definiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5f761-79ee-41ba-9ab7-a136be56a7db",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "7. Nachdem Du alle W√∂rter der Liste entsprechend geplotted hast, kannst Du **in derselben Zelle** folgende Funktionen verwenden, um den Plot zu verfeinern:\n",
    "    - `title`, um einen Titel zu setzen.\n",
    "    - `xlabel` und  `ylabel`, um die Achsen zu beschriften.\n",
    "    - `xlim`, um der x-Achse Grenzen zu setzen, z.B. von 1969 bis 2022 (dies vereinheitlicht die Plots, da diese sonst automatisch an den Wertebereich der zu plottenden W√∂rter angepasst wird und der Plot dadurch mitunter anders beschnitten sein kann).\n",
    "    - `legend`, um eine Legende einzuf√ºgen, indem Du der Funktion die Liste mit W√∂rtern √ºbergibst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b0e1a-04c7-4d63-889f-b03feef27dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterieren √ºber die zu plottenden W√∂rter\n",
    "for word in words:\n",
    "    #Schaffen eines Sub-DataFrames √ºber Filter\n",
    "    word_df = songkorpus[songkorpus[\"Token\"] == word]\n",
    "    #Sortieren des Sub-DataFrames nach der Spalte \"Jahr\" und Zur√ºcksetzen des Index\n",
    "    word_df = word_df.sort_values(by=\"Jahr\", ascending=True).reset_index()\n",
    "    #Definieren von x und y, \"Jahr\" soll auf x-Achse geplotted werden, \"Relative H√§ufigkeit\" auf y-Achse\n",
    "    x = word_df[\"Jahr\"]\n",
    "    y = word_df[\"Relative H√§ufigkeit\"]\n",
    "    #Eigentliches Plotten\n",
    "    plt.plot(x, y, 'o-')\n",
    "\n",
    "#Zus√§tzliches Verfeinern und Beschriften des Plots\n",
    "plt.title(f\"Wortverlaufskurve f√ºr {', '.join([word for word in words])}\")\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Relative H√§ufigkeit\")\n",
    "plt.xlim(1967, 2023)\n",
    "plt.legend(words, loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9938c5-e3c9-4189-b0a5-3aed75759b1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exdimed",
   "language": "python",
   "name": "exdimed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419114ff-f17c-45bb-8178-753282c0e39a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Datenanalyse Teil 2\n",
    "\n",
    "Willkommen zur√ºck! Hier geht es nahtlos weiter mit der Datenanalyse mithilfe von Python und konkret mit pandas. Wir schauen uns erst an, wie wir DataFrames filtern sowie Werte darin bearbeiten k√∂nnen. Anschlie√üend widmen wir uns dem Anwendungsfall und visualisieren eine Wortverlaufskurve.\n",
    "\n",
    "Bevor wir mit den Daten aus dem ersten Teil des Notebook weiterarbeiten k√∂nnen, m√ºssen wir diese nochmals in den Arbeitsspeicher laden. F√ºhr dazu folgende Code-Zelle aus, die den relevanten Code des ersten Teils wiederholt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3eb00c-6cb3-4e5b-b2e1-1f386008b4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Datei in Arbeitsspeicher laden\n",
    "songkorpus = pd.read_csv(\"../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "#Umbenennen der Spalten\n",
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"]\n",
    "\n",
    "#Anf√ºgen einer Spalte f√ºr das Jahrzehnt (hier mittels List Comprehension)\n",
    "songkorpus[\"Jahrzehnt\"] = [str(year)[:-1] + \"0\" for year in songkorpus[\"Jahr\"]]\n",
    "\n",
    "#Anf√ºgen einer Spalte f√ºr die L√§nge der Tokens (hier mittels List Comprehension)\n",
    "songkorpus[\"L√§nge\"] = [len(str(token)) for token in songkorpus[\"Token\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6807ea8-319a-42b1-a7d0-986eccf77a1b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## DataFrame filtern \n",
    "\n",
    "Zun√§chst wollen wir herausfinden, wie wir ein DataFrame filtern k√∂nnen. Die grundlegende Syntax sieht wie folgt aus:\n",
    "\n",
    "```DataFrame[filter]```\n",
    "\n",
    "```filter``` wiederum kann unterschiedlich ausschauen, je nach dem, wie wir unser DataFrame filtern wollen. Ein einfaches Beispiel f√ºr ```filter``` sieht so aus:\n",
    "\n",
    "```DataFrame[column] == value```\n",
    "\n",
    "Dieser Filter verlangt, dass bei ```DataFrame``` in der Spalte ```column``` exakt der Wert ```value``` steht.\n",
    "\n",
    "F√ºgen wir diesen Filter in der obigen Syntax ein und schaffen ein Sub-DataFrame, das alle Zeilen des ```songkorpus``` beinhaltet, in denen in der Spalte ```Token``` das Wort \"Liebe\" steht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbaea10-a71a-4175-9d79-556f021cde76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liebe = songkorpus[songkorpus[\"Token\"] == \"Liebe\"]\n",
    "liebe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67aeef-7a83-4d63-b6a5-7a4a79c0f1f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das klappt wunderbar. Spiel gerne mit anderen Begriffen herum.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 1:** Erstell ein Sub-DataFrame, das nur Tokens beinhaltet, die mindestens 20 Zeichen lang sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9eeb7a-1896-46a0-8bd9-0515b00678f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa95c1-5f3d-4af9-9e3c-31e3b8f303c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Abgesehen von Vergleichsoperatoren (```==```, ```!=```, ```>```, ```<```, ```>=``` und ```<=```, vgl. Notebook \"Einf√ºhrung\") bei numerischen Werten (alle Operatoren) bzw. strings (nur die ersten beiden) k√∂nnen wir bei strings auch andere Methoden in den Filter einbauen. Pandas bietet sowohl solche an, die wir bereits von gew√∂hnlichen strings kennen (vgl. Notebook \"Funktionen und Methoden Teil 1\"), als auch ein paar eigene. Wichtig ist, dass die Methoden die Boolschen Werte ```True``` oder ```False``` zur√ºckgeben. Das hei√üt, ```startswith``` funktioniert, ```split``` hingegen nicht. String-Methoden bei pandas beginnen **immer** mit ```str```, gefolgt von der Methode, also etwa ```str.startswith()```. Au√üerdem m√ºssen wir ihnen in einigen F√§llen den Parameter ```na=False``` √ºbergeben. Hier ein paar Beispiele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17553cc2-c465-4b85-a8b7-ab91ea46fc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liebe_startswith = songkorpus[songkorpus[\"Token\"].str.startswith(\"liebe\", na=False)] #Wie normale string-Methode in Python\n",
    "liebe_endswith = songkorpus[songkorpus[\"Token\"].str.endswith(\"liebe\", na=False)] #Wie normale string-Methode in Python\n",
    "liebe_contains = songkorpus[songkorpus[\"Token\"].str.contains(\"liebe\", na=False)] #Pandas-eigene Methode\n",
    "\n",
    "print(len(liebe_startswith), len(liebe_endswith), len(liebe_contains))\n",
    "liebe_contains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ab133-bfee-479e-b80c-6ac37ad4dc7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 2:** Erstell das gleiche Sub-DataFrame wie in √úbung 1 (also eines, das nur Tokens beinhaltet, die mindestes 20 Zeichen lang sind), allerdings ohne dabei die Spalte \"L√§nge\" zu bem√ºhen. Du kannst dazu eine Methode verwenden, die auch bei normalen strings funktioniert. Stell sicher, dass die Ergebnisse der beiden √úbungen identisch sind.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1 </summary>\n",
    "  <br>Beachte, dass Du, wenn Du bei pandas Methoden auf strings anwenden m√∂chtest, <code>str</code> voranstellen musst.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "  <summary>üí° Tipp 2 </summary>\n",
    "  <br>Pandas bietet zum Vergleichen von DataFrames eine eigene Methode an. Begib Dich mit Hilfe des Internets selbst auf die Suche nach dieser Methode.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b0b58-14b6-49b6-b4a6-c2117b34fe78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9839a9-fcf7-42cd-88d2-7492a17e1fbf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Gut zu wissen: Filter k√∂nnen auch miteinander kombiniert werden. Dazu verwenden wir die logischen Operatoren aus dem Notebook \"Kontrollstrukturen\", die bei pandas allerdings in einem anderen Gewand daherkommen:\n",
    "\n",
    "- ```&``` steht f√ºr f√ºr ```and```\n",
    "- ```|``` steht f√ºr ```or``` \n",
    "\n",
    "Au√üerdem steht ```~``` steht f√ºr ```not``` und kann zur Negation eines in runde Klammern gesetzten, einzelnen Filters benutzt werden.\n",
    "\n",
    "Unter Verwendung von ```&``` k√∂nnen wir beispielsweise alle (potenziellen) regelm√§√üigen Partizip II-Formen extrahieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97271f58-6d35-438c-ab3d-fecc5ec97824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songkorpus[songkorpus[\"Token\"].str.startswith(\"ge\", na=False) & songkorpus[\"Token\"].str.endswith(\"t\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4bb00-3246-4568-98ab-a75e1caf9e2b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Bedenke, dass auch falsch positive Ergebnisse dabei sein k√∂nnten sowie dass falsch negative fehlen k√∂nnten (vgl. Wahrheitsmatrix aus dem Notebook \"Input und Output Teil 1\").\n",
    "\n",
    "Nun wissen wir, wie wir ein DataFrame filtern k√∂nnen. \n",
    "\n",
    "## Werte z√§hlen\n",
    "\n",
    "Dieses Wissen k√∂nnen wir auch einsetzen, um spezifische Werte ‚Äì im Gegensatz zu allen Werten wie bei ```value_counts``` oben ‚Äì in einer Spalte auszuz√§hlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffe10b-df4a-4eed-ac55-88c91351cf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(songkorpus[songkorpus[\"Token\"] == \"Wunderkind\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa962672-ed81-4900-bad3-9f7a93f41564",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir filtern also das DataFrame (\"alle Zeilen, in denen 'Wunderkind' in der Spalte 'Token' steht\") und lassen uns ganz einfach seine L√§nge (sprich die Anzahl an Zeilen) ausgeben.\n",
    "\n",
    "## Werte bearbeiten\n",
    "\n",
    "Auch zum Bearbeiten von Werten ben√∂tigen wir nur bereits erlerntes Wissen. Grunds√§tzlich k√∂nnen wir alles von einem kompletten DataFrame, √ºber eine Series (in Form einer Spalte oder Zeile) bis hin zu einzelnen, spezifischen Werten bearbeiten. \n",
    "\n",
    "Die M√∂glichkeiten der Bearbeitung h√§ngen nat√ºrlich vom Datentyp der Werte ab. In unserem DataFrame haben wir einerseits strings und andererseits numerische Werte. Spalten weisen jeweils einen homogen Datentyp auf.\n",
    "\n",
    "Die Logik ist unabh√§ngig davon, was wir wie bearbeiten, immer die gleiche: Wir greifen auf den gew√ºnschten Ausschnitt des DataFrame zu (s.&nbsp;o.) und √ºberschreiben ihn mit demselben Ausschnitt in bearbeiteter Form. Anstatt sie zu √ºberschreiben k√∂nnen wir die bearbeiteten Werte nat√ºrlich immer auch einer neuen Spalte oder Zeile (desgleichen oder eines neuen DataFrame) zuweisen, sofern die jeweiligen Dimensionen √ºbereinstimmen  (s.&nbsp;o.). \n",
    "\n",
    "### strings\n",
    "\n",
    "Auf strings angewandt sieht das so aus, wenn wir etwa alle Tokens kleinschreiben wollen. Auch hier setzen wir ```str``` vor die pandas-string-Methode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ccb6-4b3b-433e-a3c9-1f362c480f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songkorpus[\"Token\"] = songkorpus[\"Token\"].str.lower()\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff80b29-37ca-407d-8f47-f498622ae901",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Diese einzeilige Syntax hat es in sich: Man kann sie sich in gewohnter Python-Logik wie eine Iteration vorstellen: Im vorliegenden Fall wird Wort f√ºr Wort (in der Spalte \"Token\") kleingeschrieben. Mit dem Resultat wird die Spalte √ºberschrieben. Sie ist dennoch nicht mit einer List Comprehension, die ja auch nur eine einzige Zeile ben√∂tigt, zu verwechseln. Denn im Gegensatz zu pythonischen ```for```-Loops und ihre simplifizierte Version List Comprehension, wird der Code mit der pandas-eigenen Syntax oft **wesentlich schneller** berechnet (teils √ºber 1000 Mal schneller!). \n",
    "\n",
    "Grund daf√ºr ist die sog. *Vektorisierung*. Ganz einfach forumuliert wird dabei dieselbe Operation nicht auf ein Element nach dem anderen angewandt (wie bei ```for```-Loops), sondern auf mehrere gleichzeitig. Au√üerdem sind pandas-Operationen im Gegensatz zu nativem Python-Code (```for```-Loops) speziell auf Effizienz ausgelegt. Wenn Du Dich daf√ºr interessierst, findest Du u.&nbsp;a. in [diesem Artikel](https://medium.com/analytics-vidhya/understanding-vectorization-in-numpy-and-pandas-188b6ebc5398) und [diesem Video](https://www.youtube.com/watch?v=nxWginnBklU) Ankn√ºpfungspunkte. Weiter unten folgen √úbungen zum Vergleich von nativem Python-Code und pandas-Code.\n",
    "\n",
    "Zus√§tzlich zu den bisher verwendeten string-Methoden ```lower```, ```startswith```, ```endswith``` und ```len``` bietet pandas u.&nbsp;a. folgende an, die allesamt wie ihre nativen Python-Pendants funktionieren (vgl. Notebook \"Funktionen und Methoden Teil 1\"): \n",
    "- ```upper```, ```capitalize```, ```swapcase```, ```isupper``` und ```islower``` zur Bearbeitung/√úberpr√ºfung von Gro√ü-/Kleinschreibung der strings.\n",
    "- ```split``` zum Splitten der strings, optional mit dem Parameter ```expand=True```, um jedem unterteilten Element eine neue Spalte zuzuweisen.\n",
    "- ```replace``` zum Ersetzen aller Vorkommen eines strings/regul√§ren Ausdrucks (hier zus√§tzlich ```regex=True``` spezifizieren) mit einem anderen string.\n",
    "- ```count``` zum Berechnen der Auftretensh√§ufigkeit eines strings/regul√§ren Ausdrucks in den strings.\n",
    "- ```strip```, ```lstrip``` und ```rstrip``` zum Entfernen von (leading/trailing) whitespace in den strings.\n",
    "\n",
    "Neben ```contains``` (s.&nbsp;o.) ist au√üerdem ```slice``` eine n√ºtzliche pandas-string-Methode, die abweichend von ihrem nativen Python-Pendant hei√üt: ```slice``` mit den Argumenten ```start```, ```stop```, ```step``` implementiert die Funktionalit√§t der eckigen Klammern, die wir bei normalen Python-strings zum Slicen verwenden.\n",
    "\n",
    "[Hier](https://pandas.pydata.org/docs/user_guide/text.html) findest Du mehr Infos zu s√§mlichen string-Methoden bei pandas. Denk stets daran, ```str``` vor die jeweilige string-Methode zu h√§ngen!\n",
    "\n",
    "Zwei letzte praktische Methoden sind ```isin(list)``` und ```shift(n)```, die aber nicht string-spezifisch sind, weswegen wir **kein** ```str``` vor die Methode h√§ngen. ```isin``` √ºberpr√ºft, ob ein Wert Element der √ºbergebenen Liste ist und gibt eine Series mit Boolschen Werten zur√ºck. ```shift``` wiederum l√§sst uns auf den Inhalt benachbarter Zeilen zugreifen, konkret auf den Inhalt der um ```n``` nach oben (n) bzw. nach unten (-n) *geshifteten* Zeile. Das macht ```shift``` insbesondere f√ºr die Erstellung von n-grammen interessant. Die folgende Code-Zelle demonstriert die Erstellung von Bigrammen basierend auf einer Spalte mit Tokens (Unigrammen): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae22d36-524e-4721-8ca8-27a6bcbb9a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ngram_df = pd.DataFrame([\"Ich\", \"gehe\", \"am\", \"Abend\", \"noch\", \"spazieren\"], columns=[\"unigram\"])\n",
    "ngram_df[\"bigram\"] = ngram_df[\"unigram\"] + \" \" + ngram_df[\"unigram\"].shift(-1)\n",
    "ngram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7369cdd4-58cc-40e8-bfcd-f39289dd729f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "So einfach kann die Berechnung von n-grammen sein!\n",
    "\n",
    "### Numerische Werte\n",
    "\n",
    "Bei numerischen Werten wiederum k√∂nnen wir ganz einfach arithmetische Operatoren (vgl. Notebook \"Einf√ºhrung\") verwenden, etwa um alle Werte einer Spalte zu verdoppeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e7c6b-7ad5-4e90-8d23-e5b3e229fc2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#F√ºhr diese Zeile nur einmal aus, denn mit jedem Mal verdoppeln sich die Werte.\n",
    "songkorpus[\"H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] * 2\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e1f9c-5293-42eb-85da-611bfc6702b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Hierf√ºr funktionieren auch die anderen uns bekannten arithmetischen Operatoren: ```+``` f√ºr Addition (eignet sich √ºberdies zur Konkatenation von strings), ```-``` f√ºr Subtraktion,  ```/``` f√ºr Division und ```**``` f√ºrs Potenzieren. \n",
    "\n",
    "### Datentyp √§ndern\n",
    "\n",
    "Sollten Werte mal im falschen Datentyp vorliegen, kann man (sofern sinnvoll) die Methode ```astype``` verwenden, um Werte in den gew√ºnschten Datentyp zu casten. Wenn wir z.&nbsp;B. die H√§ufigkeiten wieder in den Originalzustand versetzen wollen, k√∂nnen wir erst alle Werte in der entsprechenden Spalte halbieren..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29624f0-fe1f-41da-a5ae-17ce0110f5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songkorpus[\"H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] / 2\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af036cd4-6bae-4eba-b55f-ed5ddbf0482e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "...und, da Resultat einer Division immer Dezimalzahlen sind (s. Nachkommastelle), anschlie√üend in Ganzzahlen casten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ebc2f-1200-45d0-92b1-b12403c87a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songkorpus[\"H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"].astype(int)\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27d54d-3a15-485b-8fd4-0accd4c6080c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 3:** Oben haben wir die Spalte \"Jahrzehnt\" basierend auf den Jahreszahlen mithilfe eines ```for```-Loops geschaffen. Geh abermals von der Spalte \"Jahr\" aus, um eine neue Spalte \"Jahrzehnt_ohne_Loop\" zu schaffen, allerdings ‚Äì wie der Name verr√§t ‚Äì ohne daf√ºr einen Loop, auch nicht in Form einer List Comprehension, zu benutzen. Mit anderen Worten: Du sollst pandas-Syntax daf√ºr einsetzen. Wenn Dein Code stimmt, ergibt die bereits geschriebene (derzeit auskommentierte) Zeile ```True```.\n",
    "\n",
    "<details>\n",
    "<summary>üí° Tipp </summary> \n",
    "<br>Es sind dieselben Schritte wie im <code>for</code>-Loop oben n√∂tig, allerdings formuliert in pandas-Syntax. Ggf. musst Du in der <a href=\"https://pandas.pydata.org/docs/\">pandas Dokumentation</a> nachschlagen, wie die jeweilige Syntax der pandas-Pendants ausschaut.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660cf89-9950-4363-9134-de1f5c300c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n",
    "#print(songkorpus[\"Jahrzehnt\"].equals(songkorpus[\"Jahrzehnt_ohne_Loop\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadd3d4-40b6-4ae7-8bbd-7603fbee5b29",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Sehr gut! Die simple Iteration von oben, die s√§mtliche Werte nacheinander auf dieselbe Weise bearbeitet, k√∂nnen wir also auch ganz einfach in vektorisierter Form nachbilden. \n",
    "\n",
    "### Bedingte Bearbeitung\n",
    "\n",
    "```for```-Loops bieten aber nat√ºrlich viel mehr Funktionalit√§t. Etwa k√∂nnen wir bedingte Anweisungen einbauen, sodass die Werte je nach Bedingung unterschiedlich bearbeitet werden. Aber auch daf√ºr bietet pandas, oder besser gesagt *numpy* (eine weitere Bibliothek, die eng mit pandas verwoben ist) eine Funktion, die sich Vektorisierung zunutze macht. Auch numpy m√ºssen wir erst importieren (ggf. sogar noch zuerst installieren, s.&nbsp;o.), g√§ngigerweise weisen wir der Bibliothek den Namen ```np``` zu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e5127-ebbc-480f-a27a-6334231dd6fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0191b-5ebf-41fa-be6c-030a7409ddcb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Funktion hei√üt ```where``` und hat folgende Syntax:\n",
    "\n",
    "```where(if, then, else)```\n",
    "\n",
    "Als erstes Argument (\"if\") spezifizieren wir eine bedingte Anweisung, die bei jedem Wert entweder ```True``` oder ```False``` ergibt. Im Falle von ```True``` wird der Wert wie im zweiten Argument (\"then\") angegeben eingetragen bzw. bearbeitet. Andernfalls greift, was wir als drittes Argument (\"else\") definiert haben. \n",
    "\n",
    "Angenommen wir m√∂chten zus√§tzlich zur Spalte \"Jahrzehnt\" eine Spalte \"Jahrhundert\", k√∂nnen wir ```where``` folgenderma√üen dazu einsetzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702bd48-8582-45df-aea3-3d91288c86ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Vor 'where' steht wie gewohnt der Modulname, damit Python wei√ü, wo sich die Funktion befindet.\n",
    "songkorpus[\"Jahrhundert\"] = np.where(songkorpus[\"Jahr\"] < 2000, \"20. Jhd.\", \"21. Jhd.\")\n",
    "songkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f9267-ec62-4128-bbce-aa318ddd5c38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sehr gut! Bedenke, dass die Begriffe ```if``` und ```else```, die wir bei bedingten Anweisungen in normalem Python verwenden, nicht ben√∂tigt werden. Die Logik ergibt sich einzig √ºber die Reihenfolge der Argumente in ```where```.\n",
    "\n",
    "In diesem Fall haben wir als \"then\" bzw. \"else\" ganz einfach strings √ºbergeben, die je nachdem in der neuen Spalte \"Jahrhundert\" eingetragen wurden. In der folgenden √úbung wollen wir bei \"then\" und \"else\" bestimmte Werte in der jeweilige Zeile bearbeiten.\n",
    "\n",
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 4:** Bearbeite die Werte in der Spalte \"Token\" so, dass jedes Wort, das aus genau f√ºnf Buchstaben besteht, gro√ügeschrieben wird. Einfach weil wir's k√∂nnen! üòâ\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp </summary>\n",
    "  <br>Zum Gro√üschreiben kannst Du eine bereits im Notebook \"Funktionen und Methoden Teil 1\" kennengelernte Funktion nutzen.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf54a3-1a1e-4e43-b364-1bf5e4287536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6175bc6-2b4f-4980-9c84-56622b32c049",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Super! \n",
    "\n",
    "F√ºr den Fall, dass Du mehrere bedingte Anweisungen aneinanderh√§ngen willst (```if```-```elif```-...-```else```), kannst Du statt ```where``` die numpy-Funktion ```select``` benutzen. Wir setzen sie weiter unten noch ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d5f67-d86c-4e59-8d37-bc65bc376e13",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### ```apply``` und ```applymap```\n",
    "\n",
    "Wie erw√§hnt ist die vektorisierte Art der Datenbearbeitung in pandas meistens √§u√üerst effizient. Es gibt aber F√§lle, in denen wir dennoch eine Funktion mit nativem Python-Code anwenden wollen. Entweder, weil pandas die ben√∂tigen Operationen nicht implementiert, oder weil es mit nativem Python-Code trotz allem effizienter ist (dazu gleich mehr).  \n",
    "\n",
    "In jedem Fall bieten die Methoden ```apply``` und ```applymap``` die M√∂glichkeit, jede beliebige Funktion (und in der Verl√§ngerung auch jede beliebige Methode) auf eine Series oder gleich ein ganzes DataFrame anzuwenden. ```apply``` verwenden wir bei einer Series, ```applymap``` bei einem ganzen DataFrame. Angeh√§ngt an die Series bzw. das DataFrame √ºbergeben wir ihnen schlicht den Namen der gew√ºnschten Funktion. Es spielt keine Rolle, ob die Funktion aus der Grundausstattung von Python stammt, importiert wurde oder von Dir selbst geschrieben ist.\n",
    "\n",
    "Machen wir es konkret, und zwar in zwei kleinen Experimenten. Wir wollen die gleiche Art der Datenbearbeitung je einmal vektorisiert implementieren, und einmal √ºber eine eigene Funktion, die wir mithilfe von ```apply``` auf die Daten *appli*zieren. Zum Verst√§ndnis: Rufen wir eine Funktion √ºber ```apply``` (oder ```applymap```) auf, wird dieser wie bei einem ```for```-Loop *Wert f√ºr Wert* √ºbergeben. Will hei√üen: Bei ```apply``` k√∂nnen wir nicht von der Verarbeitung mehrerer Daten auf einmal profitieren.\n",
    "\n",
    "F√ºr das erste Experiment rufen wir ein DataFrame ins Leben, das aus einer Million Zeilen und zwei Spalten, \"A\" und \"B\", besteht. Das DataFrame bef√ºllen wir mit zuf√§lligen Zahlen zwischen null und 100 (unter Verwendung der numpy-Funktion ```random.randint```). Insgesamt also ein ziemlich gro√ües DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4b763-4d31-4414-9e88-79083498ed40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp1 = pd.DataFrame(np.random.randint(0,100, size=(1000000,2)), columns=[\"A\", \"B\"])\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f16227-f17c-4cab-b396-274dca988365",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun wollen wir eine dritte Spalte \"C\" schaffen, die ganz einfach das jeweilige Produkt der Werte in den Spalten \"A\" und \"B\" enth√§lt. In der ersten Zelle unten tun wir dies auf vektorisierte Weise, in der zweiten mithilfe einer eigenen Funktion und ```apply```. Um zu messen, wie lange das jeweils dauert, verwenden wir das ```time```-Modul aus der Grundausstattung von Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97446a0-b890-4816-aa17-df491ddee17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Vektorisiert\n",
    "import time\n",
    "start = time.time() #Zeit zum Startpunkt\n",
    "\n",
    "exp1[\"C\"] = exp1[\"A\"] * exp1[\"B\"]\n",
    "vectorized = time.time()-start #Zeit nach Beendigung der Berechnung minus Startzeit, ergibt Dauer\n",
    "\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd67e62-30d2-4800-9038-7aac3feba728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For-Loop\n",
    "start = time.time() #Zeit zum Startpunkt\n",
    "\n",
    "def multiply(row):\n",
    "    return row[\"A\"]*row[\"B\"]\n",
    "\n",
    "#Dem Funktionsnamen (hier: 'multiply') folgen keine Klammern!\n",
    "#'axis=1' spezifiziert, dass wir die Funktion auf Spalten anwenden (s. o.)\n",
    "exp1[\"C\"] = exp1.apply(multiply, axis=1) \n",
    "\n",
    "for_loop = time.time()-start #Zeit nach Beendigung der Berechnung minus Startzeit, ergibt Dauer\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b726e8a8-12c5-4559-842e-6f87f2545fe3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die effektive Berechnungsdauer h√§ngt von verschiedenen Faktoren ab und variiert auch zwischen mehreren Durchg√§ngen. In jedem Fall aber sollte sich ein gro√üer Unterschied zeigen. Typischerweise ist die vektorisierte Berechnung mehrere Hundert Male schneller als die Verwendung einer eigenen Python-Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e6363-71e0-4bdd-afda-19c291f790df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Vektorisiert:\", vectorized, \"\\nfor-Loop\", for_loop, \"\\nFaktor:\", for_loop/vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b742f3f-1e8c-4889-83b2-051d11bf5bb8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sehr eindrucksvoll! \n",
    "\n",
    "Gehen wir zum zweiten Experiment √ºber, indem wir wieder ein DataFrame mit einer Million Zeilen, aber nur einer Spalte, \"Satz\", schaffen. Diesmal bef√ºllen wir das DataFrame mit dem immergleichen string (unter Verwendung der numpy-Funktion ```repeat```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef883a-0187-4bac-89c0-e1e84923a110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp2 = pd.DataFrame(np.repeat(\"Dies ist ein nicht besonders langer Satz.\", 1000000, axis=0), columns=[\"Satz\"])\n",
    "exp2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d43151-bde7-4ce5-80bc-f37d5bbb9f86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Hier wollen wir ebenfalls eine weitere Spalte schaffen. Sie soll ganz unspektakul√§r die Anzahl an W√∂rtern des jeweiligen strings in der Spalte \"Satz\" enthalten. In diesem konstruierten Beispiel ergibt dies selbstverst√§ndlich immer sieben. Die erste Zelle enth√§lt wieder die vektorisierte pandas-Variante, w√§hrend die zweite √ºber ```apply``` eine selbst geschriebene Funktion mit Python-Code aufruft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d523cbc-947f-474e-abf9-50c88cad3f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Vektorisiert\n",
    "start = time.time()\n",
    "\n",
    "exp2[\"L√§nge\"] = exp2[\"Satz\"].str.split().str.len()\n",
    "\n",
    "vectorized = time.time()-start\n",
    "\n",
    "exp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba63d6-76b5-41e7-a3b4-dec71706d866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For-Loop\n",
    "start = time.time()\n",
    "\n",
    "def split(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "#Dem Funktionsnamen (hier: 'split') folgen keine Klammern!\n",
    "exp2[\"L√§nge\"] = exp2[\"Satz\"].apply(split)\n",
    "for_loop = time.time()-start\n",
    "\n",
    "exp2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c41862-b0b3-422b-bdc8-079556e8bf33",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Auch hier variieren die effektiven Berechnungszeiten mitunter stark, dennoch sollte sich zeigen, dass in diesem Fall die zweite Variante mit nativem Python-Code und ```apply``` um einiges schneller berechnet wird, selbst wenn der Faktor nicht gleich eindrucksvoll wie oben ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d7067-9234-43d6-a918-2300c7afbbea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Vektorisiert:\", vectorized, \"\\nfor-Loop\", for_loop, \"\\nFaktor:\", vectorized/for_loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6e33d-dc17-4667-bef8-de111fd2a10c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir k√∂nnen festhalten, dass Vektorisierung bei Zahlen unglaublich effizient ist. Bei der Bearbeitung von strings hinken pandas-Operationen, jedenfalls bei gro√üen Datenmengen, nativem Python-Code hinterher. Es sei denn Du hast riesige Mengen an strings zu bearbeiten, empfiehlt sich der Einsatz von pandas-Operationen der Einheitlichkeit halber i.&nbsp;d.&nbsp;R. dennoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d34365-3889-44c1-8beb-1692f93d1359",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "‚úèÔ∏è **√úbung 5:** Caste s√§mtliche Werte in ```songkorpus``` in strings.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp </summary>\n",
    "  <br>Du kannst Dir zunutze machen, dass <code>str</code> auch eine Funktion ist (vgl. Notebook \"Datentypen\" zum Thema Casting). Diese musst Du dann nur noch mit einer geeigneten Methode auf das gesamte DataFrame anwenden.  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4fbbc-4a93-43bf-8c64-67de2ac399c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4a23d-dea7-4994-a861-304fe140efde",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "## üîß Anwendungsfall: Wortverlaufskurven visualisieren üìà\n",
    "\n",
    "Im Anwendungsfall f√ºr dieses Notebook wollen wir wie gesagt Wortverlaufskurven visualisieren. Das hei√üt, wir wollen die H√§ufigkeit, mit der ein beliebiges Wort auftritt, √ºber die Zeit hinweg darstellen. F√ºr die vier Personalpronomen \"ich\", \"du\", \"er\" und \"sie\" sieht das z.&nbsp;B. wie in der kombinierten Grafik unten aus. Die linke Darstellung visualisiert die Daten nach einzelnen Jahren (wie der originale Datensatz), in der mittleren und rechten Darstellung werden die Daten aggregiert nach F√ºnfjahresabschnitten bzw. Zehnjahresabschnitten visualisiert. Einzelne Aussschl√§ge nach oben und unten werden so ausgeb√ºgelt und Trends sind leichter zu erkennen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533d536",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<img src=\"../3_Dateien/Grafiken_und_Videos/Wortverlaufskurve_kombiniert.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abad895-c1c6-4b30-b444-4d1c317a98dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Deine Aufgabe ist es erst einmal, Code zu schreiben, der die linke Grafik f√ºr beliebige W√∂rter produziert. Die erforderliche Aggregation f√ºr die mittlere und rechte Darstellung schauen wir uns im Anschluss an den Anwendungsfall gemeinsam an. \n",
    "\n",
    "Wie in den Notebooks \"Funktionen und Methoden Teil 2\" und \"Input und Output Teil 2\" hast Du wieder die Wahl, den Anwendungsfall ohne weitere Anleitung in Angriff zu nehmen oder einer Schritt-f√ºr-Schritt-Anleitung zu folgen. In letzterem Fall kannst Du jetzt ans Ende der n√§chsten Code-Zelle springen. Wenn Du es alleine probieren m√∂chtest, dann analysiere das gew√ºnschte Resultat oben links und frag Dich, welche Daten wie und wo visualisiert werden. \n",
    "\n",
    "Beginne in jedem Fall damit, die Datei \"songkorpus.tsv\" neu einzulesen und die Spalten wie am Anfang des Notebooks umzubenennen. Dadurch stellst Du sicher, dass Du auch wirklich mit den urspr√ºnglichen Daten arbeitest.\n",
    "\n",
    "<details>\n",
    "<summary>üí° Tipp 1</summary> \n",
    "<br>Die relativen H√§ufigkeiten pro Wort und Jahr liegen noch nicht in unserem DataFrame vor. Du musst sie also erst ausrechnen. √úberleg Dir genau, wie Du von den existierenden, absoluten H√§ufigkeiten zu den relativen H√§ufigkeiten pro Jahr kommst. Dazu seien zwei n√ºtzliche Methoden erw√§hnt (klick auf den Funktionnamen, um zur offiziellen Dokumentation zu gelangen):\n",
    "    \n",
    "<ul>\n",
    "<li><a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\"><code>groupby</code></a>: Nach dem Motto \"split-apply-combine\" erlaubt Dir diese Methode, das DataFrame nach den Werten der Spalte \"Jahr\" zu gruppieren (aufzu<i>split</i>ten). Indem Du im gleichen Statement die <code>sum</code>-Methode auf die Spalte \"H√§ufigkeit\" jedes durch <code>groupby</code> entstehenden Sub-DataFrame anwendest (<i>apply</i>), erh√§ltst Du eine zusammengef√ºhrte Series (<i>combine</i>), die f√ºr jedes Jahr die Summe aller H√§ufigkeiten aller Tokens enth√§lt. Schau Dir diese Series genau an.</li>\n",
    "<li><a href=\"https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html\"><code>replace</code></a>: Diese Methode l√§sst sich auf eine Series (etwa eine Spalte in unserem DataFrame) anwenden und nimmt u. a. eine zweite Series als Argument (etwa eine durch <code>groupby([...])[...].sum()</code> entstandene). <code>replace</code> schaut dann, ob sich Indizes der zweiten Series als Werte in der ersten Series befinden und wenn ja, ersetzt sie diese durch die dazugeh√∂rigen Werte aus der zweiten Series. Die dictionary-Analogie von oben macht den Prozess greifbarer: <code>replace</code> ersetzt in der Series, auf die sie angewandt wird, Schl√ºssel durch ihre jeweiligen Werte aus der als Argument √ºbergebenen Series.</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary>üí° Tipp 2 </summary>\n",
    "<br>Mach Dich in der <a href=\"https://matplotlib.org/stable/users/index.html\">Dokumentation</a> von matplotlib, der Bibliothek zum Visualisieren von Daten, schlau, wie Du die errechneten Werte visualisieren kannst.\n",
    "</details>\n",
    "<br>\n",
    "Viel Erfolg! üôå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598a633-a08d-47f7-b15f-15fe300781ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur √úbung schreiben.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf93902-ed8f-46d5-92f1-c7328bbae3ff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*** \n",
    "\n",
    "**Schritt-f√ºr-Schritt-Anleitung**\n",
    "\n",
    "1. Um sicherzugehen, dass wir wirklich mit den originalen Daten arbeiten, lies die Datei \"songkorpus_token.tsv\" abermals ein. \n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp </summary>\n",
    "  <br>Achte auf das Angeben des richtigen Trennzeichens bei <code>sep</code>.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf6619-c03c-4368-9853-14146e30377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19277743-8247-406c-8f2d-e9c67cbafee4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "2. Benenn die Spalten in \"Token\", \"Jahr\" und \"H√§ufigkeit\" um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c7d87-77be-4cdb-913b-22e6b745dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba33f5-41c4-40e8-9039-0d091848673b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3. Im DataFrame verf√ºgen wir bislang nur √ºber absolute H√§ufigkeiten. Um die Werte zwischen einzelnen Jahren besser vergleichbar zu machen, wollen wir aber relative H√§ufigkeiten f√ºr die Visualisierung verwenden. Schaff dazu eine Spalte \"Relative H√§ufigkeit\", die f√ºr jedes Token vermerkt, wie h√§ufig es in Relation zur Summe aller H√§ufigkeiten aller Tokens im gegebenen Jahr vorkommt. F√ºr diese Berechnung brauchst Du jeweils zwei Werte: erstens die absolute H√§ufigkeit (bereits in der Spalte \"H√§ufigkeit\") und zweitens die Summe aller H√§ufigkeiten aller Tokens im gegebenen Jahr.\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Tipp 1 </summary>\n",
    "  <br>Verwend die Methode <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\"><code>groupby</code></a> zur Berechnung der Summe aller H√§ufigkeiten pro Jahr (klick auf den Namen der Methode, um zur offiziellen Dokumentation zu gelangen). Nach dem Motto \"split-apply-combine\" erlaubt Dir diese Methode, das DataFrame nach den Werten der Spalte \"Jahr\" zu gruppieren (aufzu<i>split</i>ten). Indem Du im gleichen Statement die <code>sum</code>-Methode auf die Spalte \"H√§ufigkeit\" jedes durch <code>groupby</code> entstehenden Sub-DataFrame anwendest (<i>apply</i>), erh√§ltst Du eine zusammengef√ºhrte Series (<i>combine</i>), die f√ºr jedes Jahr die Summe aller H√§ufigkeiten aller Tokens enth√§lt. Weis die Series der Variablen <code>total_freq_per_year</code> zu und inspizier sie.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>üí° Tipp 2 </summary>\n",
    "<br>Um nun zur relativen H√§ufigkeit zu gelangen, musst Du f√ºr jedes Token in <code>songkorpus</code> den Wert in der Spalte \"H√§ufigkeit\" durch die jeweilige Summe an H√§ufigkeiten im gegebenen Jahr teilen. Da wir letzteren Wert in einer anderen Series (n√§mlich in <code>total_freq_per_year</code>) vorliegen haben, m√ºssen wir zu einem Trick greifen: Wend die <code>replace</code>-Methode auf die Spalte \"Jahr\" an und √ºbergib ihr <code>total_freq_per_year</code>. Wir machen uns hier den Umstand zunutze, dass eine Series wie ein dictionary funktioniert. Will hei√üen: <code>replace</code> ersetzt kurzerhand jedes Jahr (Schl√ºssel) durch die jeweilige Summe der H√§ufigkeiten pro Jahr (Wert).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f3060-7230-4d82-9814-c5bb08f856ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0e505-b8c3-4308-a51a-f18fcba1a8c3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "4. Installier ggf. ```matplotlib``` √ºber das Terminal oder die Eingabeaufforderung und importier anschlie√üend ```matplotlib.pyplot as plt``` (wieder so eine g√§ngige Abk√ºrzung). matplotlib ist die Bibliothek, die wir zum Visualisieren unserer Daten verwenden. Mithilfe der Funktion ```plot(x, y)``` (denk an den Modulnamen davor) k√∂nnen wir einfach Grafiken produzieren. ```x``` ist dabei eine Liste oder Series an Werten, die auf der x-Achse abgebildet werden sollen und ```y``` eine Liste oder Series derjenigen Werte, die auf der y-Achse dargestellt werden sollen. ```x``` und ```y``` m√ºssen gleich lange sein. Konkret wird der erste Punkt in der Grafik bei den Koordinaten ```x[0]``` und ```y[0]``` eingezeichnet, der zweite bei ```x[1]``` und ```y[1]```, etc. Standardm√§√üig werden die einzelnen Punkte wie oben zu einem Graphen verbunden. Schau in den Beispieldarstellungen oben, welche Werte wir entlang der x-Achse bzw. entlang der y-Achsen plotten wollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61f63e-15e9-4ee1-b0ce-5c1146f1120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263d752-d684-49ac-bb5f-58939d2fb96e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "5. Definier eine Liste an W√∂rtern, die Du visualisieren m√∂chtest. Diesen Schritt kannst Du auch interaktiv umsetzen, sodass Du bei jeder Ausf√ºhrung aufgefordert wirst, W√∂rter zur Visualisierung anzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a60b35-d4d8-4361-adea-c622376562a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481daded-afdd-421b-a33b-9a70b9d2e2fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "6. Plotte nun nacheinander eine Verlaufskurve f√ºr jedes Wort auf der Liste. Geh dazu f√ºr jedes Wort wie folgt vor:\n",
    "    - Schaff ein Sub-DataFrame, in dem in der Spalte \"Token\" nur das gegebene Wort steht.\n",
    "    - Sortier das Sub-DataFrame aufsteigend nach der Spalte \"Jahr\" und setz den Index anschlie√üend zur√ºck.\n",
    "    - √úbergib der ```plot```-Funktion die relevanten Spalten des Sub-DataFrame an Stelle von ```x``` und ```y```. √úbergib als drittes Argument den string \"o-\", der den Stil des Graphen (Linie mit Punkten) definiert.\n",
    "    \n",
    "<details>\n",
    "  <summary>üí° Tipp </summary>\n",
    "  <br>Um die Wortverlaufskurven nacheinander in das Diagramm einzuf√ºgen, musst Du √ºber die Liste mit Deinen W√∂rtern iterieren und Wort f√ºr Wort separat plotten. Nutz daf√ºr eine for-Schleife.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b936a0-3311-4f8f-9ed1-0fcb1611021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Aufgabe schreiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8158d2-a776-47a5-b96a-6804ec651fc3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "7. Nachdem Du alle W√∂rter der Liste entsprechend geplotted hast, kannst Du **in derselben Zelle** (aber unter dem Code aus Schritt 6) folgende Funktionen verwenden, um den Plot zu verfeinern:\n",
    "    - ```title```, um einen Titel zu setzen.\n",
    "    - ```xlabel``` und  ```ylabel```, um die Achsen zu beschriften.\n",
    "    - ```xlim```, um der x-Achse Grenzen zu setzen, z.&nbsp;B. von 1969 bis 2022 (dies vereinheitlicht die Plots, da diese sonst automatisch an den Wertebereich der zu plottenden W√∂rter angepasst wird und der Plot dadurch mitunter anders beschnitten sein kann).\n",
    "    - ```legend```, um eine Legende einzuf√ºgen, indem Du der Funktion die Liste mit W√∂rtern √ºbergibst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5f9c1-4392-43c5-83e5-9508c5b0dbe7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "\n",
    "Super! ü§©\n",
    "\n",
    "Bevor wir uns zum Abschluss noch den Output von DataFrames anschauen, wollen wir die Daten wie gesagt zu gr√∂√üeren Zeiteinheiten aggregieren, und zwar zu Zehn- und F√ºnfjahresabschnitten.\n",
    "\n",
    "Auch hier laden wir zur Sicherheit noch einmal die originale Datei, benennen die Spalten um und schaffen zus√§tzlich die Spalten \"Jahrzehnt\" und \"Relative H√§ufigkeit\". Letztere wird nach wie vor relativ zur H√§ufigkeit aller Tokens in *einem* Jahr berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5082b5-9fe0-4ac4-b832-54e633a2bac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songkorpus = pd.read_csv(\"../3_Dateien/Songkorpus/songkorpus_token.tsv\", sep=\"\\t\") \n",
    "\n",
    "songkorpus.columns = [\"Token\", \"Jahr\", \"H√§ufigkeit\"]\n",
    "\n",
    "#Hier verwenden wir im Gegensatz zu oben die pandas-eigene Syntax\n",
    "songkorpus[\"Jahrzehnt\"] = (songkorpus[\"Jahr\"].astype(str).str.slice(0,-1) + \"0\").astype(int) \n",
    "\n",
    "total_freq_per_year = songkorpus.groupby([\"Jahr\"])[\"H√§ufigkeit\"].sum()\n",
    "songkorpus[\"Relative H√§ufigkeit\"] = songkorpus[\"H√§ufigkeit\"] / songkorpus[\"Jahr\"].replace(total_freq_per_year) \n",
    "\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957c305-891f-456a-bc68-1970efbd7037",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Eine Spalte mit sog. *Jahrf√ºnften* k√∂nnen wir nun unter Verwendung von numpys ```select``` erstellen. Dazu definieren wir zwei Listen, eine mit \"if\"-Bedingungen (etwa \"Wert in Spalte 'Jahr' kleiner als 1970...\") und eine mit \"then\"-Statements (\"...dann setz den Wert 1965 ein.\"). Diese Listen √ºbergeben wir der Funktion zusammen mit dem dritten Argument, das ganz einfach im \"else\"-Fall greift. Bedenk, dass die Reihenfolge der Elemente auf den beiden Listen ebenso wie die Reihenfolge von ```if```-```elif```-...-Statements in normalem Python-Code entscheidend ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486b827-1685-4c36-87d2-3f06bdbba776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = songkorpus[\"Jahr\"]\n",
    "if_list   = [x<1970, x<1975, x<1980, x<1985, x<1990, x<1995, x<2000, x<2005, x<2010, x<2015, x<2020] #Hier zeigt sich auch, warum wir die Spalte \"Jahr\" oben in Ganzzahlen gecasted haben\n",
    "then_list = [1965, 1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015]\n",
    "songkorpus[\"Jahrf√ºnft\"] = np.select(if_list, then_list, 2020)\n",
    "songkorpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50693c97-d8da-4d46-81fb-b36b7e3445b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun fehlt nur noch der Aggregationsschritt. Bei den jahresbasierten relativen H√§ufigkeiten konnten wir uns ja darauf verlassen, dass jedes Wort nur ein einziges Mal pro Jahr in unserem DataFrame steht, so sind unsere Daten ganz einfach strukturiert. \n",
    "\n",
    "Bei den Jahrf√ºnften und Jahrzehnten kann ein einzelnes Wort hingegen bis zu f√ºnf bzw. zehn Mal vorkommen. Da wir aber nur einen Wert pro Zeitabschnitt plotten wollen, m√ºssen wir s√§mtliche relativen H√§ufigkeiten in einem Jahrf√ºnft bzw. Jahrzehnt aufsummieren und anschlie√üend durch 5 resp. 10 teilen. Dadurch erhalten wir die durchschnittliche relative H√§ufigkeit pro Wort und Zeitabschnitt. \n",
    "\n",
    "Genau dies tun wir im neu eingef√ºgten Aggregationsschritt unten: Wir gruppieren das Sub-DataFrame ```word_df``` abermals mithilfe von ```groupby``` nach dem gew√ºnschten Zeitabschnitt (wahlweise Jahrf√ºnft oder Jahrzehnt) und aggregieren die Werte in der Spalte \"Relative H√§ufigkeit\", indem wir sie pro Zeitabschnitt aufsummieren. Anschlie√üend teilen wir die Summe durch die Anzahl an Jahre des Zeitabschnitts (f√ºnf oder zehn), um den Durchschnitt zu errechnen. Um wirklich nur mit kompletten Jahrf√ºnften bzw. Jahrzehnten zu rechnen, exkludieren wir zu Beginn noch s√§mtliche Tokens in den Jahren 1969, 2020, 2021 und 2022 (die Division durch f√ºnf bzw. zehn w√ºrde ja sonst zu zu kleinen Durchschnitten f√ºhren).\n",
    "\n",
    "Abgesehen vom Aggregationsschritt und dem Ausschluss inkompletter Jahrf√ºnfte bzw. Jahrzehnte wurde im Code unten die Variable ```span``` f√ºr die Zeiteinheit eingesetzt, sodass diese neben zu den zu plottenden W√∂rtern initial definiert werden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555eaee6-f59d-41dc-87b2-f030e985eef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "span, span_dict = \"Jahrzehnt\", {\"Jahrzehnt\": 10, \"Jahrf√ºnft\": 5}\n",
    "words = [\"ich\", \"du\", \"er\", \"sie\"]\n",
    "\n",
    "#Ausschluss inkompletter Jahrf√ºnfte bzw. Jahrzehnte durch Kombination zweier Filter\n",
    "songkorpus = songkorpus[(songkorpus[\"Jahr\"] > 1969) & (songkorpus[\"Jahr\"] < 2020)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word in words:\n",
    "    word_df = songkorpus[songkorpus[\"Token\"] == word]\n",
    "\n",
    "    \"\"\"NEUER SCHRITT: AGGREGATION\"\"\"\n",
    "    word_df = word_df.groupby([span]).aggregate({\"Relative H√§ufigkeit\": \"sum\"}) / span_dict[span]\n",
    "    \"\"\"NEUER SCHRITT: AGGREGATION\"\"\"\n",
    "    \n",
    "    \n",
    "    word_df = word_df.sort_values(by=span, ascending=True).reset_index()\n",
    "    x = word_df[span]\n",
    "    y = word_df[f\"Relative H√§ufigkeit\"]\n",
    "    plt.plot(x, y, 'o-')\n",
    "\n",
    "plt.title(f\"Wortverlaufskurve f√ºr {', '.join([word for word in words])}\")\n",
    "plt.xlabel(span)\n",
    "plt.ylabel(f\"Relative H√§ufigkeit ({span})\")\n",
    "plt.xlim(1969, 2011) #Anpassen, je nach Zeitabschnitt\n",
    "plt.legend(words, loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57db405-026d-4488-83b2-d1414ac610ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wunderbar. \n",
    "\n",
    "Sollte hier neben dem Plot auch eine ```SettingWithCopyWarning``` zur√ºckgegeben worden sein, kannst Du diese ignorieren.\n",
    "\n",
    "Mit ```plt.savefig(path)``` kannst Du Grafiken √ºbrigens auch auf Deiner Festplatte speichern.\n",
    "\n",
    "Damit sind wir fast am Ende des Notebooks angelangt.\n",
    "\n",
    "## Output\n",
    "\n",
    "√úbrig bleibt noch, die Methode ```to_csv``` vorzustellen, die wir verwenden k√∂nnen, um ein DataFrame als kommaseparierte Datei extern zu speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbf3fb-d6b0-46ad-a485-2d8ca2f846d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songkorpus.to_csv(\"../3_Dateien/Output/songkorpus_new.csv\", sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30eeee-6c91-43d1-af0d-fc6daf64d162",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Neben dem Ausgabepfad k√∂nnen wir das gew√ºnschte Trennzeichen und Encoding spezifizieren. Neben ```to_csv``` gibt es analog zum Input auch spezifische Output-Methoden f√ºr XML (```to_xml```), JSON (```to_json```) und Excel (```to_excel```).\n",
    "\n",
    "Damit sind wir am Ende des zweiteiligen Notebooks angelangt. Gute Arbeit!\n",
    "<br><br>\n",
    "***\n",
    "<table>\n",
    "      <tr>\n",
    "        <td>\n",
    "            <img src=\"../3_Dateien/Lizenz/CC-BY-SA.png\" width=\"400\">\n",
    "        </td> \n",
    "        <td>\n",
    "            <p>Dieses Notebook sowie s√§mtliche weiteren <a href=\"https://github.com/yannickfrommherz/exdimed-student/tree/main\">Materialien zum Programmierenlernen f√ºr Geistes- und Sozialwissenschaftler:innen</a> sind im Rahmen des Projekts <i>Experimentierraum Digitale Medienkompetenz</i> als Teil von <a href=\"https://tu-dresden.de/gsw/virtuos/\">virTUos</a> entstanden. Erstellt wurden sie von Yannick Frommherz unter Mitarbeit von Anne Josephine Matz. Sie stehen als Open Educational Resource nach <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY SA</a> zur freien Verf√ºgung.\n",
    "        </td>\n",
    "      </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b564f25e-d7f5-493e-89a0-0b4ed8053686",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# L√∂sungen zu den Zusatz√ºbungen zum Notebook \"Input und Output\"\n",
    "\n",
    "‚òùÔ∏è Beachte: Es gibt beim Programmieren fast immer verschiedene L√∂sungswege. Deine L√∂sung mag anders aussehen, aber dennoch zum gew√ºnschten Resultat f√ºhren. Das richtige Resultat ist das Wichtigste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648cb5f2-2e5e-43f5-8ad8-d06cf7a55a48",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "1. Lies das erste Kapitel von [Niels Holgersens wunderbare Reise mit den Wildg√§nsen](https://www.projekt-gutenberg.org/lagerloe/nielsho1/titlepage.html) von Selma Lagerl√∂f ein und weis es ```niels_holgersen``` zu. Entfern dabei s√§mtliche Zeilenumbr√ºche, sodass ein Flie√ütext entsteht. Lass Dir die ersten 1000 Zeichen ausgeben.\n",
    "\n",
    "   üìå Herausforderung: L√∂s die √úbung mithilfe einer List Comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0144d06-f541-4c3c-a729-8d1fcd9f6944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt\n",
    "with open(\"../../3_Dateien/Niels_Holgersen/Kapitel_1.txt\", encoding=\"utf-8\") as read_file:\n",
    "    niels_holgersen = [] #Initialisieren einer leeren Liste, an die Zeilen ohne Umbr√ºche angeh√§ngt werden\n",
    "    for line in read_file:\n",
    "        #√úberspringen, falls leere Zeile\n",
    "        if line.isspace():\n",
    "            continue\n",
    "        #Anh√§ngen der von trailing whitespace befreiten Zeile an 'niels_holgersen'\n",
    "        niels_holgersen.append(line.rstrip())\n",
    "\n",
    "    niels_holgersen = \" \".join(niels_holgersen) #Wiederzusammenf√ºgen zu einem string\n",
    "\n",
    "    \"\"\"Als List Comprehension: Achtung: funktioniert nur, wenn die gesamte for-Schleife oben auskommentiert wird!\n",
    "    Dies liegt daran, dass 'read_file' beim Iterieren dar√ºber aufgebraucht wird, d. h. jedes Element wird nach der Iteration \n",
    "    aus dem Arbeitsspeicher gel√∂scht, weswegen maximal einmal dar√ºber iteriert werden kann.\"\"\"\n",
    "    #niels_holgersen = \" \".join([line.rstrip() for line in read_file if not line.isspace()])\n",
    "\n",
    "print(niels_holgersen[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a5def-2c3e-4499-a8a8-b4e1317fa42f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "2. Lass Dir ```niels_holgersen``` als Blocksatz mit jeweils 100 Zeichen pro Zeile ausgeben. W√∂rter d√ºrfen sich √ºber Zeilenumbr√ºche hinweg erstrecken, ein Bindestrich ist nicht n√∂tig.\n",
    "\n",
    "    üìå Herausforderung: L√∂s die √úbung mithilfe einer List Comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a93031-699b-4b4f-ac51-9cfc8da6f4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "justified = [] #Initialisieren einer leeren Liste, um Zeilen bestehend aus jeweils 100 Zeichen anzuh√§ngen\n",
    "max_chars = 100 #Definieren einer Variablen f√ºr die maximale Anzahl an Zeichen pro Zeile (m√∂glichst wenig Harcoding!)\n",
    "\n",
    "#Iterieren √ºber 'niels_holgersen' mithilfe der 'range'-Funktion, wobei jeweils 'max_chars' √ºbersprungen werden\n",
    "for i in range(0, len(niels_holgersen), max_chars):\n",
    "    justified.append(niels_holgersen[i:i+max_chars]) #Slicen eines Abschnitt der L√§nge 'max_chars' und anh√§ngen an 'justified'\n",
    "\n",
    "justified = \"\\n\".join(justified)\n",
    "print(justified[0:1010]) #Ausgabe der ersten zehn Zeilen (1010, da zehn Zeilenumbr√ºche mitgerechnet werden)\n",
    "\n",
    "#Herausforderung:\n",
    "justified = \"\\n\".join([niels_holgersen[i:i+max_chars] for i in range(0, len(niels_holgersen), max_chars)])\n",
    "#print(justified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7590024-3439-489e-8673-a9f9b8f21c70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3. Extrahier s√§mtliche F√§lle von direkter Rede aus ```niels_holgersen``` und speicher sie auf der Liste ```direct_speech``` ab. Ein zu extrahierendes Beispiel lautet \n",
    "    \n",
    "        ¬ªWartet! Wartet! ich komme.¬´\n",
    "   </br>\n",
    "    Nutz hierf√ºr keine regul√§ren Ausdr√ºcke (vgl. Notebook \"Regul√§re Ausdr√ºcke\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c36e5a-4332-4ee0-8ba2-459740a5947e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "direct_speech = [] #Initialisieren einer leeren Liste, an die wir F√§lle von direkter Rede anh√§ngen\n",
    "\n",
    "#Iterieren √ºber die Zeichen in 'niels_holgersen' mittels 'range'-Funktion\n",
    "for index in range(len(niels_holgersen)):\n",
    "    #Wenn das entsprechende Zeichen in 'niels_holgersen' dem √∂ffnenden Anf√ºhrungszeichen entspricht, soll der Index als 'start_index' gespeichert werden.\n",
    "    if niels_holgersen[index] == \"¬ª\":\n",
    "        start_index = index\n",
    "    #Wenn das entsprechende Zeichen in 'niels_holgersen' dem schlie√üenden Anf√ºhrungszeichen entspricht, soll der Index als 'end_index' gespeichert werden.\n",
    "    elif niels_holgersen[index] == \"¬´\":\n",
    "        end_index = index  \n",
    "        #Nun haben wir 'start_index' und 'end_index' und k√∂nnen √ºber die gespeicherten Indizes die direkte Rede aus 'niels_holgersen' herausslicen und 'direct_speech' anh√§ngen\n",
    "        direct_speech.append(niels_holgersen[start_index:end_index])\n",
    "\n",
    "direct_speech[0:3] #Ausgabe der ersten drei Redebeitr√§ge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48d0a4-7413-47d0-a0f2-2377db62ac5a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "4. Schaff einen irrwitzigen Dialog zwischen den Figuren auf ```subjects``` (f√ºg gerne weitere am√ºsante Charaktere hinzu). Verwend dazu s√§mtliche Redebeitr√§ge auf der Liste ```direct_speech``` aus der √úbung 3 in zuf√§lliger Reihenfolge. Die Figuren sollen abwechselnd zu Wort kommen, wobei sie ihren Redebeitrag √ºber ein jeweils zuf√§lliges Sprechaktverb der Liste ```verbs``` √§u√üern (auch hier kannst Du gerne weitere Verben hinzuf√ºgen). Der Dialog soll wie folgt aussehen:\n",
    "\n",
    "     <img src=\"../../3_Dateien/Grafiken_und_Videos/Irrwitziger_Dialog.png\">\n",
    "\n",
    "    und so weiter.\n",
    "\n",
    "   Um eine zuf√§llige Reihenfolge bzw. eine zuf√§llige Auswahl zu generieren, musst Du ein Dir bekanntes Modul importieren. Lies ggf. in der Dokumentation des Moduls nach, welche Funktionen die ben√∂tigten Operationen implementieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145a58a-26d0-43ba-bbf7-6916c17f9240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjects = [\"Der Witwer\", \"Die Diva\", \"Der Kobold (der heimlich zugegen war)\", \"Die misanthrope Ente\"]\n",
    "verbs = [\"meinte\", \"schrie\", \"fl√ºsterte\", \"hielt dagegen\", \"verk√ºndete\", \"jauchzte\", \"raunte\", \"soufflierte\", \"r√∂chelte\"]\n",
    "\n",
    "import random #Importieren des Moduls 'random', um zuf√§llige Reihenfolge der Redebeitr√§ge sowie zuf√§lliges Verb zu generieren\n",
    "\n",
    "random.shuffle(direct_speech) #Zuf√§lliges Umordnen der Elemente auf der Liste (geschieht in-place)\n",
    "\n",
    "dialog = [] #Initialisieren einer leeren Liste, um anschlie√üend die einzelnen Redebeitr√§ge anzuh√§ngen (direkte Ausgabe mittels 'print' in der Schleife ist auch in Ordnung)\n",
    "\n",
    "i = 0 #Initialisieren einer Z√§hlervariablen, um Figuren abwechselnd zu indizieren (s. u.)\n",
    "\n",
    "#Iterieren √ºber die Redebeitr√§ge\n",
    "for utterance in direct_speech:\n",
    "    random_verb = random.choice(verbs) #Zuf√§lliges Verb aus der Liste ausw√§hlen\n",
    "    \"\"\"Zusammenf√ºgen von alternierendem Subjekt (indiziert via Z√§hlervariable, die nach dem letzten Element auf null zur√ºckgesetzt wird (s. u.)),\n",
    "    zuf√§lligem Verb und Redebeitrag zu einem string sowie Anh√§ngen an Liste 'dialog'\"\"\"\n",
    "    line = subjects[i] + \" \" + random_verb + \": \" + utterance + \".\"\n",
    "    dialog.append(line)\n",
    "\n",
    "    #Erh√∂hen der Z√§hlervariablen um eins\n",
    "    i+=1\n",
    "    \"\"\"Zur√ºcksetzen der Z√§hlervariablen auf null (d. h. im n√§chsten Redebeitrag spricht wieder die erste Figur der Liste), \n",
    "    falls sie gr√∂√üer als die L√§nge der Liste der Figuren minus eins ist (minus eins, da die Z√§hlervariable bzw. Indizes bei null beginnnen,\n",
    "    die L√§nge der Liste jedoch bei eins)\"\"\"\n",
    "    if i > len(subjects)-1:\n",
    "        i=0\n",
    "\n",
    "print(\"\\n\".join(dialog)) #Ausgabe des Dialogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f32be4-9eef-4c47-84e6-4ec019223f61",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "5. F√ºhr den Code, den Du in √úbung 4 geschrieben hast, ein paar Mal aus, bis Du einen besonders lustigen Dialog erh√§ltst. Speicher nun diesen Dialog als Textdatei im Ordner \"Output\". Formatier dabei den Text wie ein Drama (vgl. *Nathan der Weise* im Lehrnotebook Teil 1). Die Textdatei soll zudem einen Titel sowie eine Auflistung der Figuren beinhalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6fdbb-71d8-4718-90d6-fb83560d216f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = \"Der wirre Witwer und die misanthrope Ente. Eine Posse.\" #Definieren eines frei gew√§hlten Titels\n",
    "characters = \", \".join(subjects) #Zusammenf√ºgen der Figuren zu einem string\n",
    "\n",
    "#(Schaffen) und √ñffnen einer zu beschreibenden Datei im Ordner \"Output\"\n",
    "with open(\"../../3_Dateien/Output/irrwitzigster_dialog.txt\", \"w\", encoding=\"utf-8\") as write_file:\n",
    "\n",
    "    #Schreiben des Titels und der Figurenliste am Anfang der Datei\n",
    "    write_file.write(title + \"\\n\\n\")\n",
    "    write_file.write(\"Figuren: \" + characters + \".\\n\\n--------------\\n\\n\")\n",
    "\n",
    "    #Iterieren √ºber Redebeitr√§ge\n",
    "    for line in dialog:\n",
    "        \"\"\"Schreiben der einzelnen Redebeitr√§ge in die Datei, jeweils mit doppeltem Zeilenumbruch abgeschlossen, um Redebeitr√§ge (die in sich theoretisch\n",
    "        auch Zeilenumbr√ºche beinhalten k√∂nnten) voneinander klar abzugrenzen\"\"\"\n",
    "        write_file.write(line + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bf966-38f0-4df1-a95b-8467ca9013a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "6. F√ºg Deiner eben geschaffenen Datei (mithilfe von Python!) den Satz \"An dieser Stelle endet die Zusammenkunft abrupt.\" an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424f011-29cc-48d1-9c39-193992d56e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end = \"An dieser Stelle endet die die Zusammenkunft abrupt.\" #Definieren des string, der am Ende der Datei stehen soll\n",
    "\n",
    "#√ñffnen der bereits existierenden Datei im 'append'-Modus (\"a\")\n",
    "with open(\"../../3_Dateien/Output/irrwitzigster_dialog.txt\", \"a\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(end) #Anh√§ngen des string 'end' am Ende der Datei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490e21c-c27d-42f9-a34b-e5a120047ff4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "7. Lass Dir das aktuelle Arbeitsverzeichnis sowie die darin befindlichen Dateien und Verzeichnisse ausgeben.\n",
    "\n",
    "    üìå Herausforderung: Schaff mithilfe von Python ein neues Verzeichnis namens \"new_dir\" im aktuellen Arbeitsverzeichnis und √ºberpr√ºf anschlie√üend ebenfalls mithilfe von Python, ob es geklappt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6138c7-c5f0-4f0d-a60a-d90070adbd0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os #Importieren des Moduls\n",
    "\n",
    "#Ausgeben von aktuellem Arbeitsverzeichnis sowie den darin befindlichen Dateien und Verzeichnissen\n",
    "print(os.getcwd()) #Beachte: Hier wird ein anderer Pfad als im √úbungsnotebook ausgegeben, da sich das L√∂sungsnotebook in einem anderen Verzeichnis befindet.\n",
    "print(os.listdir()) #Entsprechend befinden sich auch andere Dateien und Verzeichnisse darin.\n",
    "\n",
    "#Herausforderung\n",
    "os.makedirs(\"new_dir\") #Schaffen eines neuen Verzeichnisses (beachte: funktioniert nur einmal, danach 'FileExistsError!')\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4f56f-e924-4b5d-95e0-c85d30411877",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "8. Lies aufbauend auf der Zusatz√ºbung 7 zum Notebook \"Kontrollstrukturen\" die Datei \"de_sv.csv\" aus dem Ordner \"Tabellarische_Daten\" ein. Darin befinden sich nun mehr als nur eine Handvoll Vokabeln Deutsch-Schwedisch. Genauer gesagt handelt es sich um die 100 wichtigsten Vokabeln gem√§√ü ChatGPT. √úberf√ºhr die Daten in ein geeignetes Objekt und \"f√ºtter\" damit den bereits programmierten Vokabeltrainer. Beim Einlesen d√ºrfte die Dir noch unbekannte `next`-Funktion hilfreich sein ‚Äì erkunde selbst√§ndig, wie Du sie einsetzen kannst. Implementier au√üerdem einen Mechanismus, √ºber den Benutzer:innen die Lernsession vorzeitig beenden k√∂nnen, falls sie nicht alle 100 Vokabeln lernen m√∂chten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5013ac-bc8b-4255-b463-bf1c52df2c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Achtung: anderer Pfad als im Notebook, da das L√∂sungsnotebook in einem anderen Verzeichnis liegt\n",
    "with open(\"../../3_Dateien/Tabellarische_Daten/de_sv.csv\", encoding=\"utf-8\") as read_file:\n",
    "    \n",
    "    de_sv = {} #Initialisieren eines leeren dictionary, an das wir die Daten als Schl√ºssel-Werte-Paare anh√§ngen\n",
    "\n",
    "    #Die erste Zeile beinhaltet Spaltennamen, wir √ºberspringen sie mit der Funktion 'next'\n",
    "    next(read_file) \n",
    "\n",
    "    \"\"\"Iterieren √ºber einzelne Zeilen in 'read_file', aufsplitten beim Trennzeichen (\",\") und schaffen von Schl√ºssel-Werte-Paaren.\n",
    "    An dieser Stelle k√∂nnten wir auch die 'reader'-Funktion des 'csv-Moduls' einsetzen.\"\"\"\n",
    "    for line in read_file:\n",
    "        de, sv = line.split(\",\")\n",
    "        de_sv[de] = sv.strip() #Entfernen von trailing whitespace (Zeilenumbruch)\n",
    "\n",
    "\"\"\"Hier wird der Vokabeltrainer (Dokumentation des Codes siehe L√∂sung zu Zusatz√ºbung 7 zum Notebook \"Kontrollstrukturen\")\n",
    "in eine Funktion gepackt, damit wir die doppelte Schleife (while und for) auf einfache Weise beenden k√∂nnen, sobald Benutzer:innen\n",
    "die Lernsession abbrechen wollen. Dies erreichen wir unkompliziert mithilfe des 'return'-Statements (s. u.).\n",
    "Ohne Funktion lie√üe sich dieser Mechanismus z. B. mit zwei 'break'-Statements (eines in jeder Schleife) implementieren.\"\"\"\n",
    "def vocab_trainer():\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        #Zus√§tzliche Info, wie die Lernsession beendet werden kann\n",
    "        print(\"Hej! Mit mir kannst Du Schwedisch lernen! Wenn Du genug gelernt hast, gib einfach 'X' ein.\")\n",
    "    \n",
    "        learnt_during_iteration = []\n",
    "            \n",
    "        for word, translation in de_sv.items():\n",
    "            \n",
    "            prompt = \"Wie sagt man '\" + word + \"' auf Schwedisch?\" \n",
    "    \n",
    "            answer = input(prompt)\n",
    "\n",
    "            #Zus√§tzliche Bedingung, die √ºberpr√ºft, ob Benutzer:in Lernsession beenden will (hier mittels Eingabe von \"X\")\n",
    "            if answer == \"X\":\n",
    "                return(\"Tsch√ºss / Hejd√•!\")\n",
    "            \n",
    "            if answer == translation:\n",
    "                print(\"Korrekt! ü•≥\")\n",
    "                learnt_during_iteration.append(word)\n",
    "            else:\n",
    "                print(\"Das war leider falsch üòÖ. Richtig w√§re '\" + translation + \"' gewesen!\")\n",
    "        \n",
    "        for learnt_word in learnt_during_iteration:\n",
    "            de_sv.pop(learnt_word)\n",
    "            \n",
    "        if len(de_sv) < 1:\n",
    "            print(\"Du kannst alle Vokabeln! üéâ\")\n",
    "            break\n",
    "\n",
    "vocab_trainer() #Aufrufen der Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137dc06-de9c-42ed-a946-c7d89ba83a1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "9. Pass den Code aus √úbung 8 derart an, dass Benutzer:innen eine √úbersicht √ºber die korrekt √ºbersetzten bzw. falsch √ºbersetzten Vokabeln gegeben wird, sobald sie die Lernsession beenden. √úberleg Dir, wie Du diese √úbersicht visuell ansprechend formatieren kannst. Folgender Screenshot ist eine Idee, Du kannst die Ausgabe auch gerne anders gestalten:\n",
    "   \n",
    "    <img src=\"../../3_Dateien/Grafiken_und_Videos/Formatierung.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a09fc6-3b58-4df4-9807-f9f13dec6074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dokumentation s. o.\n",
    "with open(\"../../3_Dateien/Tabellarische_Daten/de_sv.csv\", encoding=\"utf-8\") as read_file:\n",
    "    \n",
    "    de_sv = {} \n",
    "\n",
    "    next(read_file) \n",
    "\n",
    "    for line in read_file:\n",
    "        de, sv = line.split(\",\")\n",
    "        de_sv[de] = sv.strip() \n",
    "\n",
    "def vocab_trainer():\n",
    "    \n",
    "    correctly_translated, incorrectly_translated = [], [] #Initialisieren zweier Listen f√ºr (in)korrekt √ºbersetzte Vokabeln\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        print(\"Hej! Mit mir kannst Du Schwedisch lernen! Wenn Du genug gelernt hast, gib einfach 'X' ein.\")\n",
    "    \n",
    "        learnt_during_iteration = []\n",
    "            \n",
    "        for word, translation in de_sv.items():\n",
    "            \n",
    "            prompt = \"Wie sagt man '\" + word + \"' auf Schwedisch?\" \n",
    "    \n",
    "            answer = input(prompt)\n",
    "\n",
    "            if answer == \"X\":\n",
    "                \n",
    "                \"\"\"F√ºr eine ansprechende √úbersicht von (in)korrekt √ºbersetzten Vokabeln verwenden wir f-strings, und genauer,\n",
    "                die Angabe eines digit space von 20 Zeichen pro Wort und Sprache. Um eine Tabelle zu imitieren, lassen wir uns\n",
    "                am vertikalen Anfang und Ende der jeweiligen √úbersicht '-' 40 Mal ausgeben (komplexer Ausdruck), \n",
    "                jeweils mit '|' am horizontalen Anfang, in der Mitte sowie am Ende.\"\"\"\n",
    "                \n",
    "                print(f\"\\nDiese Vokabeln hast Du korrekt √ºbersetzt:\\n\")\n",
    "                print(f\"|{'‚Äì'*20}|{'-'*20}|\")\n",
    "                print(f\"| {'Deutsch':19}| {'Schwedisch':19}|\")\n",
    "                print(f\"|{'-'*20}|{'-'*20}|\")\n",
    "\n",
    "                for word in correctly_translated:\n",
    "                    print(f\"| {word:19}| {de_sv[word]:19}|\")\n",
    "\n",
    "                print(f\"|{'-'*20}|{'-'*20}|\")\n",
    "\n",
    "\n",
    "                print(f\"\\nDiese Vokabeln hast Du falsch √ºbersetzt:\\n\")\n",
    "                print(f\"|{'‚Äì'*20}|{'-'*20}|\")\n",
    "                print(f\"| {'Deutsch':19}| {'Schwedisch':19}|\")\n",
    "                print(f\"|{'-'*20}|{'-'*20}|\")\n",
    "\n",
    "                for word in incorrectly_translated:\n",
    "                    print(f\"| {word:19}| {de_sv[word]:19}|\")\n",
    "\n",
    "                print(f\"|{'-'*20}|{'-'*20}|\")\n",
    "                \n",
    "                return(\"Tsch√ºss / Hejd√•!\")\n",
    "            \n",
    "            if answer == translation:\n",
    "                print(\"Korrekt! ü•≥\")\n",
    "                learnt_during_iteration.append(word)\n",
    "                correctly_translated.append(word)\n",
    "            else:\n",
    "                print(\"Das war leider falsch üòÖ. Richtig w√§re '\" + translation + \"' gewesen!\")\n",
    "                incorrectly_translated.append(word)\n",
    "        \n",
    "        for learnt_word in learnt_during_iteration:\n",
    "            de_sv.pop(learnt_word)\n",
    "            \n",
    "        if len(de_sv) < 1:\n",
    "            print(\"Du kannst alle Vokabeln! üéâ\")\n",
    "            break\n",
    "\n",
    "vocab_trainer() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bce57-09f2-49e0-bfc8-3a86988c9421",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "10. Wirklich gute Texte bringen die Sache tats√§chlich auch jeweils klar auf den Punkt.\n",
    "\n",
    "    Dieser Satz ist wahr, aber schlecht formuliert, da f√ºnf von dreizehn W√∂rtern F√ºllw√∂rter sind. F√ºllw√∂rter tragen wenig zur Aussage eines Satzes bei und schm√§lern dadurch insgesamt seine Aussagekraft. In dieser √úbung kannst Du √ºberpr√ºfen, wie es um von Dir verfasste Texte in Bezug auf F√ºllw√∂rter steht. Such Dir dazu einen l√§ngeren Text aus (z.&nbsp;B. eine Seminararbeit). Es soll sich um eine Microsoft Word-Datei handeln.\n",
    "    \n",
    "    1. Installier das Modul `docx2txt` √ºber das Terminal bzw. die Eingabeaufforderung (```pip3 install docx2txt```) und importier es anschlie√üend hier. Deinen Text kannst Du mihilfe der Funktion `process` unter Angabe seines Dateipfads einlesen, also so: ```docx2txt.process(path)```. Splitte Deinen Text in W√∂rter und nimm sinnvolle Preprocessing-Schritte vor.\n",
    "    2. Lies die Datei \"fuellwoerter.txt\" aus dem gleichnamigen Ordner ein und schaff eine Liste mit F√ºllw√∂rtern.\n",
    "    3. Z√§hl s√§mtliche F√ºllw√∂rter in Deinem Text aus und lass Dir die zehn h√§ufigsten F√ºllw√∂rter inklusive ihrer Vorkommensh√§ufigkeit ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ee196-a69b-4ced-a3b7-a490214e605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "\n",
    "text = docx2txt.process(\"path\") #F√ºg hier den Pfad zu Deinem Text ein.\n",
    "words = text.lower().split() #Splitten des Texts und Kleinschreiben s√§mtlicher W√∂rter \n",
    "\n",
    "#Einlesen der F√ºllw√∂rter\n",
    "with open(\"../../3_Dateien/Fuellwoerter/fuellwoerter.txt\") as f:\n",
    "    fillers = [word.strip().lower() for word in f.readlines()] #Anh√§ngen der bereinigten F√ºllw√∂rter an 'fillers'\n",
    "        \n",
    "fillers_dict = {} #Initialisieren eines leeren dictionary, dem wir nach und nach F√ºllwort-Vorkommen-Paare anh√§ngen\n",
    "#Iterieren √ºber die einzelnen F√ºllw√∂rter \n",
    "for filler in fillers:\n",
    "    \"\"\"Schaffen eines neuen Schl√ºssel-Werte-Paars in 'filler_dict' mit dem jeweiligen F√ºllwort als Schl√ºssel \n",
    "    und dessen Vorkommen (ermittelt √ºber 'count') als Wert\"\"\"\n",
    "    fillers_dict[filler] = words.count(filler)\n",
    "\n",
    "fillers_sorted = sorted(fillers_dict.items(), key=lambda x: x[1], reverse=True) #Absteigendes Sortieren von 'fillers_dict' nach Werten \n",
    "fillers_sorted[0:10] #Ausgabe der ersten zehn Elemente auf 'fillers_sorted'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8a102-e83a-4d91-9483-bed4e5168792",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "11. Es gibt ja diese Theorie, dass man die Reihenfolge der Buchstaben in W√∂rtern zuf√§llig mischen kann. Solange der erste und letzte Buchstabe erhalten bleiben, k√∂nnen wir das Wort trotzdem fl√ºssig lesen. √úberpr√ºfen wir das an dieser Aufgabenstellung. Schreib dazu einen Code, der die Buchstaben in den W√∂rtern dieser Aufgabenstellung zuf√§llig mischt, wobei der jeweilige Anfangs- und Endbuchstabe eines Wortes gleich bleiben sollen. Die Reihenfolge der W√∂rter soll nat√ºrlich ebenfalls gleich bleiben. Zur zuf√§lligen Mischung kannst Du wie oben die Funktion ```shuffle``` des Moduls ```random``` benutzen. Zeig das Resultat einer uneingeweihten Person und schau, ob diese den manipulierten Text lesen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ccb37-93ba-4da5-ad75-0a2291161bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Es gibt ja diese Theorie, dass man die Reihenfolge der Buchstaben in W√∂rtern zuf√§llig mischen kann. Solange der erste und letzte Buchstabe erhalten bleiben, k√∂nnen wir das Wort trotzdem fl√ºssig lesen. √úberpr√ºfen wir das an dieser Aufgabenstellung. Schreib dazu einen Code, der die Buchstaben in den W√∂rtern dieser Aufgabenstellung zuf√§llig mischt, wobei der jeweilige Anfangs- und Endbuchstabe eines Wortes gleich bleiben sollen. Die Reihenfolge der W√∂rter soll nat√ºrlich ebenfalls gleich bleiben. Zur zuf√§lligen Mischung kannst Du wie oben die Funktion shuffle des Moduls random benutzen. Zeig das Resultat einer uneingeweihten Person und schau, ob diese den manipulierten Text lesen kann.\"\n",
    "\n",
    "import random\n",
    "\n",
    "#Splitten des Texts in W√∂rter sowie Entfernen von Sonderzeichen bei s√§mtlichen W√∂rtern\n",
    "words = [word.strip(\",.-\") for word in text.split()] \n",
    "\n",
    "#Iterieren √ºber die einzelnen W√∂rter\n",
    "for word in words:\n",
    "    \"\"\"√úberpr√ºfen, ob das Wort aus mehr als drei Buchstaben besteht (da wir ja nur wortinterne Buchstaben mischen wollen;\n",
    "    bei drei Buchstaben kann sich die Position des einzigen wortinternen Buchstaben ja nicht ver√§ndern)\"\"\"\n",
    "    if len(word) > 3:\n",
    "        first_letter = word[0] #Extrahieren des Anfangsbuchstabens\n",
    "        last_letter = word[-1] #Extrahieren des Endbuchstabens\n",
    "        internal_letters = list(word[1:-1]) #Splitten der wortinternen Buchstaben mithilfe von 'list'\n",
    "        random.shuffle(internal_letters) #Zuf√§lliges Mischen der wortinternen Buchstaben\n",
    "        internal_letters = \"\".join(internal_letters) #Wiederzusammenf√ºgen der gemischten Buchstaben zu einem string\n",
    "        #Konkatenation aller Buchstaben, wobei 'end=\"\"' spezifiziert, dass am Ende der Ausgabe kein Zeilenumbruch stehen soll\n",
    "        print(first_letter + internal_letters + last_letter + \" \", end=\"\") \n",
    "    else:\n",
    "        print(word + \" \", end=\"\") #Ausgabe von zu kurzen W√∂rtern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20108b18-0df7-4972-b9ed-c8b6a6cf9040",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "12. In dieser letzten √úbung begeben wir uns in unbekanntes Terrain. Den Gro√üteil der Arbeit erledigen wir n√§mlich nicht wie gewohnt aus dem Jupyter Notebook heraus, sondern √ºber die Command Line (Terminal unter macOS und Linux/Eingabeaufforderung unter Windows; Achtung: √úbung funktioniert nicht innerhalb von GitHub Codespace). Manche Tools stehen n√§mlich nur f√ºr die Command Line bereit und nicht f√ºr Python. So auch [TreeTagger](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/), ein Tool, mit dem wir Text in verschiedenen Sprachen mit metalinguistischen Informationen wie Lemmata (also die jeweiligen Formen von W√∂rtern, die in einem W√∂rterbuch stehen, z.&nbsp;B. \"Kindes\" > \"Kind\") oder Part-of-Speech-Tags (Wortarten; abgek√ºrzt: *POS*) anreichern k√∂nnen.\n",
    "\n",
    "    1. Installier TreeTagger √ºber die Schritte 1-5 auf der oben verlinkten Seite. Bei den \"parameter files\" l√§dst Du das [German parameter file](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/german.par.gz) herunter. Speicher alle Dateien im gleichen Verzeichnis und achte darauf, dass der Dateipfad dorthin keine Leerschl√§ge enth√§lt. Entpack keine der Dateien. Bei Schritt 5 ist es wichtig, dass Du die Command Line entweder direkt aus dem Verzeichnis mit den TreeTagger-Dateien heraus √∂ffnest (i.&nbsp;d.&nbsp;R. m√∂glich √ºber Rechtsklick im Verzeichnis), oder mittels ```cd path``` zum Verzeichnis navigierst. Dadurch hat die Command Line das Verzeichnis der TreeTagger-Dateien als aktuelles Arbeitsverzeichnis.\n",
    "    3. Schau, ob die Installation geklappt hat, indem Du in der Command Line (mit dem TreeTagger-Verzeichnis als Arbeitsverzeichnis!) den Befehl ```echo 'Hallo Welt!' | cmd/tree-tagger-german``` eingibst. Ggf. verhindert Dein Betriebssystem die Ausf√ºhrung des Befehls, weil TreeTagger nicht von einem verifizierten Entwickler stammt. √úber die Einstellungen Deines Betriebssystems solltest Du diese Blockierung aufheben k√∂nnen. Die Ausgabe sollte folgenderma√üen ausschauen:\n",
    "\n",
    "        <img src=\"../../3_Dateien/Grafiken_und_Videos/Terminal_Output.png\" width=\"450\"/>\n",
    "\n",
    "\n",
    "        Die erste Spalte enth√§lt die urspr√ºnglichen W√∂rter unserer Eingabe in tokenisierter Form (ein Token pro Zeile). Die zweite Spalte enth√§lt die POS-Tags (die deutsche Legende findest Du [hier](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/STTS-Tagset.pdf)) und die dritte die Lemmata.\n",
    "    4. Nun wollen wir einen l√§ngeren Text taggen. Speicher dazu den in √úbung 1 erstellten Flie√ütext mit Niels Holgersens erstem Kapitel im gleichen Verzeichnis wie die TreeTagger-Dateien unter dem Namen \"niels_holgersen.txt\" ab.\n",
    "    5. F√ºhr den Befehl ```cmd/tree-tagger-german niels_holgersen.txt > niels_holgersen_tagged.txt``` in der Command Line (mit dem TreeTagger-Verzeichnis als Arbeitsverzeichnis!) aus. Dadurch √ºbergeben wir \"niels_holgersen.txt\" dem Programm \"tree-tagger-german\" (das sich im Unterverzeichnis \"cmd/\" befindet). Das Programm tokenisiert, POS-taggt und lemmatisiert den Text in \"niels_holgersen.txt\" und speichert das Ergebnis in \"niels_holgersen_tagged.txt\". √ñffne die neue Datei (z.&nbsp;B. mit Sublime Text) und inspizier sie.\n",
    "    6. Lies die Datei hier ein und find heraus, welches POS-Tag am h√§ufigsten vorkommt. Es sollte sich um Nomen (NN) handeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db6fcc-bfa7-4f34-84f6-a3d1541eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Im folgenden Befehl fehlt der Pfad zum Verzeichnis mit den TreeTagger-Dateien, setz ihn bei 'path' ein und entfern die Hashtags\n",
    "#with open(\"path/niels_holgersen.txt\", \"w\", encoding=\"utf-8\") as write_file:\n",
    "    #write_file.write(niels_holgersen)\n",
    "\n",
    "#An dieser Stelle f√ºhrst Du Schritt D aus\n",
    "\n",
    "#Hier lesen wir 'niels_holgersen_tagged.txt' ein, wobei der Pfad wiederum individuell ist, setz ihn bei 'path' ein\n",
    "with open(\"path/niels_holgersen_tagged.txt\", encoding=\"utf-8\") as read_file:\n",
    "    \n",
    "    pos_tags = [] #Erstellen einer leeren Liste, an die wir alle POS-Tags aus der zweiten Spalte anh√§ngen\n",
    "\n",
    "    #Iterieren √ºber alle Zeilen, Splitten nach Tab und Anh√§ngen des zweiten Elements (mit Index eins) an 'pos_tags'\n",
    "    for line in read_file:\n",
    "        pos = line.split(\"\\t\")[1]\n",
    "        pos_tags.append(pos)\n",
    "\n",
    "    \"\"\"Als List Comprehension: Achtung: funktioniert nur, wenn die gesamte for-Schleife oben auskommentiert wird!\n",
    "    Dies liegt daran, dass 'read_file' beim Iterieren dar√ºber aufgebraucht wird, d. h. jedes Element wird nach der Iteration \n",
    "    aus dem Arbeitsspeicher gel√∂scht, weswegen maximal einmal dar√ºber iteriert werden kann.\"\"\"\n",
    "    #pos_tags = [line.split(\"\\t\")[1] for line in read_file]\n",
    "\n",
    "types = set(pos_tags) #Erstellen einer Menge an POS-Tags\n",
    "\n",
    "freq_dict = {} #Erstellen eines frequency dictionary, an das wir POS-Tags sowie ihre Frequenzen als Schl√ºssel-Werte-Paare anh√§ngen\n",
    "\n",
    "#Iterieren √ºber alle Types und Z√§hlen des jeweiligen Vorkommens in 'pos_tags' sowie Schaffen eines Schl√ºssel-Werte-Paars\n",
    "for type_ in types:\n",
    "    freq_dict[type_] = pos_tags.count(type_)\n",
    "\n",
    "#Ausgabe des ersten Elements des nach Werten absteigend sortierten 'freq_dict'\n",
    "print(sorted(freq_dict.items(), key = lambda x: x[1], reverse=True)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
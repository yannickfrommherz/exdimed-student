{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958eddb3-e696-4db7-a180-4097589d74cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Zusatzübungen zum Notebook \"Datenanalyse\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edacc49-c17c-419b-8ede-bf3e2288dc0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "✏️ **Übung 1:** Lad Dir den Datensatz mit einer Million Sätzen aus deutschsprachigen Nachrichtentexten (\"News\") aus dem Jahr 2022 von der Seite des Projekts [Wortschatz Leipzig](https://wortschatz.uni-leipzig.de/de/download/German) herunter und speicher ihn an einem sinnvollen Ort. Entpack die Datei (falls das bei Windows auf Anhieb nicht funktioniert, empfiehlt sich das Programm [WinRAR](https://www.winrar.de)) und lies die Datei \"deu_news_2022_1M-sentences.txt\" mithilfe von pandas ein. Das DataFrame soll ```news_df``` heißen und aus zwei Spalten (```sentence_id``` und ```sentence```) sowie einer Million Zeilen bestehen. Spaltennamen kannst Du mithilfe des ```names```-Argument beim Einlesen definieren. Lass Dir die ersten zehn Zeilen ausgeben.\n",
    "  \n",
    "   Befinden sich wirklich eine Million Sätze im DataFrame? Falls dies bei Deinem DataFrame nicht der Fall ist, überleg Dir, was schief gelaufen sein könnte, denn in der Datei \"deu_news_2022_1M-sentences.txt\" befinden sich garantiert eine Million Sätze.\n",
    "<details>\n",
    "    <summary> 💡 Tipp </summary>\n",
    "    <br> Zeilen, die ein öffnendes, aber kein schließendes Anführungszeichen beinhalten, führen dazu, dass pandas \"\\t\" am Ende der Zeile literal anstatt als Trennzeichen interpretiert. Dadurch landen mehrere Sätze in <i>einer</i> Zeile (nämlich alle bis zum nächsten \"schließenden\" Anführungszeichen), weswegen schlussendlich weniger als eine Million Zeilen im DataFrame stehen. Informier Dich in der Dokumentation von pandas über den Parameter <code>quoting</code>, mit dessen Hilfe Du dieses Verhalten übersteuern kannst.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae4310-3430-4ae4-89d6-0eb1e74578ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f77ccd9-64d5-4971-bb5e-e83e5fdddf2e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 2:** Find heraus, ob es in den deutschsprachigen Nachrichten 2022 häufiger um die Ukraine oder Corona ging (unter der Annahme, dass der Datensatz repräsentativ für die deutschsprachigen Nachrichten ist).\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Tipp </summary>\n",
    "    <br>Du kannst hierfür die Methode <code>contains</code> nutzen. Bedenk aber, dass Du bei der Arbeit mit strings in pandas noch etwas vor die Methode schreiben musst.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c83732-9d6f-4a3e-9ced-18997cdfe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0ed30-784d-41b1-bd04-c685a0e62b8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 3:** Schaff eine zusätzliche Spalte im DataFrame, in der die jeweilige Länge des Satzes in Wörtern verzeichnet ist.\n",
    "\n",
    "   Wie lang ist der längste Satz? Wie lang ist der kürzeste Satz? Und was ist die durchschnittliche Satzlänge?\n",
    "\n",
    "   Lass Dir den längsten sowie den kürzesten Satz ausgeben!\n",
    "   \n",
    "<details>\n",
    "    <summary>💡 Tipp </summary>\n",
    "    <br>Die Berechnung der Länge eines Satzes kommt bereits im Notebook \"Datenanalyse Teil 2\" vor. Schau dort noch einmal nach und pass den Code an die Aufgabe hier an.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f8fd1-ce81-4a63-960e-85177141aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134217b6-86e7-46a8-a392-454fe0f40fff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 4:** Sortier das DataFrame nach der Länge der Sätze in absteigender Reihenfolge. Welcher Schritt ist anschließend noch sinnvoll?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73f820-d529-4de4-bf96-d5ea4ed2e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f543b92-96d4-43af-98b8-52b288ad438c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 5:** Bereinige sämtliche Sätze derart, dass Sonderzeichen von allen Wortanfängen und -enden entfernt werden. Dazu steht Dir die Liste ```special_signs``` zur Verfügung. Groß- und Kleinschreibung sollst Du beibehalten. Jeder Satz soll auch nach dem Preprocessing als ein string vorliegen. \n",
    "\n",
    "<details>\n",
    "    <summary>💡 Tipp </summary>\n",
    "    <br>Verwend die pandas-eigene, vektorisierte Art der Datenbearbeitung und denk daran, dass Du diese auch in Kombination mit selbst definierten Funktionen verwenden kannst.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "    <summary>🦊 Herausforderung </summary>\n",
    "    <br>Verwend maximal eine Zeile zur Bereinigung der Sätze.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff981af-f891-4949-931c-323472eb6093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n",
    "special_signs = ['‰', ':', '§', '´', '.', '́', ';', '❓', '‑', '”', ')', ',', '<', '″', '»', '−', '✔', '•', '\"', '`', '〉', '†', '*', '>', '&', \"'\", '‹', '/', '‚', '®', '°', '‒', '▶', '(', '%', '‘', '€', '«', 'Ł', '═', '„', '!', '–', '?', '-', '︎', '—', '“', '·', '…', '‟', '‡','’', '$', 'ł', '~', '™', '›', '+']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22931f-fec9-4454-af94-a7c4f2e74fa4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 6:** Mit welchen zehn Wörtern beginnen die Nachrichtensätze am häufigsten?\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Tipp </summary>\n",
    "    <br>Um jeweils auf das n-te Element einer Liste in jeder Zeile einer bestimmten Spalte zuzugreifen, kannst Du <code>.str[n]</code> an den Spaltennamen anhängen. So kannst Du den Satzanfang addressieren und mit einer geeigneten Methode die Häufigkeiten auszählen.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1085d-acae-427f-8c4c-c569ebcf1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15347b0-018b-4686-a8c1-cb68d554af4f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 7:** Und mit welchen zehn Wörtern enden die Nachrichtensätze am häufigsten?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd4824-edae-4092-b45a-365aeef3d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffa3ba-524e-45f9-9b40-e702518c6100",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 8:** Wortschatz Leipzig stellt nicht nur eine Million Sätze zur Verfügung, sondern listet auch auf, wann und von welchem Nachrichtenportal die Sätze extrahiert wurden. Diese Informationen sind jedoch in zwei weiteren Dateien gespeichert, die Du ebenfalls bereits heruntergeladen und entpackt hast. Sämtliche Quellen sowie Daten (wann wurde der Satz heruntergeladen?) sind in \"deu_news_2022_1M-sources.txt\" aufgelistet und mit Quellen-IDs versehen, die Zuordnung zwischen Quellen-ID und Satz-ID findet sich wiederum in \"deu_news_2022_1M-inv_so.txt\".\n",
    "\n",
    "Deine Aufgabe ist es nun, diese Informationen (Quelle und Datum) mit dem DataFrame ```news_df``` zu vereinen. Dazu bietet sich eine Dir vermutlich noch unbekannte Methode namens ```merge``` an. Informier Dich [hier](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) über die Methode. Bei ```merge``` kannst Du mithilfe des ```on```-Parameters spezifizieren, auf Basis der Werte welcher Spalte die Zusammenführung zweier DataFrames erfolgen soll. Wichtig ist dabei, dass der angegebene Spaltenname in beiden DataFrames existiert. Stell sicher, dass Du am Ende immer noch eine Million Sätze in Deinem DataFrame hast, sowie dass keine fehlenden Werte (die etwa aufgrund eines falschen Mergings eingetragen wurden) darin vorkommen. Verwend dazu entweder ```if```-Bedingungen, oder, eleganter, ```assert```-Statements (mehr dazu [hier](https://realpython.com/python-assert-statement/#getting-to-know-assertions-in-python)). \n",
    "    \n",
    "Überprüf abschließend bei ein paar Quellenlinks, ob die jeweiligen Sätze tatsächlich auf der entsprechenden Website zu finden sind.\n",
    "    \n",
    "⚠️ Achtung: Wenn Du mehrfach hintereinander dieselben DataFrames zusammenfügst, riskierst Du einen ```KeyError``` bei der als ```on```-Parameter übergebenen Spalte. Die Fehlermeldung rührt daher, dass pandas bei mehrmaligem Mergen bereits existierende Spaltennamen um ein Suffix ergänzt, da Spaltennamen einzigartig sein müssen. Schaff deshalb als erstes eine Kopie von ```news_df``` mithilfe von ```news_df_enriched = news_df.copy()``` und arbeite fortan mit ```news_df_enriched```. Jedes Mal, wenn Du die ganze Zelle ausführst, um die DataFrames zu mergen, passiert dies somit auf Basis einer (immer wieder) neu erstellten Kopie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce126da8-439d-4cf2-881d-b1bc4812c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n",
    "news_df_enriched = news_df.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94c799-0fec-4f48-90ab-266796124fdf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 9:** Füg eine weitere Spalte namens ```country``` hinzu, die basierend auf der Top-Level-Domain (TLD) des Quellenlinks (z.&nbsp;B. \".de\" oder \".ch\") angibt, aus welchem Land der jeweilige Nachrichtensatz stammt. Dies lässt sich am leichtesten mithilfe eines regulären Ausdrucks (vgl. Notebook \"Reguläre Ausdrücke\") und der Methode```findall``` umsetzen. Wenn Du bereits Erfahrung mit regulären Ausdrücken hast, probier Dich gern daran aus. Sonst kannst Du die Aufgabe natürlich aber auch ohne reguläre Ausdrücke lösen.\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Tipp </summary>\n",
    "    <br>Wenn Du nicht mit regulären Ausdrücken arbeiten willst, schau Dir im Vorfeld mit einem Editor die Links in \"deu_news_2022_1M-sources.txt\" an. Alle Links beginnen mit derselben Struktur. Durch Splitten an bestimmten Zeichen kannst Du die TLD extrahieren.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "    <summary>🦊 Herausforderung </summary>\n",
    "    <br>Lass Dir eine schön formatierte Übersicht über die absolute und eine relative Häufigkeitsverteilung der Länder ausgeben. Folgender Screenshot ist eine Idee für die Formatierung, Du kannst es aber auch anders umsetzen: <br><br>\n",
    "    <img src=\"../3_Dateien/Grafiken_und_Videos/tld_overview.png\" width=\"300\"/>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81834c1c-c8df-43e9-8218-50ee2f5000c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n",
    "news_df = news_df_enriched #\"Zurückverweisen\" von 'news_df_enriched' auf 'news_df', da dies der simplere Variablenname ist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073b44d-1dd5-4147-a915-27e53986188b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 10:** Schaff ein Sub-DataFrame mit Nachrichtensätzen aus dem [DACH](https://de.wikipedia.org/wiki/D-A-CH)-Raum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d384950-4273-4eea-bfd9-6542bd1377ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111709e8-3dfa-4f77-8a73-8e2ab1d0bdef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "✏️ **Übung 11:** Zum Schluss wollen wir noch überprüfen, ob das Sampling der Nachrichtensätze im Datensatz einigermaßen repräsentativ für \n",
    "die deutschsprachigen Länder ist, wobei wir uns der Einfachheit halber wieder auf den DACH-Raum beschränken. Deutschland ist ungefähr um den Faktor zehn größer als Österreich resp. die Schweiz (überprüf gerne die aktuellen Einwohner:innenzahl der drei Länder). Entsprechend sollten zirka zehn mal so viele Nachrichtensätze aus Deutschland stammen als aus Österreich bzw. der Schweiz. Gleichzeitig sollte der Anteil an Nachrichtensätzen aus Deutschland, Österreich und der Schweiz aber auch einigermaßen gleichmäßig über das Jahr 2022 verteilt sein. Idealerweise wurden nicht bloß im Januar Schweizer Quellen, im Februar österreichische und den Rest des Jahres deutsche gesammelt... Die Verteilung nach Land über die Monate des Jahres 2022 hinweg wollen wir uns als Plot ausgeben lassen. Bevor Du diesen Plot erstellst, führ folgende Vorbereitungsschritte aus:\n",
    "\n",
    "- Wenn Du Dir die Daten (wann wurde der Satz heruntergeladen?) in ```news_df``` anschaust (z.&nbsp;B. mittels ```news_df[~news_df.date.str.startswith(\"2022\")])```, siehst Du, dass einige unrealistische Daten dabei sind. Da hat wohl das Web-Scraping bzw. das Postprocessing versagt... Filter das DataFrame derart, dass nur Sätze aus dem Jahr 2022 übrigbleiben.\n",
    "- Da wir die Verteilung anstatt über 365 Tage vereinfacht über zwölf Monate hinweg plotten wollen, schaff eine neue Spalte mit dem jeweiligen Extraktionsmonat des Nachrichtensatzes. Sortier das DataFrame anschließend nach den Werten dieser neuen Spalte.\n",
    "    </br></br>\n",
    "    \n",
    "    Analysier nun folgenden Plot und erstell ihn anschließend selbst. Überleg Dir abschließend, ob das Sampling repräsentativ für die Größe der DACH-Länder über die Monate hinweg ist.\n",
    "    \n",
    "    \n",
    "    <img src=\"../3_Dateien/Grafiken_und_Videos/news_dach.png\" width=\"600\"/> </br>\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Tipp 1</summary>\n",
    "    <br>Orientier Dich an der Diagrammerstellung im Notebook \"Datenanalyse Teil 2\". \n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "    <summary>💡 Tipp 2</summary>\n",
    "    <br>Um den Monat aus einem Datum zu extrahieren, kannst Du an einem entsprechenden Zeichen splitten und anschließend Indexing anwenden.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d0e1c-fe9a-4949-b701-ae4710f56364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In diese Zelle kannst Du den Code zur Übung schreiben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babfd1f-bd5c-458f-a8a7-3178484cc98f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "<table>\n",
    "      <tr>\n",
    "        <td>\n",
    "            <img src=\"../3_Dateien/Lizenz/CC-BY-SA.png\" width=\"400\">\n",
    "        </td> \n",
    "        <td>\n",
    "            <p>Dieses Notebook sowie sämtliche weiteren <a href=\"https://github.com/yannickfrommherz/exdimed-student/tree/main\">Materialien zum Programmierenlernen für Geistes- und Sozialwissenschaftler:innen</a> sind im Rahmen des Projekts <i>Experimentierraum Digitale Medienkompetenz</i> als Teil von <a href=\"https://tu-dresden.de/gsw/virtuos/\">virTUos</a> entstanden. Erstellt wurden sie von Yannick Frommherz unter Mitarbeit von Anne Josephine Matz. Sie stehen als Open Educational Resource nach <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">CC BY SA</a> zur freien Verfügung. Für Feedback und bei Fragen nutz bitte das <a href=\"https://forms.gle/VsYJgy4bZTSqKioA7\">Kontaktformular</a>.\n",
    "        </td>\n",
    "      </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}